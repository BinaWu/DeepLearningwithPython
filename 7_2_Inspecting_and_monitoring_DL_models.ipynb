{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.2-Inspecting_and_monitoring_DL_models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "r3dnK4h7vCs1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eathon/DeepLearningwithPython/blob/master/7_2_Inspecting_and_monitoring_DL_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "22U4wtacvCrZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Companion Notebook - 7.2 Inspecting and monitoring DL models \n",
        "# using Keras callbacks and TensorBoard\n",
        "## Chap 7 «Advanced Deep-learning best practices»\n",
        "## «Deep Learning with Python» book by François Chollet\n",
        "\n",
        "This notebook contains the code samples found in Chapter 7 of «Deep Learning with Python». Note that the original text features far more content, in particular further explanations and figures.\n",
        "\n",
        "修改與補充Claude COULOMBE的github :https://github.com/ClaudeCoulombe/deep-learning-with-python-notebooks (by Claude COULOMBE - PhD candidate - TÉLUQ / UQAM - Montréal.)"
      ]
    },
    {
      "metadata": {
        "id": "3khujC1uvCrb",
        "colab_type": "code",
        "outputId": "e8031b79-c66c-4921-ca12-a5bee5271b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# sudo pip3 install --ignore-installed --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as KTF\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "KTF.set_session(session)\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)\n",
        "# To ignore keep_dims warning\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.4\n",
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tcrWMnMwxLib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Install some packages to visualize the network structure\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BDNuWfzUw5Lc",
        "colab_type": "code",
        "outputId": "57ff7aea-5ce4-45ee-c392-2d4cb8c57c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3140
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz \n",
        "!apt-get install graphviz "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting graphviz\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Installing collected packages: graphviz\n",
            "Successfully installed graphviz-0.10.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fontconfig libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "Suggested packages:\n",
            "  gsfonts graphviz-doc libgd-tools\n",
            "The following NEW packages will be installed:\n",
            "  fontconfig graphviz libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "0 upgraded, 30 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 4,154 kB of archives.\n",
            "After this operation, 16.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libann0 amd64 1.1.2+doc-6 [24.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcdt5 amd64 2.40.1-2 [19.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcgraph6 amd64 2.40.1-2 [40.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtiff5 amd64 4.0.9-5 [152 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebp6 amd64 0.6.1-2 [185 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.2 [119 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-0 amd64 0.34.0-2 [229 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-render0 amd64 1.13-1 [14.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shm0 amd64 1.13-1 [5,572 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo2 amd64 1.15.10-2 [580 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl7 amd64 2.4.6-2 [38.8 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpathplan4 amd64 2.40.1-2 [22.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6 amd64 2.40.1-2 [601 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvpr2 amd64 2.40.1-2 [169 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblab-gamut1 amd64 2.40.1-2 [178 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 graphviz amd64 2.40.1-2 [601 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
            "Fetched 4,154 kB in 2s (2,285 kB/s)\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libann0.\n",
            "Preparing to unpack .../01-libann0_1.1.2+doc-6_amd64.deb ...\n",
            "Unpacking libann0 (1.1.2+doc-6) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.40.1-2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../04-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../05-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../06-libwebp6_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../07-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../08-libgd3_2.2.5-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Selecting previously unselected package libgts-0.7-5:amd64.\n",
            "Preparing to unpack .../09-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../10-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../11-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../12-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../13-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../14-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../15-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../16-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../17-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../18-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.40.1-2) ...\n",
            "Selecting previously unselected package liblab-gamut1.\n",
            "Preparing to unpack .../24-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
            "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../25-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../26-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../27-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../28-graphviz_2.40.1-2_amd64.deb ...\n",
            "Unpacking graphviz (2.40.1-2) ...\n",
            "Selecting previously unselected package libgts-bin.\n",
            "Preparing to unpack .../29-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Setting up libpathplan4 (2.40.1-2) ...\n",
            "Setting up liblab-gamut1 (2.40.1-2) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libann0 (1.1.2+doc-6) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libcdt5 (2.40.1-2) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.40.1-2) ...\n",
            "Setting up libwebp6:amd64 (0.6.1-2) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libgvpr2 (2.40.1-2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libgvc6 (2.40.1-2) ...\n",
            "Setting up graphviz (2.40.1-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ikjjtc_lvp7v",
        "colab_type": "code",
        "outputId": "2054ccbd-2726-4c7e-de50-4febdb488ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Install pydot to visualize the network structure\n",
        "!pip install pydot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
            "\r\u001b[K    7% |██▌                             | 10kB 21.4MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 20kB 2.9MB/s eta 0:00:01\r\u001b[K    23% |███████▌                        | 30kB 3.3MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 40kB 3.1MB/s eta 0:00:01\r\u001b[K    38% |████████████▍                   | 51kB 3.4MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 61kB 4.0MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▍              | 71kB 4.2MB/s eta 0:00:01\r\u001b[K    62% |███████████████████▉            | 81kB 4.1MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▍         | 92kB 4.5MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 102kB 4.7MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▎    | 112kB 4.7MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 122kB 5.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 133kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.0)\n",
            "Building wheels for collected packages: pydot\n",
            "  Running setup.py bdist_wheel for pydot ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
            "Successfully built pydot\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vR2KUIrbwHXC",
        "colab_type": "code",
        "outputId": "6727c5d5-fe3c-4c76-a681-9007b2a9f2d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install pydot-ng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydot-ng\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/5b/9a08333f2d70d404ffe42cea4f50159c4ad94feaa4d7585551c05cacef46/pydot_ng-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from pydot-ng) (2.3.0)\n",
            "Installing collected packages: pydot-ng\n",
            "Successfully installed pydot-ng-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qk_sxXLQxzDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### After fininishing the installation, you have to restart the runtime!!"
      ]
    },
    {
      "metadata": {
        "id": "kzRenJDNvCro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.2. Inspecting and monitoring DL models using Keras call-backs and TensorBoard \n",
        "\n",
        "In this section, we’ll review ways to gain greater access to and control over what goes on inside your model during training. Launching a training run on a large dataset for tens of epochs using model.fit() or model.fit_generator() can be a bit like launching a paper airplane: past the initial impulse, you don’t have any control over its trajectory or its landing spot. If you want to avoid bad outcomes (and thus wasted paper airplanes), it’s smarter to use not a paper plane, but a drone that can sense its environment, send data back to its operator, and automatically make steering decisions based on its current state. The techniques we present here will transform the call to model.fit() from a paper airplane into a smart, autonomous drone that can self-introspect and dynamically take action. \n",
        "\n",
        "### 7.2.1. Using callbacks to act on a model during training \n",
        "\n",
        "When you’re training a model, there are many things you can’t predict from the start. In particular, you can’t tell how many epochs will be needed to get to an optimal validation loss. The examples so far have adopted the strategy of training for enough epochs that you begin overfitting, using the first run to figure out the proper number of epochs to train for, and then finally launching a new training run from scratch using this optimal number. Of course, this approach is wasteful. \n",
        "\n",
        "A much better way to handle this is to stop training when you measure that the validation loss in no longer improving. This can be achieved using a Keras callback. A callback is an object (a class instance implementing specific methods) that is passed to the model in the call to fit and that is called by the model at various points during training. It has access to all the available data about the state of the model and its performance, and it can take action: interrupt training, save a model, load a different weight set, or otherwise alter the state of the model.\n",
        "\n",
        "Here are some examples of ways you can use callbacks: \n",
        "\n",
        "* **Model checkpointing** — Saving the current weights of the model at different points during training. \n",
        "* **Early stopping** — Interrupting training when the validation loss is no longer improving (and of course, saving the best model obtained during training). \n",
        "* **Dynamically adjusting the value of certain parameters during training** — Such as the learning rate of the optimizer. \n",
        "* **Logging / Visualizing training and validation metrics during training** or visualizing the representations learned by the model as they’re updated — The Keras progress bar that you’re familiar with is a callback!\n",
        "\n",
        "The keras.callbacks module includes a number of built-in callbacks (this is not an exhaustive list):\n",
        "\n",
        "https://keras.io/callbacks/\n",
        "\n",
        "* keras.callbacks.ModelCheckpoint\n",
        "* keras.callbacks.EarlyStopping\n",
        "* keras.callbacks.LearningRateScheduler\n",
        "* keras.callbacks.ReduceLROnPlateau\n",
        "* keras.callbacks.CSVLogger\n",
        "\n",
        "### The ModelCheckpoint and EarlyStopping callbacks\n",
        "\n",
        "You can use the `EarlyStopping` callback to interrupt training once a target metric being monitored has stopped improving for a fixed number of epochs. For instance, this callback allows you to interrupt training as soon as you start overfitting, thus avoiding having to retrain your model for a smaller number of epochs. This callback is typically used in combination with `ModelCheckpoint`, which lets you continually save the model during training (and, optionally, save only the current best model so far: the version of the model that achieved the best performance at the end of an epoch)"
      ]
    },
    {
      "metadata": {
        "id": "QQl57IvlvCrr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Python\n",
        "\n",
        "import keras\n",
        "\n",
        "# Callbacks are passed to the model via the callbacks argument in fit, \n",
        "# which takes a list of callbacks. You can pass any number of callbacks.\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=1,\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath='my_model_callback.h5',\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "# You monitor accuracy, so it should be part of the model’s metrics.\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])\n",
        "\n",
        "# Note that because the callback will monitor validation loss and validation accuracy,\n",
        "# you need to pass validation_data to the call to fit.\n",
        "model.fit(x, y,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(x_val, y_val)\n",
        "         )\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "bKIknm9rvCrs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train a CNN model using the Functional API and the MNIST data\n",
        "### with EarlyStopping and ModelCheckpoint callbacks\n",
        "\n",
        "Inspired by: \n",
        "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
      ]
    },
    {
      "metadata": {
        "id": "0f7t6LeGvCrv",
        "colab_type": "code",
        "outputId": "9c1be191-e2a2-43b8-901e-dcb50afada2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "def cnn_layers(inputs):\n",
        "    x = layers.Conv2D(32, (3, 3),\n",
        "                      activation='relu', padding='valid')(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    predictions = layers.Dense(num_classes,\n",
        "                               activation='softmax',\n",
        "                               name='x_train_out')(x)\n",
        "    return predictions\n",
        "\n",
        "model_input = layers.Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "model_output = cnn_layers(model_input)\n",
        "model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FmRWzHWPvCr5",
        "colab_type": "code",
        "outputId": "05cb43bc-c604-4173-fc26-247ad743c69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1293
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "images (InputLayer)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "x_train_out (Dense)          (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 843,658\n",
            "Trainable params: 843,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"629pt\" viewBox=\"0.00 0.00 229.00 629.00\" width=\"229pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-625 225,-625 225,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140397339618440 -->\n<g class=\"node\" id=\"node1\">\n<title>140397339618440</title>\n<polygon fill=\"none\" points=\"46.5,-584.5 46.5,-620.5 174.5,-620.5 174.5,-584.5 46.5,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-598.8\">images: InputLayer</text>\n</g>\n<!-- 140397339616424 -->\n<g class=\"node\" id=\"node2\">\n<title>140397339616424</title>\n<polygon fill=\"none\" points=\"44,-511.5 44,-547.5 177,-547.5 177,-511.5 44,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-525.8\">conv2d_1: Conv2D</text>\n</g>\n<!-- 140397339618440&#45;&gt;140397339616424 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140397339618440-&gt;140397339616424</title>\n<path d=\"M110.5,-584.4551C110.5,-576.3828 110.5,-566.6764 110.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-557.5903 110.5,-547.5904 107.0001,-557.5904 114.0001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397339617880 -->\n<g class=\"node\" id=\"node3\">\n<title>140397339617880</title>\n<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 221,-474.5 221,-438.5 0,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-452.8\">max_pooling2d_1: MaxPooling2D</text>\n</g>\n<!-- 140397339616424&#45;&gt;140397339617880 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140397339616424-&gt;140397339617880</title>\n<path d=\"M110.5,-511.4551C110.5,-503.3828 110.5,-493.6764 110.5,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-484.5903 110.5,-474.5904 107.0001,-484.5904 114.0001,-484.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397339618776 -->\n<g class=\"node\" id=\"node4\">\n<title>140397339618776</title>\n<polygon fill=\"none\" points=\"44,-365.5 44,-401.5 177,-401.5 177,-365.5 44,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-379.8\">conv2d_2: Conv2D</text>\n</g>\n<!-- 140397339617880&#45;&gt;140397339618776 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140397339617880-&gt;140397339618776</title>\n<path d=\"M110.5,-438.4551C110.5,-430.3828 110.5,-420.6764 110.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-411.5903 110.5,-401.5904 107.0001,-411.5904 114.0001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397234210576 -->\n<g class=\"node\" id=\"node5\">\n<title>140397234210576</title>\n<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 221,-328.5 221,-292.5 0,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-306.8\">max_pooling2d_2: MaxPooling2D</text>\n</g>\n<!-- 140397339618776&#45;&gt;140397234210576 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140397339618776-&gt;140397234210576</title>\n<path d=\"M110.5,-365.4551C110.5,-357.3828 110.5,-347.6764 110.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-338.5903 110.5,-328.5904 107.0001,-338.5904 114.0001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397234211304 -->\n<g class=\"node\" id=\"node6\">\n<title>140397234211304</title>\n<polygon fill=\"none\" points=\"54,-219.5 54,-255.5 167,-255.5 167,-219.5 54,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-233.8\">flatten_1: Flatten</text>\n</g>\n<!-- 140397234210576&#45;&gt;140397234211304 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140397234210576-&gt;140397234211304</title>\n<path d=\"M110.5,-292.4551C110.5,-284.3828 110.5,-274.6764 110.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-265.5903 110.5,-255.5904 107.0001,-265.5904 114.0001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397234329528 -->\n<g class=\"node\" id=\"node7\">\n<title>140397234329528</title>\n<polygon fill=\"none\" points=\"57,-146.5 57,-182.5 164,-182.5 164,-146.5 57,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140397234211304&#45;&gt;140397234329528 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140397234211304-&gt;140397234329528</title>\n<path d=\"M110.5,-219.4551C110.5,-211.3828 110.5,-201.6764 110.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-192.5903 110.5,-182.5904 107.0001,-192.5904 114.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397233919480 -->\n<g class=\"node\" id=\"node8\">\n<title>140397233919480</title>\n<polygon fill=\"none\" points=\"43.5,-73.5 43.5,-109.5 177.5,-109.5 177.5,-73.5 43.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-87.8\">dropout_1: Dropout</text>\n</g>\n<!-- 140397234329528&#45;&gt;140397233919480 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140397234329528-&gt;140397233919480</title>\n<path d=\"M110.5,-146.4551C110.5,-138.3828 110.5,-128.6764 110.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-119.5903 110.5,-109.5904 107.0001,-119.5904 114.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397233919760 -->\n<g class=\"node\" id=\"node9\">\n<title>140397233919760</title>\n<polygon fill=\"none\" points=\"47.5,-.5 47.5,-36.5 173.5,-36.5 173.5,-.5 47.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-14.8\">x_train_out: Dense</text>\n</g>\n<!-- 140397233919480&#45;&gt;140397233919760 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140397233919480-&gt;140397233919760</title>\n<path d=\"M110.5,-73.4551C110.5,-65.3828 110.5,-55.6764 110.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-46.5903 110.5,-36.5904 107.0001,-46.5904 114.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "pufcBwRWvCsD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training the model"
      ]
    },
    {
      "metadata": {
        "id": "XfXxwJpIvCsF",
        "colab_type": "code",
        "outputId": "220c920e-b7c2-4d48-c854-e915a4dc9395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks are passed to the model via the callbacks argument in fit, \n",
        "# which takes a list of callbacks. You can pass any number of callbacks.\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=1,\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath='my_model_callback.h5',\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks_list,\n",
        "                    # C.COULOMBE, in order to keep a test dataset\n",
        "                    # just create a validation dataset by splitting\n",
        "                    # the training dataset\n",
        "                    validation_split=0.2\n",
        "#                     validation_data=(x_test, y_test)\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/12\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.2664 - acc: 0.9168 - val_loss: 0.0859 - val_acc: 0.9728\n",
            "Epoch 2/12\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.0779 - acc: 0.9757 - val_loss: 0.0519 - val_acc: 0.9852\n",
            "Epoch 3/12\n",
            "48000/48000 [==============================] - 5s 105us/step - loss: 0.0540 - acc: 0.9829 - val_loss: 0.0418 - val_acc: 0.9879\n",
            "Epoch 4/12\n",
            "48000/48000 [==============================] - 5s 104us/step - loss: 0.0436 - acc: 0.9871 - val_loss: 0.0408 - val_acc: 0.9879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1WevHvzIvCsM",
        "colab_type": "code",
        "outputId": "fa1e1aaa-5f0e-4d55-fe20-6da6c808351e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# acc = history.history['acc']\n",
        "# val_acc = history.history['val_acc']\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "acc = history.history['acc'][1:]\n",
        "val_acc = history.history['val_acc'][1:]\n",
        "loss = history.history['loss'][1:]\n",
        "val_loss = history.history['val_loss'][1:]\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "epochs = range(1,len(acc)+1)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAG4CAYAAAD1zMvGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb0c669f828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAG4CAYAAAD1zMvGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb0c66a8a58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "YcecS39JvCsT",
        "colab_type": "code",
        "outputId": "3bce65e4-4e4b-4ae8-83de-a60214594d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.031877049914028614\n",
            "Test accuracy: 0.9893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tgOjOZwmvCsY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The ReduceLROnPlateau callback\n",
        "\n",
        "You can use this callback to reduce the learning rate when the validation loss has stopped improving. Reducing or increasing the learning rate in case of a loss plateau is is an effective strategy to get out of local minima during training. The following example uses the ReduceLROnPlateau callback:\n",
        "\n",
        "```Python\n",
        "callbacks_list = [ \n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        # Monitors the model’s validation loss\n",
        "        monitor='val_loss',\n",
        "        # Divides the learning rate by 10 when triggered\n",
        "        factor=0.1,\n",
        "        # The callback is triggered after the validation loss \n",
        "        # has stopped improving for 10 epochs.\n",
        "        patience=10,\n",
        "    ) \n",
        "] \n",
        "\n",
        "model.fit(x, y,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=(x_val, y_val)\n",
        ")  \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "JnYaRmjbvCsb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train a CNN model using the Functional API and the MNIST data\n",
        "### with ReduceLROnPlateau callback\n",
        "\n",
        "Inspired by: \n",
        "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
      ]
    },
    {
      "metadata": {
        "id": "RUrmEOYzvCsc",
        "colab_type": "code",
        "outputId": "5168ae6f-fc0a-49cf-bfeb-9ae6416fb396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "def cnn_layers(inputs):\n",
        "    x = layers.Conv2D(32, (3, 3),\n",
        "                      activation='relu', padding='valid')(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    predictions = layers.Dense(num_classes,\n",
        "                               activation='softmax',\n",
        "                               name='x_train_out')(x)\n",
        "    return predictions\n",
        "\n",
        "model_input = layers.Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "model_output = cnn_layers(model_input)\n",
        "model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "psDCyUVwvCsg",
        "colab_type": "code",
        "outputId": "add52be3-63f5-4004-c3f6-be176543424a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1285
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "images (InputLayer)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "x_train_out (Dense)          (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 843,658\n",
            "Trainable params: 843,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"629pt\" viewBox=\"0.00 0.00 229.00 629.00\" width=\"229pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-625 225,-625 225,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140397179234008 -->\n<g class=\"node\" id=\"node1\">\n<title>140397179234008</title>\n<polygon fill=\"none\" points=\"46.5,-584.5 46.5,-620.5 174.5,-620.5 174.5,-584.5 46.5,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-598.8\">images: InputLayer</text>\n</g>\n<!-- 140397219354496 -->\n<g class=\"node\" id=\"node2\">\n<title>140397219354496</title>\n<polygon fill=\"none\" points=\"44,-511.5 44,-547.5 177,-547.5 177,-511.5 44,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-525.8\">conv2d_5: Conv2D</text>\n</g>\n<!-- 140397179234008&#45;&gt;140397219354496 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140397179234008-&gt;140397219354496</title>\n<path d=\"M110.5,-584.4551C110.5,-576.3828 110.5,-566.6764 110.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-557.5903 110.5,-547.5904 107.0001,-557.5904 114.0001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179233784 -->\n<g class=\"node\" id=\"node3\">\n<title>140397179233784</title>\n<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 221,-474.5 221,-438.5 0,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-452.8\">max_pooling2d_5: MaxPooling2D</text>\n</g>\n<!-- 140397219354496&#45;&gt;140397179233784 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140397219354496-&gt;140397179233784</title>\n<path d=\"M110.5,-511.4551C110.5,-503.3828 110.5,-493.6764 110.5,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-484.5903 110.5,-474.5904 107.0001,-484.5904 114.0001,-484.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179234232 -->\n<g class=\"node\" id=\"node4\">\n<title>140397179234232</title>\n<polygon fill=\"none\" points=\"44,-365.5 44,-401.5 177,-401.5 177,-365.5 44,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-379.8\">conv2d_6: Conv2D</text>\n</g>\n<!-- 140397179233784&#45;&gt;140397179234232 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140397179233784-&gt;140397179234232</title>\n<path d=\"M110.5,-438.4551C110.5,-430.3828 110.5,-420.6764 110.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-411.5903 110.5,-401.5904 107.0001,-411.5904 114.0001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179405648 -->\n<g class=\"node\" id=\"node5\">\n<title>140397179405648</title>\n<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 221,-328.5 221,-292.5 0,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-306.8\">max_pooling2d_6: MaxPooling2D</text>\n</g>\n<!-- 140397179234232&#45;&gt;140397179405648 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140397179234232-&gt;140397179405648</title>\n<path d=\"M110.5,-365.4551C110.5,-357.3828 110.5,-347.6764 110.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-338.5903 110.5,-328.5904 107.0001,-338.5904 114.0001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179408168 -->\n<g class=\"node\" id=\"node6\">\n<title>140397179408168</title>\n<polygon fill=\"none\" points=\"54,-219.5 54,-255.5 167,-255.5 167,-219.5 54,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-233.8\">flatten_3: Flatten</text>\n</g>\n<!-- 140397179405648&#45;&gt;140397179408168 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140397179405648-&gt;140397179408168</title>\n<path d=\"M110.5,-292.4551C110.5,-284.3828 110.5,-274.6764 110.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-265.5903 110.5,-255.5904 107.0001,-265.5904 114.0001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179494640 -->\n<g class=\"node\" id=\"node7\">\n<title>140397179494640</title>\n<polygon fill=\"none\" points=\"57,-146.5 57,-182.5 164,-182.5 164,-146.5 57,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-160.8\">dense_3: Dense</text>\n</g>\n<!-- 140397179408168&#45;&gt;140397179494640 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140397179408168-&gt;140397179494640</title>\n<path d=\"M110.5,-219.4551C110.5,-211.3828 110.5,-201.6764 110.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-192.5903 110.5,-182.5904 107.0001,-192.5904 114.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397178920520 -->\n<g class=\"node\" id=\"node8\">\n<title>140397178920520</title>\n<polygon fill=\"none\" points=\"43.5,-73.5 43.5,-109.5 177.5,-109.5 177.5,-73.5 43.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-87.8\">dropout_3: Dropout</text>\n</g>\n<!-- 140397179494640&#45;&gt;140397178920520 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140397179494640-&gt;140397178920520</title>\n<path d=\"M110.5,-146.4551C110.5,-138.3828 110.5,-128.6764 110.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-119.5903 110.5,-109.5904 107.0001,-119.5904 114.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397178919680 -->\n<g class=\"node\" id=\"node9\">\n<title>140397178919680</title>\n<polygon fill=\"none\" points=\"47.5,-.5 47.5,-36.5 173.5,-36.5 173.5,-.5 47.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-14.8\">x_train_out: Dense</text>\n</g>\n<!-- 140397178920520&#45;&gt;140397178919680 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140397178920520-&gt;140397178919680</title>\n<path d=\"M110.5,-73.4551C110.5,-65.3828 110.5,-55.6764 110.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.0001,-46.5903 110.5,-36.5904 107.0001,-46.5904 114.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "zFxFe1KlvCsl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training the model"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "li174WegvCsl",
        "colab_type": "code",
        "outputId": "659b880d-db10-4d77-ddea-ac62bd7e6133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "# Callbacks are passed to the model via the callbacks argument in fit, \n",
        "# which takes a list of callbacks. You can pass any number of callbacks.\n",
        "callbacks_list = [ \n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        # Monitors the model’s validation loss\n",
        "        monitor='val_loss',\n",
        "        # Divides the learning rate by 10 when triggered\n",
        "        factor=0.1,\n",
        "        # The callback is triggered after the validation loss \n",
        "        # has stopped improving for 1 epochs.\n",
        "        patience=1,\n",
        "        verbose=1\n",
        "    ) \n",
        "] \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    # C.COULOMBE More epochs in order to \n",
        "                    # get more learning rate changes\n",
        "                    epochs=15,\n",
        "                    batch_size=32,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks_list,\n",
        "                    # C.COULOMBE, in order to keep a test dataset\n",
        "                    # just create a validation dataset by splitting\n",
        "                    # the training dataset\n",
        "                    validation_split=0.2\n",
        "#                     validation_data=(x_test, y_test)\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/15\n",
            "48000/48000 [==============================] - 17s 347us/step - loss: 0.1576 - acc: 0.9495 - val_loss: 0.0540 - val_acc: 0.9839\n",
            "Epoch 2/15\n",
            "48000/48000 [==============================] - 16s 337us/step - loss: 0.0547 - acc: 0.9831 - val_loss: 0.0451 - val_acc: 0.9868\n",
            "Epoch 3/15\n",
            "48000/48000 [==============================] - 16s 339us/step - loss: 0.0403 - acc: 0.9879 - val_loss: 0.0398 - val_acc: 0.9881\n",
            "Epoch 4/15\n",
            "48000/48000 [==============================] - 16s 338us/step - loss: 0.0312 - acc: 0.9903 - val_loss: 0.0383 - val_acc: 0.9891\n",
            "Epoch 5/15\n",
            "48000/48000 [==============================] - 16s 341us/step - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0342 - val_acc: 0.9904\n",
            "Epoch 6/15\n",
            "48000/48000 [==============================] - 16s 339us/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0337 - val_acc: 0.9910\n",
            "Epoch 7/15\n",
            "48000/48000 [==============================] - 16s 333us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0339 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.1.\n",
            "Epoch 8/15\n",
            "48000/48000 [==============================] - 16s 338us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0289 - val_acc: 0.9922\n",
            "Epoch 9/15\n",
            "48000/48000 [==============================] - 16s 338us/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0288 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 10/15\n",
            "48000/48000 [==============================] - 16s 328us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0289 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 11/15\n",
            "48000/48000 [==============================] - 16s 328us/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0289 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "Epoch 12/15\n",
            "48000/48000 [==============================] - 16s 332us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.0289 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "Epoch 13/15\n",
            "48000/48000 [==============================] - 16s 341us/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0289 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "Epoch 14/15\n",
            "48000/48000 [==============================] - 16s 340us/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0289 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
            "Epoch 15/15\n",
            "48000/48000 [==============================] - 16s 339us/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0289 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jznAtu8uvCsq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc'][1:]\n",
        "val_acc = history.history['val_acc'][1:]\n",
        "loss = history.history['loss'][1:]\n",
        "val_loss = history.history['val_loss'][1:]\n",
        "lr = history.history['lr'][1:]\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "epochs = range(1,len(acc)+1)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(epochs, lr, 'b', label='Learning Rate')\n",
        "plt.title('Learning Rate')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4pVoGPWEvCsv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqUcqsB8vCsy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Writing your own callback (先跳過, 大家短期內還不會用到)\n",
        "\n",
        "If you need to take a specific action during training that isn’t covered by one of the built-in callbacks, you can write your own callback. Callbacks are implemented by subclassing the class `keras.callbacks.Callback`. You can then implement any number of the following transparently named methods, which are called at various points during training: \n",
        "\n",
        "```Python\n",
        "# Called at the start of every epoch\n",
        "on_epoch_begin\n",
        "# Called at the end of every epoch\n",
        "on_epoch_end\n",
        "# Called right before processing each batch\n",
        "on_batch_begin\n",
        "# Called right after processing each batch\n",
        "on_batch_end\n",
        "# Called at the start of training \n",
        "on_train_begin\n",
        "# Called at the end of training\n",
        "on_train_end  \n",
        "```\n",
        "\n",
        "These methods all are called with a logs argument, which is a dictionary containing information about the previous batch, epoch, or training run: training and validation metrics, and so on. Additionally, the callback has access to the following attributes: \n",
        "\n",
        "* `self.model` — The model instance from which the callback is being called \n",
        "* `self.validation_data` — The value of what was passed to fit as validation data \n",
        "\n",
        "Here’s a simple example of a custom callback that saves to disk (as Numpy arrays) the activations (weights ?) of every layer of the model at the end of every epoch, computed on the first sample of the validation set: \n",
        "\n",
        "```Python\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "\n",
        "class ActivationLogger(keras.callbacks.Callback):\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Called by the parent model before training, \n",
        "        # to inform the callback of what model will be calling it\n",
        "        self.model = model\n",
        "        layer_outputs = [layer.output for layer in model.layers]\n",
        "        # Model instance that returns the activations of every layer\n",
        "        self.activations_model = keras.models.Model(model.input,layer_outputs)\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if self.validation_data is None:\n",
        "            raise RuntimeError('Requires validation_data.')\n",
        "        # Obtains the first input sample of the validation data\n",
        "        validation_sample = self.validation_data[0][0:1]\n",
        "        activations = self.activations_model.predict(validation_sample)\n",
        "        # Saves arrays to disk\n",
        "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'wb')\n",
        "        np.savez(f,*activations)\n",
        "        f.close() \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "M2aCGBg0vCsz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is all you need to know about callbacks—the rest is technical details, which you can easily look up. Now you’re equipped to perform any sort of logging or preprogrammed intervention on a Keras model during training."
      ]
    },
    {
      "metadata": {
        "id": "r3dnK4h7vCs1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train a CNN model using the Functional API and the MNIST data\n",
        "### with custom ActivationLogger callback\n",
        "\n",
        "Inspired by: \n",
        "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
      ]
    },
    {
      "metadata": {
        "id": "x7Bmx8GUvCs2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "def cnn_layers(inputs):\n",
        "    x = layers.Conv2D(32, (3, 3),\n",
        "                      activation='relu', padding='valid')(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    predictions = layers.Dense(num_classes,\n",
        "                               activation='softmax',\n",
        "                               name='x_train_out')(x)\n",
        "    return predictions\n",
        "\n",
        "model_input = layers.Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "model_output = cnn_layers(model_input)\n",
        "model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SlgY29u1vCs6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvIDzWjfvCs_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training the model"
      ]
    },
    {
      "metadata": {
        "id": "A4GMA1SSvCtA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ActivationLogger(keras.callbacks.Callback):\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Called by the parent model before training, \n",
        "        # to inform the callback of what model will be calling it\n",
        "        self.model = model\n",
        "        # Here the model has 9 layers\n",
        "        layer_outputs = [layer.output for layer in model.layers]\n",
        "        # Model instance that returns the activations of every layer\n",
        "        #  self.activations_model = keras.models.Model(inputs=model.inputs[0],outputs=layer_outputs)\n",
        "        self.activations_model = keras.models.Model(model.input,layer_outputs)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if self.validation_data is None:\n",
        "            raise RuntimeError('Requires validation_data.')\n",
        "        # Obtains the first input sample of the validation data\n",
        "        validation_sample_x = self.validation_data[0][0:1]\n",
        "        validation_sample_y = self.validation_data[1]\n",
        "        # predict(self, x, batch_size=None, verbose=0, steps=None)\n",
        "        # x: The input data, as a Numpy array (or list of Numpy arrays if the model has multiple outputs).\n",
        "        activations = self.activations_model.predict(validation_sample_x)\n",
        "        # Saves arrays to disk\n",
        "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'wb')\n",
        "        # Since we have several arrays of different dimensions, we expand the arguments:\n",
        "        np.savez(f,*activations)\n",
        "        f.close()\n",
        "        \n",
        "# Callbacks are passed to the model via the callbacks argument in fit, \n",
        "# which takes a list of callbacks. You can pass any number of callbacks.\n",
        "callbacks_list = [ \n",
        "    ActivationLogger() \n",
        "] \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=12,\n",
        "                    batch_size=batch_size,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks_list,\n",
        "                    # C.COULOMBE, in order to keep a test dataset\n",
        "                    # just create a validation dataset by splitting\n",
        "                    # the training dataset\n",
        "                    validation_split=0.2\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7yX5gbEBvCtG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Recover the layers activation weights"
      ]
    },
    {
      "metadata": {
        "id": "OVdBeKMJvCtH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For example, recover the arrays of weights for the last epoch 12 => 11 \n",
        "# and the last layer 9 => 8\n",
        "last_epoch_activations = np.load('activations_at_epoch_11.npz')\n",
        "activations = [last_epoch_activations[key] for key in last_epoch_activations]\n",
        "print(len(activations))\n",
        "print(activations[8])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "XsDmFBSivCtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is all you need to know about callbacks—the rest is technical details, which you can easily look up. Now you’re equipped to perform any sort of logging or preprogrammed intervention on a Keras model during training."
      ]
    },
    {
      "metadata": {
        "id": "C5XwW1-uvCtL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2.2. Introduction to TensorBoard: the TensorFlow visualization framework \n",
        "\n",
        "To do good research or develop good models, you need rich, frequent feedback about what’s going on inside your models during your experiments. That’s the point of running experiments: to get information about how well a model performs—as much information as possible. Making progress is an iterative process, or loop: you start with an idea and express it as an experiment, attempting to validate or invalidate your idea. You run this experiment and process the information it generates. This inspires your next idea. The more iterations of this loop you’re able to run, the more refined and powerful your ideas become. Keras helps you go from idea to experiment in the least possible time, and fast GPUs can help you get from experiment to result as quickly as possible. \n",
        "\n",
        "But what about processing the experiment results? That’s where TensorBoard comes in.\n",
        "\n",
        "This section introduces TensorBoard, a browser-based visualization tool that comes packaged with TensorFlow. Note that it’s only available for Keras models when you’re using Keras with the TensorFlow backend. \n",
        "\n",
        "The key purpose of TensorBoard is to help you visually monitor everything that goes on inside your model during training. If you’re monitoring more information than just the model’s final loss, you can develop a clearer vision of what the model does and doesn’t do, and you can make progress more quickly. TensorBoard gives you access to several neat features, all in your browser: \n",
        "\n",
        "* Visually monitoring metrics during training Visualizing your model architecture\n",
        "* Visualizing your model architecture\n",
        "* Visualizing histograms of activations and gradients \n",
        "* Exploring embeddings in 3D \n",
        "\n",
        "Let’s demonstrate these features on a simple example. You’ll train a 1D convnet on the IMDB sentiment-analysis task. \n",
        "\n",
        "The model is similar to the one you saw in the last section of chapter 6. You’ll consider only the top 2,000 words in the IMDB vocabulary, to make visualizing word embeddings more tractable. \n",
        "\n",
        "#### IMDB Text-classification model to use with TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "ArAK6lrGvCtL",
        "colab_type": "code",
        "outputId": "7549f559-1242-428a-d30b-30410f665df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import keras \n",
        "from keras import layers \n",
        "from keras.datasets import imdb \n",
        "from keras.preprocessing import sequence \n",
        "import keras.backend as K\n",
        "K.clear_session()\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 2000\n",
        "# Cuts off texts after this number of words (among max_features most common words)\n",
        "max_len = 500\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) \n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len) \n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len) \n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(max_features,128,\n",
        "                           input_length=max_len,\n",
        "                           name='embed'))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kpGdx8EovCtN",
        "colab_type": "code",
        "outputId": "450e3fc9-a04d-4819-de0d-3bc3c769470f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed (Embedding)            (None, 500, 128)          256000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 291,937\n",
            "Trainable params: 291,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"483pt\" viewBox=\"0.00 0.00 312.00 483.00\" width=\"312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 308,-479 308,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140397177584832 -->\n<g class=\"node\" id=\"node1\">\n<title>140397177584832</title>\n<polygon fill=\"none\" points=\"87,-365.5 87,-401.5 217,-401.5 217,-365.5 87,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-379.8\">embed: Embedding</text>\n</g>\n<!-- 140397183418208 -->\n<g class=\"node\" id=\"node2\">\n<title>140397183418208</title>\n<polygon fill=\"none\" points=\"85.5,-292.5 85.5,-328.5 218.5,-328.5 218.5,-292.5 85.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-306.8\">conv1d_1: Conv1D</text>\n</g>\n<!-- 140397177584832&#45;&gt;140397183418208 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140397177584832-&gt;140397183418208</title>\n<path d=\"M152,-365.4551C152,-357.3828 152,-347.6764 152,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-338.5903 152,-328.5904 148.5001,-338.5904 155.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397218972056 -->\n<g class=\"node\" id=\"node3\">\n<title>140397218972056</title>\n<polygon fill=\"none\" points=\"41.5,-219.5 41.5,-255.5 262.5,-255.5 262.5,-219.5 41.5,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-233.8\">max_pooling1d_1: MaxPooling1D</text>\n</g>\n<!-- 140397183418208&#45;&gt;140397218972056 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140397183418208-&gt;140397218972056</title>\n<path d=\"M152,-292.4551C152,-284.3828 152,-274.6764 152,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-265.5903 152,-255.5904 148.5001,-265.5904 155.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397228813560 -->\n<g class=\"node\" id=\"node4\">\n<title>140397228813560</title>\n<polygon fill=\"none\" points=\"85.5,-146.5 85.5,-182.5 218.5,-182.5 218.5,-146.5 85.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-160.8\">conv1d_2: Conv1D</text>\n</g>\n<!-- 140397218972056&#45;&gt;140397228813560 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140397218972056-&gt;140397228813560</title>\n<path d=\"M152,-219.4551C152,-211.3828 152,-201.6764 152,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-192.5903 152,-182.5904 148.5001,-192.5904 155.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179012992 -->\n<g class=\"node\" id=\"node5\">\n<title>140397179012992</title>\n<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 304,-109.5 304,-73.5 0,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-87.8\">global_max_pooling1d_1: GlobalMaxPooling1D</text>\n</g>\n<!-- 140397228813560&#45;&gt;140397179012992 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140397228813560-&gt;140397179012992</title>\n<path d=\"M152,-146.4551C152,-138.3828 152,-128.6764 152,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-119.5903 152,-109.5904 148.5001,-119.5904 155.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397218621424 -->\n<g class=\"node\" id=\"node6\">\n<title>140397218621424</title>\n<polygon fill=\"none\" points=\"98.5,-.5 98.5,-36.5 205.5,-36.5 205.5,-.5 98.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-14.8\">dense_1: Dense</text>\n</g>\n<!-- 140397179012992&#45;&gt;140397218621424 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140397179012992-&gt;140397218621424</title>\n<path d=\"M152,-73.4551C152,-65.3828 152,-55.6764 152,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-46.5903 152,-36.5904 148.5001,-46.5904 155.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397183230808 -->\n<g class=\"node\" id=\"node7\">\n<title>140397183230808</title>\n<polygon fill=\"none\" points=\"87.5,-438.5 87.5,-474.5 216.5,-474.5 216.5,-438.5 87.5,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-452.8\">140397183230808</text>\n</g>\n<!-- 140397183230808&#45;&gt;140397177584832 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140397183230808-&gt;140397177584832</title>\n<path d=\"M152,-438.4551C152,-430.3828 152,-420.6764 152,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-411.5903 152,-401.5904 148.5001,-411.5904 155.5001,-411.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "vVGfGRCKk26K",
        "colab_type": "code",
        "outputId": "e692a782-0d3b-4dd7-cf22-799a3da421c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "MQvpv5afvCtP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kxjz3rLOvCtV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before you start using TensorBoard, you need to create a directory where you’ll store the log files it generates.\n",
        "\n",
        "Creating a directory for TensorBoard log files\n",
        "\n",
        "    > mkdir my_log_dir\n",
        "    \n",
        "Let’s launch the training with a TensorBoard callback instance. This callback will write log events to disk at the specified location.\n",
        "\n",
        "#### Training the model with a TensorBoard callback"
      ]
    },
    {
      "metadata": {
        "id": "5lVy_E2_qNdQ",
        "colab_type": "code",
        "outputId": "5fccddff-2436-4c41-9b7f-c0745fda819e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov 16 05:43:06 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    57W / 149W |    331MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "yoszxAwivCtW",
        "colab_type": "code",
        "outputId": "364261f4-8c53-4c46-ab6a-d6a8baa06dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "  \n",
        "# Tensorboard\n",
        "\n",
        "#安裝tensorboard colab\n",
        "!pip install tensorboardcolab\n",
        "import numpy\n",
        "from tensorboardcolab import *\n",
        "tbc=TensorBoardColab()\n",
        "\n",
        "callbacks = [\n",
        "    TensorBoardColabCallback(tbc,histogram_freq=1,embeddings_freq=1, embeddings_layer_names = None, embeddings_data=x_train[0:100])\n",
        "    \n",
        "] \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=3,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardcolab\n",
            "  Downloading https://files.pythonhosted.org/packages/73/3d/eaf745e162e471c5bb2737a407d8626fb8684a88cf085045456aeb841d3c/tensorboardcolab-0.0.19.tar.gz\n",
            "Building wheels for collected packages: tensorboardcolab\n",
            "  Running setup.py bdist_wheel for tensorboardcolab ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ab/74/02/cda602d1dc28b2f12eab313c49b9bfa14d6371326bc2590e06\n",
            "Successfully built tensorboardcolab\n",
            "Installing collected packages: tensorboardcolab\n",
            "Successfully installed tensorboardcolab-0.0.19\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://7ede96b8.ngrok.io\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "20000/20000 [==============================] - 5s 228us/step - loss: 0.5853 - acc: 0.7074 - val_loss: 0.4344 - val_acc: 0.8296\n",
            "Epoch 2/3\n",
            "20000/20000 [==============================] - 4s 203us/step - loss: 0.4524 - acc: 0.7820 - val_loss: 0.7156 - val_acc: 0.7102\n",
            "Epoch 3/3\n",
            "20000/20000 [==============================] - 4s 197us/step - loss: 0.3904 - acc: 0.7394 - val_loss: 0.7184 - val_acc: 0.6624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0NSQiKQnvCtb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At this point, you can launch the TensorBoard server from the command line, instructing it to read the logs the callback is currently writing.\n",
        "\n",
        "The tensorboard utility should have been automatically installed on your machine the moment you installed TensorFlow (for example, via pip): \n",
        "\n",
        "    > cd <path-to-the-notebook-directory>\n",
        "    > tensorboard --logdir=my_log_dir \n",
        "\n",
        "You can then browse to http://localhost:6006 and look at your model training (see figure 7.10). In addition to live graphs of the training and validation metrics,  \n",
        "\n",
        "<center>Figure 7.10. TensorBoard: metrics monitoring</center>\n",
        "<img src=\"https://cdn-images-1.medium.com/max/750/1*ik2dzj_Z0GvOG6uETvQhJw.png\" width=600>\n",
        "\n",
        "you get access to the Histograms tab, where you can find pretty visualizations of histograms of activation values taken by your layers (see figure 7.11).\n",
        "\n",
        "<center>Figure 7.11. TensorBoard: activation histograms</center>\n",
        "<img src=\"https://cdn-images-1.medium.com/max/750/1*rKv6i1nwC1m4CMSV3BZAhA.png\" width=600>\n",
        "\n",
        "The Embeddings tab gives you a way to inspect the embedding locations and spatial relationships of the 2 000 (or 10,000) words in the input vocabulary, as learned by the initial Embedding layer. Because the embedding space is 128-dimensional, TensorBoard automatically reduces it to 2D or 3D using a dimensionality-reduction algorithm of your choice: either principal component analysis (PCA) or t-distributed stochastic neighbor embedding (t-SNE). \n",
        "\n",
        "In figure 7.12 below, in the point cloud, you can clearly see two clusters: words with a positive connotation and words with a negative connotation. The visualization makes it immediately obvious that embeddings trained jointly with a specific objective result in models that are completely specific to the underlying task—that’s the reason using pretrained generic word embeddings is rarely a good idea.\n",
        "\n",
        "<center>Figure 7.12.a TensorBoard: interactive 3D word-embedding visualization - PCA</center>\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1500/1*vJ1uwS2fYmW8B74Xdq3fJQ.png\" width=600>\n",
        "\n",
        "<center>Figure 7.12.b TensorBoard: interactive 3D word-embedding visualization - T-SNE</center>\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1500/1*y87HCKKBsdRaDy-y_oE4jQ.png\" width=600>\n",
        "\n",
        "The Graphs tab shows an interactive visualization of the graph of low-level TensorFlow operations underlying your Keras model (see figure 7.13). As you can see, there’s a lot more going on than you would expect. The model you just built may look simple when defined in Keras—a small stack of basic layers—but under the hood, you need to construct a fairly complex graph structure to make it work. A lot of it is related to the gradient-descent process. This complexity differential between what you see and what you’re manipulating is the key motivation for using Keras as your way of building models, instead of working with raw TensorFlow to define everything from scratch. Keras makes your workflow dramatically simpler. Figure 7.13. TensorBoard: TensorFlow graph visualization\n",
        "\n",
        "<center>Figure 7.13. TensorBoard: TensorFlow graph visualization</center>\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1500/1*8yNvoDNaXF-g4l5nP1cXmg.png\" width=600>\n",
        "\n",
        "Note that Keras also provides another, cleaner way to plot models as graphs of layers rather than graphs of TensorFlow operations: the utility keras.utils.plot_model. Using it requires that you’ve installed the Python pydot and pydot-ng libraries as well as the graphviz library. Let’s take a quick look: from keras.utils import plot_model plot_model(model, to_file='model.png') This creates the PNG image shown in figure 7.14."
      ]
    },
    {
      "metadata": {
        "id": "RDps-x_mvCtc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### A model plot as a graph of layers, generated with plot_model"
      ]
    },
    {
      "metadata": {
        "id": "sfWr2bMkvCte",
        "colab_type": "code",
        "outputId": "022bd272-4e0e-4e73-c740-fb65e58c6327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model \n",
        "plot_model(model, to_file='model.png')\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"483pt\" viewBox=\"0.00 0.00 312.00 483.00\" width=\"312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 308,-479 308,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140397177584832 -->\n<g class=\"node\" id=\"node1\">\n<title>140397177584832</title>\n<polygon fill=\"none\" points=\"87,-365.5 87,-401.5 217,-401.5 217,-365.5 87,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-379.8\">embed: Embedding</text>\n</g>\n<!-- 140397183418208 -->\n<g class=\"node\" id=\"node2\">\n<title>140397183418208</title>\n<polygon fill=\"none\" points=\"85.5,-292.5 85.5,-328.5 218.5,-328.5 218.5,-292.5 85.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-306.8\">conv1d_1: Conv1D</text>\n</g>\n<!-- 140397177584832&#45;&gt;140397183418208 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140397177584832-&gt;140397183418208</title>\n<path d=\"M152,-365.4551C152,-357.3828 152,-347.6764 152,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-338.5903 152,-328.5904 148.5001,-338.5904 155.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397218972056 -->\n<g class=\"node\" id=\"node3\">\n<title>140397218972056</title>\n<polygon fill=\"none\" points=\"41.5,-219.5 41.5,-255.5 262.5,-255.5 262.5,-219.5 41.5,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-233.8\">max_pooling1d_1: MaxPooling1D</text>\n</g>\n<!-- 140397183418208&#45;&gt;140397218972056 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140397183418208-&gt;140397218972056</title>\n<path d=\"M152,-292.4551C152,-284.3828 152,-274.6764 152,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-265.5903 152,-255.5904 148.5001,-265.5904 155.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397228813560 -->\n<g class=\"node\" id=\"node4\">\n<title>140397228813560</title>\n<polygon fill=\"none\" points=\"85.5,-146.5 85.5,-182.5 218.5,-182.5 218.5,-146.5 85.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-160.8\">conv1d_2: Conv1D</text>\n</g>\n<!-- 140397218972056&#45;&gt;140397228813560 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140397218972056-&gt;140397228813560</title>\n<path d=\"M152,-219.4551C152,-211.3828 152,-201.6764 152,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-192.5903 152,-182.5904 148.5001,-192.5904 155.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179012992 -->\n<g class=\"node\" id=\"node5\">\n<title>140397179012992</title>\n<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 304,-109.5 304,-73.5 0,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-87.8\">global_max_pooling1d_1: GlobalMaxPooling1D</text>\n</g>\n<!-- 140397228813560&#45;&gt;140397179012992 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140397228813560-&gt;140397179012992</title>\n<path d=\"M152,-146.4551C152,-138.3828 152,-128.6764 152,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-119.5903 152,-109.5904 148.5001,-119.5904 155.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397218621424 -->\n<g class=\"node\" id=\"node6\">\n<title>140397218621424</title>\n<polygon fill=\"none\" points=\"98.5,-.5 98.5,-36.5 205.5,-36.5 205.5,-.5 98.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-14.8\">dense_1: Dense</text>\n</g>\n<!-- 140397179012992&#45;&gt;140397218621424 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140397179012992-&gt;140397218621424</title>\n<path d=\"M152,-73.4551C152,-65.3828 152,-55.6764 152,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-46.5903 152,-36.5904 148.5001,-46.5904 155.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140397183230808 -->\n<g class=\"node\" id=\"node7\">\n<title>140397183230808</title>\n<polygon fill=\"none\" points=\"87.5,-438.5 87.5,-474.5 216.5,-474.5 216.5,-438.5 87.5,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-452.8\">140397183230808</text>\n</g>\n<!-- 140397183230808&#45;&gt;140397177584832 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140397183230808-&gt;140397177584832</title>\n<path d=\"M152,-438.4551C152,-430.3828 152,-420.6764 152,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.5001,-411.5903 152,-401.5904 148.5001,-411.5904 155.5001,-411.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "M-q8GpIuvCti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### A model plot as a graph of layers with shape information"
      ]
    },
    {
      "metadata": {
        "id": "8YLIXjBUvCtk",
        "colab_type": "code",
        "outputId": "06709c12-1383-4f5f-cba3-3430dacd649a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model \n",
        "plot_model(model, to_file='model.png')\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"543pt\" viewBox=\"0.00 0.00 472.00 543.00\" width=\"472pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 539)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-539 468,-539 468,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140397177584832 -->\n<g class=\"node\" id=\"node1\">\n<title>140397177584832</title>\n<polygon fill=\"none\" points=\"79.5,-415.5 79.5,-461.5 384.5,-461.5 384.5,-415.5 79.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144.5\" y=\"-434.8\">embed: Embedding</text>\n<polyline fill=\"none\" points=\"209.5,-415.5 209.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-438.5 267.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-415.5 267.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326\" y=\"-446.3\">(None, 500)</text>\n<polyline fill=\"none\" points=\"267.5,-438.5 384.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326\" y=\"-423.3\">(None, 500, 128)</text>\n</g>\n<!-- 140397183418208 -->\n<g class=\"node\" id=\"node2\">\n<title>140397183418208</title>\n<polygon fill=\"none\" points=\"78,-332.5 78,-378.5 386,-378.5 386,-332.5 78,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144.5\" y=\"-351.8\">conv1d_1: Conv1D</text>\n<polyline fill=\"none\" points=\"211,-332.5 211,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"211,-355.5 269,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"269,-332.5 269,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.5\" y=\"-363.3\">(None, 500, 128)</text>\n<polyline fill=\"none\" points=\"269,-355.5 386,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.5\" y=\"-340.3\">(None, 494, 32)</text>\n</g>\n<!-- 140397177584832&#45;&gt;140397183418208 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140397177584832-&gt;140397183418208</title>\n<path d=\"M232,-415.3799C232,-407.1745 232,-397.7679 232,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"235.5001,-388.784 232,-378.784 228.5001,-388.784 235.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140397218972056 -->\n<g class=\"node\" id=\"node3\">\n<title>140397218972056</title>\n<polygon fill=\"none\" points=\"37.5,-249.5 37.5,-295.5 426.5,-295.5 426.5,-249.5 37.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148\" y=\"-268.8\">max_pooling1d_1: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"258.5,-249.5 258.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"258.5,-272.5 316.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"316.5,-249.5 316.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371.5\" y=\"-280.3\">(None, 494, 32)</text>\n<polyline fill=\"none\" points=\"316.5,-272.5 426.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371.5\" y=\"-257.3\">(None, 98, 32)</text>\n</g>\n<!-- 140397183418208&#45;&gt;140397218972056 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140397183418208-&gt;140397218972056</title>\n<path d=\"M232,-332.3799C232,-324.1745 232,-314.7679 232,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"235.5001,-305.784 232,-295.784 228.5001,-305.784 235.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140397228813560 -->\n<g class=\"node\" id=\"node4\">\n<title>140397228813560</title>\n<polygon fill=\"none\" points=\"85.5,-166.5 85.5,-212.5 378.5,-212.5 378.5,-166.5 85.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-185.8\">conv1d_2: Conv1D</text>\n<polyline fill=\"none\" points=\"218.5,-166.5 218.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"218.5,-189.5 276.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"276.5,-166.5 276.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.5\" y=\"-197.3\">(None, 98, 32)</text>\n<polyline fill=\"none\" points=\"276.5,-189.5 378.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.5\" y=\"-174.3\">(None, 92, 32)</text>\n</g>\n<!-- 140397218972056&#45;&gt;140397228813560 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140397218972056-&gt;140397228813560</title>\n<path d=\"M232,-249.3799C232,-241.1745 232,-231.7679 232,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"235.5001,-222.784 232,-212.784 228.5001,-222.784 235.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140397179012992 -->\n<g class=\"node\" id=\"node5\">\n<title>140397179012992</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 464,-129.5 464,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-102.8\">global_max_pooling1d_1: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"304,-83.5 304,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"304,-106.5 362,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"362,-83.5 362,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413\" y=\"-114.3\">(None, 92, 32)</text>\n<polyline fill=\"none\" points=\"362,-106.5 464,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140397228813560&#45;&gt;140397179012992 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140397228813560-&gt;140397179012992</title>\n<path d=\"M232,-166.3799C232,-158.1745 232,-148.7679 232,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"235.5001,-139.784 232,-129.784 228.5001,-139.784 235.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140397218621424 -->\n<g class=\"node\" id=\"node6\">\n<title>140397218621424</title>\n<polygon fill=\"none\" points=\"109.5,-.5 109.5,-46.5 354.5,-46.5 354.5,-.5 109.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"216.5,-.5 216.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"216.5,-23.5 274.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"274.5,-.5 274.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"274.5,-23.5 354.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140397179012992&#45;&gt;140397218621424 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140397179012992-&gt;140397218621424</title>\n<path d=\"M232,-83.3799C232,-75.1745 232,-65.7679 232,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"235.5001,-56.784 232,-46.784 228.5001,-56.784 235.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140397183230808 -->\n<g class=\"node\" id=\"node7\">\n<title>140397183230808</title>\n<polygon fill=\"none\" points=\"167.5,-498.5 167.5,-534.5 296.5,-534.5 296.5,-498.5 167.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-512.8\">140397183230808</text>\n</g>\n<!-- 140397183230808&#45;&gt;140397177584832 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140397183230808-&gt;140397177584832</title>\n<path d=\"M232,-498.4092C232,-490.4308 232,-480.795 232,-471.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"235.5001,-471.5333 232,-461.5333 228.5001,-471.5334 235.5001,-471.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "SI4nJ9HMIdsY",
        "colab_type": "code",
        "outputId": "cd35886a-c0b0-44de-e08c-be1c5e2d9bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"imdb_cnn_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"imdb_cnn_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}