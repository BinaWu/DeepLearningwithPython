{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.1-Keras_functional_API.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "n5fjCj6d-2i0",
        "fapYi3at-2jb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eathon/DeepLearningwithPython/blob/master/7_1_Keras_functional_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vju1DifR-2g8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Companion Notebook - 7.1 Keras Functional API\n",
        "## Chap 7 «Advanced Deep-learning best practices»\n",
        "## «Deep Learning with Python» book by François Chollet\n",
        "\n",
        "This notebook contains the code samples found in Chapter 7 of «Deep Learning with Python». Note that the original text features far more content, in particular further explanations and figures. \n",
        "\n",
        "修改與補充Claude COULOMBE的github :https://github.com/ClaudeCoulombe/deep-learning-with-python-notebooks (by Claude COULOMBE - PhD candidate - TÉLUQ / UQAM - Montréal.)"
      ]
    },
    {
      "metadata": {
        "id": "DASRlwQI-2hA",
        "colab_type": "code",
        "outputId": "b9f44346-7fa6-420b-833d-27d8e5b965b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# sudo pip3 install --ignore-installed --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as KTF\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "KTF.set_session(session)\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)\n",
        "# To ignore keep_dims warning\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.4\n",
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OgFh1JBX6z7N",
        "colab_type": "code",
        "outputId": "edbfa5cc-95f6-4a39-b6c9-978bb7fc269b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3565
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz \n",
        "!apt-get install graphviz \n",
        "# Install pydot to visualize the network structure\n",
        "!pip install pydot\n",
        "!pip install pydot-ng\n",
        "\n",
        "#After fininishing the installation, you have to restart the colab runtime!!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting graphviz\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Installing collected packages: graphviz\n",
            "Successfully installed graphviz-0.10.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fontconfig libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "Suggested packages:\n",
            "  gsfonts graphviz-doc libgd-tools\n",
            "The following NEW packages will be installed:\n",
            "  fontconfig graphviz libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "0 upgraded, 30 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 4,154 kB of archives.\n",
            "After this operation, 16.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libann0 amd64 1.1.2+doc-6 [24.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcdt5 amd64 2.40.1-2 [19.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcgraph6 amd64 2.40.1-2 [40.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtiff5 amd64 4.0.9-5 [152 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebp6 amd64 0.6.1-2 [185 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.2 [119 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-0 amd64 0.34.0-2 [229 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-render0 amd64 1.13-1 [14.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shm0 amd64 1.13-1 [5,572 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo2 amd64 1.15.10-2 [580 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl7 amd64 2.4.6-2 [38.8 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpathplan4 amd64 2.40.1-2 [22.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6 amd64 2.40.1-2 [601 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvpr2 amd64 2.40.1-2 [169 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblab-gamut1 amd64 2.40.1-2 [178 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 graphviz amd64 2.40.1-2 [601 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
            "Fetched 4,154 kB in 0s (26.2 MB/s)\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libann0.\n",
            "Preparing to unpack .../01-libann0_1.1.2+doc-6_amd64.deb ...\n",
            "Unpacking libann0 (1.1.2+doc-6) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.40.1-2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../04-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../05-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../06-libwebp6_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../07-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../08-libgd3_2.2.5-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Selecting previously unselected package libgts-0.7-5:amd64.\n",
            "Preparing to unpack .../09-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../10-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../11-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../12-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../13-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../14-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../15-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../16-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../17-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../18-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.40.1-2) ...\n",
            "Selecting previously unselected package liblab-gamut1.\n",
            "Preparing to unpack .../24-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
            "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../25-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../26-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../27-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../28-graphviz_2.40.1-2_amd64.deb ...\n",
            "Unpacking graphviz (2.40.1-2) ...\n",
            "Selecting previously unselected package libgts-bin.\n",
            "Preparing to unpack .../29-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Setting up libpathplan4 (2.40.1-2) ...\n",
            "Setting up liblab-gamut1 (2.40.1-2) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libann0 (1.1.2+doc-6) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libcdt5 (2.40.1-2) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.40.1-2) ...\n",
            "Setting up libwebp6:amd64 (0.6.1-2) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libgvpr2 (2.40.1-2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libgvc6 (2.40.1-2) ...\n",
            "Setting up graphviz (2.40.1-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting pydot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.0)\n",
            "Building wheels for collected packages: pydot\n",
            "  Running setup.py bdist_wheel for pydot ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
            "Successfully built pydot\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-1.2.4\n",
            "Collecting pydot-ng\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/5b/9a08333f2d70d404ffe42cea4f50159c4ad94feaa4d7585551c05cacef46/pydot_ng-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from pydot-ng) (2.3.0)\n",
            "Installing collected packages: pydot-ng\n",
            "Successfully installed pydot-ng-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dSP03XDi-2hO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.1 Going beyond the Sequential model: the Keras functional API\n",
        "\n",
        "Until now, we've seen neural networks implemented using the Sequential model which makes the assumption that the network has exactly one input and one output, and that consists of a linear stack of layers.\n",
        "\n",
        "Some networks require several independent inputs, others require multiple outputs, and networks have internal branching between layers that makes them look like graphs of layers like in the Inception and ResNET architectures."
      ]
    },
    {
      "metadata": {
        "id": "zEyy2tvn-2hR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7.1.1. Introduction to the Keras functional API\n",
        "\n",
        "Fortunately there’s a more general and flexible way to use Keras: the functional API. In the functional API, you directly manipulate tensors, and you use layers as functions that take tensors and return tensors (hence, the name functional API):"
      ]
    },
    {
      "metadata": {
        "id": "6zuIl5rh-2hU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Input, layers \n",
        "input_tensor = Input(shape=(32,))\n",
        "dense = layers.Dense(32, activation='relu')\n",
        "output_tensor = dense(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vz748XOC-2hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let’s start with a minimal example that shows side by side a simple Sequential model and its equivalent in the functional API:"
      ]
    },
    {
      "metadata": {
        "id": "xh7Y3icp-2hg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model \n",
        "from keras import layers \n",
        "from keras import Input \n",
        "\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,))) \n",
        "seq_model.add(layers.Dense(32, activation='relu'))\n",
        "seq_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "input_tensor = Input(shape=(64,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(input_tensor, output_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZjnwoR2-2hm",
        "colab_type": "code",
        "outputId": "75f59300-6a11-4687-9a9d-6e1e8a9b2646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"304pt\" viewBox=\"0.00 0.00 279.00 304.00\" width=\"279pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 275,-300 275,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139867764672384 -->\n<g class=\"node\" id=\"node1\">\n<title>139867764672384</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 271,-295.5 271,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-268.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-249.5 133,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-272.5 191,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-249.5 191,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-280.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"191,-272.5 271,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-257.3\">(None, 64)</text>\n</g>\n<!-- 139867764798352 -->\n<g class=\"node\" id=\"node2\">\n<title>139867764798352</title>\n<polygon fill=\"none\" points=\"13,-166.5 13,-212.5 258,-212.5 258,-166.5 13,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-185.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"120,-166.5 120,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"120,-189.5 178,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"178,-166.5 178,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-197.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"178,-189.5 258,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 139867764672384&#45;&gt;139867764798352 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139867764672384-&gt;139867764798352</title>\n<path d=\"M135.5,-249.3799C135.5,-241.1745 135.5,-231.7679 135.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"139.0001,-222.784 135.5,-212.784 132.0001,-222.784 139.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867764800984 -->\n<g class=\"node\" id=\"node3\">\n<title>139867764800984</title>\n<polygon fill=\"none\" points=\"13,-83.5 13,-129.5 258,-129.5 258,-83.5 13,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-102.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"120,-83.5 120,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"120,-106.5 178,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"178,-83.5 178,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-114.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"178,-106.5 258,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 139867764798352&#45;&gt;139867764800984 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139867764798352-&gt;139867764800984</title>\n<path d=\"M135.5,-166.3799C135.5,-158.1745 135.5,-148.7679 135.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"139.0001,-139.784 135.5,-129.784 132.0001,-139.784 139.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867764374552 -->\n<g class=\"node\" id=\"node4\">\n<title>139867764374552</title>\n<polygon fill=\"none\" points=\"13,-.5 13,-46.5 258,-46.5 258,-.5 13,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-19.8\">dense_7: Dense</text>\n<polyline fill=\"none\" points=\"120,-.5 120,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"120,-23.5 178,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"178,-.5 178,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"178,-23.5 258,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 139867764800984&#45;&gt;139867764374552 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139867764800984-&gt;139867764374552</title>\n<path d=\"M135.5,-83.3799C135.5,-75.1745 135.5,-65.7679 135.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"139.0001,-56.784 135.5,-46.784 132.0001,-56.784 139.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "Rn64ldmx-2hw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The only part that may seem a bit magical at this point is instantiating a Model object using only an input tensor and an output tensor. Behind the scenes, Keras retrieves every layer involved in going from input_tensor to output_tensor, bringing them together into a graph-like data structure—a Model. Of course, the reason it works is that output_tensor was obtained by repeatedly transforming input_tensor. If you tried to build a model from inputs and outputs that weren’t related, you’d get a RuntimeError:"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "R3tOtgz1-2hy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unrelated_input = Input(shape=(32,))\n",
        "bad_model = Model(unrelated_input, output_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0tvEG5yT-2h9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This error tells you, in essence, that Keras couldn’t reach input_2 from the provided output tensor. \n",
        "\n",
        "When it comes to compiling, training, or evaluating such an instance of Model, the API is the same as that of Sequential:"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Zqd4dH7a-2h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10)) \n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "score = model.evaluate(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FapBiqDA-2iN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1.2 Multi-input models\n",
        "\n",
        "The functional API can be used to build models that have multiple inputs. Typically, such models at some point merge their different input branches using a layer that can combine several tensors: by adding them, concatenating them, and so on. This is usually done via a Keras merge operation such as keras.layers.add, keras.layers.concatenate, and so on. \n",
        "\n",
        "#### A question-answering model example\n",
        "Let’s look at a very simple example of a multi-input model: a question-answering model. A typical question-answering model has two inputs: a natural-language question and a text snippet (such as a news article) providing information to be used for answering the question. The model must then produce an answer: in the simplest possible setup, this is a one-word answer obtained via a softmax over some predefined vocabulary (see figure 7.6).\n",
        "\n",
        "Following is an example of how you can build such a model with the functional API. You set up two independent branches, encoding the text input and the question input as representation vectors; then, concatenate these vectors; and finally, add a softmax classifier on top of the concatenated representations.\n",
        "\n",
        "#### Functional API implementation of a two-input question-answering model"
      ]
    },
    {
      "metadata": {
        "id": "10kVo7D4-2iP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "# The text input is a variable-length sequence of integers. \n",
        "# Note that you can optionally name the inputs.\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "# Embeds the inputs into a sequence of vectors of size 64\n",
        "# embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
        "# embedded_text = layers.Embedding(output_dim=64, input_dim=text_vocabulary_size)(text_input)\n",
        "embedded_text = layers.Embedding(text_vocabulary_size,64)(text_input)\n",
        "# Encodes the vectors in a single vector via an LSTM\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "# Same process (with different layer instances) for the question\n",
        "question_input = Input(shape=(None,),dtype='int32',name='question')\n",
        "# embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
        "# embedded_question = layers.Embedding(output_dim=32, input_dim=question_vocabulary_size)(question_input)\n",
        "embedded_question = layers.Embedding(question_vocabulary_size,32)(question_input)\n",
        "encoded_question = layers.LSTM(16)(embedded_question) \n",
        "# Concatenates the encoded question and encoded text\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question],axis=-1)\n",
        "# Adds a softmax classifier on top\n",
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
        "# At model instantiation, you specify the two inputs and the output.\n",
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxLF6Jt6-2iX",
        "colab_type": "code",
        "outputId": "ccf5415f-6dff-4fe1-b223-fb86f649bb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 32)           12416       embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 16)           3136        embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 48)           0           lstm_5[0][0]                     \n",
            "                                                                 lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 500)          24500       concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,000,052\n",
            "Trainable params: 1,000,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"387pt\" viewBox=\"0.00 0.00 722.00 387.00\" width=\"722pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 718,-383 718,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139867401665560 -->\n<g class=\"node\" id=\"node1\">\n<title>139867401665560</title>\n<polygon fill=\"none\" points=\"42.5,-332.5 42.5,-378.5 305.5,-378.5 305.5,-332.5 42.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-351.8\">text: InputLayer</text>\n<polyline fill=\"none\" points=\"151.5,-332.5 151.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"151.5,-355.5 209.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"209.5,-332.5 209.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.5\" y=\"-363.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"209.5,-355.5 305.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.5\" y=\"-340.3\">(None, None)</text>\n</g>\n<!-- 139867401665448 -->\n<g class=\"node\" id=\"node3\">\n<title>139867401665448</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 348,-295.5 348,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-268.8\">embedding_5: Embedding</text>\n<polyline fill=\"none\" points=\"171,-249.5 171,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"171,-272.5 229,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"229,-249.5 229,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-280.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"229,-272.5 348,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-257.3\">(None, None, 64)</text>\n</g>\n<!-- 139867401665560&#45;&gt;139867401665448 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139867401665560-&gt;139867401665448</title>\n<path d=\"M174,-332.3799C174,-324.1745 174,-314.7679 174,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"177.5001,-305.784 174,-295.784 170.5001,-305.784 177.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867401666008 -->\n<g class=\"node\" id=\"node2\">\n<title>139867401666008</title>\n<polygon fill=\"none\" points=\"394.5,-332.5 394.5,-378.5 685.5,-378.5 685.5,-332.5 394.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"463\" y=\"-351.8\">question: InputLayer</text>\n<polyline fill=\"none\" points=\"531.5,-332.5 531.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"531.5,-355.5 589.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"589.5,-332.5 589.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637.5\" y=\"-363.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"589.5,-355.5 685.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637.5\" y=\"-340.3\">(None, None)</text>\n</g>\n<!-- 139867401666288 -->\n<g class=\"node\" id=\"node4\">\n<title>139867401666288</title>\n<polygon fill=\"none\" points=\"366,-249.5 366,-295.5 714,-295.5 714,-249.5 366,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451.5\" y=\"-268.8\">embedding_6: Embedding</text>\n<polyline fill=\"none\" points=\"537,-249.5 537,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"537,-272.5 595,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"595,-249.5 595,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654.5\" y=\"-280.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"595,-272.5 714,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654.5\" y=\"-257.3\">(None, None, 32)</text>\n</g>\n<!-- 139867401666008&#45;&gt;139867401666288 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139867401666008-&gt;139867401666288</title>\n<path d=\"M540,-332.3799C540,-324.1745 540,-314.7679 540,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"543.5001,-305.784 540,-295.784 536.5001,-305.784 543.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867401666064 -->\n<g class=\"node\" id=\"node5\">\n<title>139867401666064</title>\n<polygon fill=\"none\" points=\"68.5,-166.5 68.5,-212.5 347.5,-212.5 347.5,-166.5 68.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.5\" y=\"-185.8\">lstm_5: LSTM</text>\n<polyline fill=\"none\" points=\"170.5,-166.5 170.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"170.5,-189.5 228.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"228.5,-166.5 228.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-197.3\">(None, None, 64)</text>\n<polyline fill=\"none\" points=\"228.5,-189.5 347.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 139867401665448&#45;&gt;139867401666064 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139867401665448-&gt;139867401666064</title>\n<path d=\"M183.4709,-249.3799C186.9052,-240.9962 190.8532,-231.3584 194.564,-222.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"197.91,-223.3645 198.462,-212.784 191.4324,-220.7109 197.91,-223.3645\" stroke=\"#000000\"/>\n</g>\n<!-- 139867401245752 -->\n<g class=\"node\" id=\"node6\">\n<title>139867401245752</title>\n<polygon fill=\"none\" points=\"382.5,-166.5 382.5,-212.5 661.5,-212.5 661.5,-166.5 382.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"433.5\" y=\"-185.8\">lstm_6: LSTM</text>\n<polyline fill=\"none\" points=\"484.5,-166.5 484.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"513.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"484.5,-189.5 542.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"513.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"542.5,-166.5 542.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"602\" y=\"-197.3\">(None, None, 32)</text>\n<polyline fill=\"none\" points=\"542.5,-189.5 661.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"602\" y=\"-174.3\">(None, 16)</text>\n</g>\n<!-- 139867401666288&#45;&gt;139867401245752 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139867401666288-&gt;139867401245752</title>\n<path d=\"M534.986,-249.3799C533.1872,-241.0854 531.1222,-231.5633 529.1759,-222.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"532.5895,-221.815 527.0495,-212.784 525.7485,-223.2987 532.5895,-221.815\" stroke=\"#000000\"/>\n</g>\n<!-- 139867400437040 -->\n<g class=\"node\" id=\"node7\">\n<title>139867400437040</title>\n<polygon fill=\"none\" points=\"160,-83.5 160,-129.5 552,-129.5 552,-83.5 160,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-102.8\">concatenate_3: Concatenate</text>\n<polyline fill=\"none\" points=\"335,-83.5 335,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"335,-106.5 393,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"393,-83.5 393,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-114.3\">[(None, 32), (None, 16)]</text>\n<polyline fill=\"none\" points=\"393,-106.5 552,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-91.3\">(None, 48)</text>\n</g>\n<!-- 139867401666064&#45;&gt;139867400437040 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139867401666064-&gt;139867400437040</title>\n<path d=\"M249.2263,-166.3799C266.7936,-156.5279 287.449,-144.9442 305.8879,-134.6034\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"307.7284,-137.5841 314.7384,-129.6399 304.3043,-131.4787 307.7284,-137.5841\" stroke=\"#000000\"/>\n</g>\n<!-- 139867401245752&#45;&gt;139867400437040 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139867401245752-&gt;139867400437040</title>\n<path d=\"M475.7597,-166.3799C455.7872,-156.3936 432.2558,-144.6279 411.3622,-134.1811\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"412.7894,-130.9816 402.2799,-129.6399 409.6589,-137.2426 412.7894,-130.9816\" stroke=\"#000000\"/>\n</g>\n<!-- 139867401245808 -->\n<g class=\"node\" id=\"node8\">\n<title>139867401245808</title>\n<polygon fill=\"none\" points=\"226.5,-.5 226.5,-46.5 485.5,-46.5 485.5,-.5 226.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-19.8\">dense_10: Dense</text>\n<polyline fill=\"none\" points=\"340.5,-.5 340.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"340.5,-23.5 398.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"398.5,-.5 398.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442\" y=\"-31.3\">(None, 48)</text>\n<polyline fill=\"none\" points=\"398.5,-23.5 485.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442\" y=\"-8.3\">(None, 500)</text>\n</g>\n<!-- 139867400437040&#45;&gt;139867401245808 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139867400437040-&gt;139867401245808</title>\n<path d=\"M356,-83.3799C356,-75.1745 356,-65.7679 356,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-56.784 356,-46.784 352.5001,-56.784 359.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Gt34QOV_-2id",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, how do you train this two-input model? There are two possible APIs: you can feed the model a list of Numpy arrays as inputs, or you can feed it a dictionary that maps input names to Numpy arrays. Naturally, the latter option is available only if you give names to your inputs. \n",
        "\n",
        "#### Training the multi-input model"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "YWUF6KOE-2ie",
        "colab_type": "code",
        "outputId": "d727fac0-650b-4579-8a98-e2c5f0305f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5219
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_samples = 1000 \n",
        "max_length = 100\n",
        "\n",
        "# Generates dummy Numpy data\n",
        "text = np.random.randint(1, text_vocabulary_size,size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocabulary_size,size=(num_samples, max_length)) \n",
        "# Answers are one-hot encoded, not integers\n",
        "# answers = np.random.randint(0, 1,size=(num_samples, answer_vocabulary_size))\n",
        "answers = np.random.randint(answer_vocabulary_size, size=(num_samples))\n",
        "answers = keras.utils.to_categorical(answers, answer_vocabulary_size)\n",
        "\n",
        "# Fitting using a list of inputs\n",
        "print('-'*10,\"First training run with list of NumPy arrays\",'-'*60)\n",
        "model.fit([text, question], answers, epochs = 100, batch_size = 128, validation_split = 0.2)\n",
        "print()\n",
        "\n",
        "# Fitting using a dictionary of inputs (only if inputs are named)\n",
        "print('-'*10,\"Second training run with dictionary and named inputs\",'-'*60)\n",
        "model.fit({'text': text, 'question': question}, answers, epochs = 50, batch_size = 128, validation_split = 0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- First training run with list of NumPy arrays ------------------------------------------------------------\n",
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 6.2147 - acc: 0.0000e+00 - val_loss: 6.2158 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 6.1995 - acc: 0.0488 - val_loss: 6.2169 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 6.1778 - acc: 0.0262 - val_loss: 6.2355 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 6.0905 - acc: 0.0050 - val_loss: 6.2820 - val_acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 6.0024 - acc: 0.0063 - val_loss: 6.3456 - val_acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.9337 - acc: 0.0100 - val_loss: 6.3444 - val_acc: 0.0000e+00\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.8421 - acc: 0.0163 - val_loss: 6.4317 - val_acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.7476 - acc: 0.0100 - val_loss: 6.4055 - val_acc: 0.0000e+00\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.6728 - acc: 0.0125 - val_loss: 6.5810 - val_acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.5924 - acc: 0.0200 - val_loss: 6.6028 - val_acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.5323 - acc: 0.0312 - val_loss: 6.9812 - val_acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.4925 - acc: 0.0450 - val_loss: 6.6309 - val_acc: 0.0000e+00\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.4161 - acc: 0.0588 - val_loss: 6.6933 - val_acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.3627 - acc: 0.0625 - val_loss: 6.9190 - val_acc: 0.0000e+00\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.3053 - acc: 0.0750 - val_loss: 7.1341 - val_acc: 0.0000e+00\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.2591 - acc: 0.0825 - val_loss: 6.9876 - val_acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.2086 - acc: 0.0875 - val_loss: 7.3537 - val_acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.1494 - acc: 0.0900 - val_loss: 6.8444 - val_acc: 0.0000e+00\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.1178 - acc: 0.0900 - val_loss: 6.9781 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.0481 - acc: 0.1025 - val_loss: 7.0655 - val_acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 5.0182 - acc: 0.0975 - val_loss: 6.9784 - val_acc: 0.0000e+00\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.9711 - acc: 0.1000 - val_loss: 7.5750 - val_acc: 0.0000e+00\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.9248 - acc: 0.1075 - val_loss: 7.2186 - val_acc: 0.0000e+00\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.8839 - acc: 0.1250 - val_loss: 7.4885 - val_acc: 0.0000e+00\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.8570 - acc: 0.1187 - val_loss: 7.4881 - val_acc: 0.0000e+00\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.8026 - acc: 0.1275 - val_loss: 7.2914 - val_acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.7788 - acc: 0.1275 - val_loss: 7.7355 - val_acc: 0.0000e+00\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.7253 - acc: 0.1437 - val_loss: 7.6481 - val_acc: 0.0000e+00\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.6969 - acc: 0.1487 - val_loss: 7.7163 - val_acc: 0.0000e+00\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.6561 - acc: 0.1387 - val_loss: 7.8323 - val_acc: 0.0000e+00\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.6187 - acc: 0.1575 - val_loss: 7.6861 - val_acc: 0.0000e+00\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.5710 - acc: 0.1575 - val_loss: 7.7402 - val_acc: 0.0000e+00\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.5392 - acc: 0.1712 - val_loss: 7.5067 - val_acc: 0.0000e+00\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.5088 - acc: 0.1762 - val_loss: 7.7743 - val_acc: 0.0000e+00\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.4523 - acc: 0.1813 - val_loss: 7.7971 - val_acc: 0.0000e+00\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.4274 - acc: 0.1875 - val_loss: 7.8004 - val_acc: 0.0000e+00\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.4448 - acc: 0.1937 - val_loss: 7.6183 - val_acc: 0.0000e+00\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.3629 - acc: 0.2038 - val_loss: 7.9349 - val_acc: 0.0000e+00\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.3260 - acc: 0.2075 - val_loss: 7.8237 - val_acc: 0.0000e+00\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.2881 - acc: 0.2275 - val_loss: 7.8490 - val_acc: 0.0000e+00\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.2740 - acc: 0.2263 - val_loss: 7.7127 - val_acc: 0.0000e+00\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.2075 - acc: 0.2500 - val_loss: 7.8697 - val_acc: 0.0000e+00\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.1758 - acc: 0.2587 - val_loss: 7.7506 - val_acc: 0.0000e+00\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.1799 - acc: 0.2475 - val_loss: 7.7119 - val_acc: 0.0000e+00\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.1236 - acc: 0.2750 - val_loss: 7.5188 - val_acc: 0.0050\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.1039 - acc: 0.2838 - val_loss: 7.8008 - val_acc: 0.0000e+00\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.0500 - acc: 0.2913 - val_loss: 7.9903 - val_acc: 0.0000e+00\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 4.0097 - acc: 0.2875 - val_loss: 7.9968 - val_acc: 0.0000e+00\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.9957 - acc: 0.3000 - val_loss: 7.8153 - val_acc: 0.0000e+00\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.9382 - acc: 0.3325 - val_loss: 7.7373 - val_acc: 0.0000e+00\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.8909 - acc: 0.3613 - val_loss: 7.5930 - val_acc: 0.0000e+00\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.8618 - acc: 0.3625 - val_loss: 8.2044 - val_acc: 0.0050\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.8442 - acc: 0.3812 - val_loss: 7.9728 - val_acc: 0.0000e+00\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.7879 - acc: 0.3775 - val_loss: 7.7614 - val_acc: 0.0000e+00\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.7595 - acc: 0.3962 - val_loss: 7.9641 - val_acc: 0.0000e+00\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.7542 - acc: 0.3788 - val_loss: 8.1169 - val_acc: 0.0000e+00\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.6896 - acc: 0.4113 - val_loss: 7.9731 - val_acc: 0.0000e+00\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.6459 - acc: 0.4200 - val_loss: 8.0190 - val_acc: 0.0050\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.5995 - acc: 0.4462 - val_loss: 7.8960 - val_acc: 0.0000e+00\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.5640 - acc: 0.4475 - val_loss: 7.6123 - val_acc: 0.0000e+00\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.5325 - acc: 0.4425 - val_loss: 7.5098 - val_acc: 0.0050\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.5401 - acc: 0.4662 - val_loss: 8.1275 - val_acc: 0.0050\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.5108 - acc: 0.4488 - val_loss: 8.0963 - val_acc: 0.0050\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.4383 - acc: 0.5000 - val_loss: 8.0095 - val_acc: 0.0050\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.3911 - acc: 0.4925 - val_loss: 7.9107 - val_acc: 0.0000e+00\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.3437 - acc: 0.5112 - val_loss: 8.0934 - val_acc: 0.0000e+00\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.3098 - acc: 0.5125 - val_loss: 7.9073 - val_acc: 0.0050\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.2783 - acc: 0.5200 - val_loss: 8.1934 - val_acc: 0.0000e+00\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.2334 - acc: 0.5237 - val_loss: 8.0502 - val_acc: 0.0050\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.2069 - acc: 0.5487 - val_loss: 8.0263 - val_acc: 0.0050\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.1613 - acc: 0.5712 - val_loss: 7.7046 - val_acc: 0.0100\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.1067 - acc: 0.5837 - val_loss: 8.1442 - val_acc: 0.0000e+00\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.0771 - acc: 0.5787 - val_loss: 7.9102 - val_acc: 0.0100\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 3.0854 - acc: 0.5500 - val_loss: 8.1277 - val_acc: 0.0000e+00\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.9951 - acc: 0.6062 - val_loss: 7.9338 - val_acc: 0.0050\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.9423 - acc: 0.5975 - val_loss: 7.9556 - val_acc: 0.0050\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.9052 - acc: 0.6138 - val_loss: 8.0684 - val_acc: 0.0050\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.9033 - acc: 0.6000 - val_loss: 8.0698 - val_acc: 0.0050\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.8275 - acc: 0.6275 - val_loss: 7.5811 - val_acc: 0.0000e+00\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.7767 - acc: 0.6350 - val_loss: 8.0833 - val_acc: 0.0000e+00\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.7472 - acc: 0.6438 - val_loss: 8.1696 - val_acc: 0.0050\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.7011 - acc: 0.6575 - val_loss: 7.9708 - val_acc: 0.0000e+00\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.6459 - acc: 0.6625 - val_loss: 8.1383 - val_acc: 0.0000e+00\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.6518 - acc: 0.6613 - val_loss: 8.0290 - val_acc: 0.0050\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.5554 - acc: 0.6850 - val_loss: 7.9610 - val_acc: 0.0050\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.5254 - acc: 0.6913 - val_loss: 7.9472 - val_acc: 0.0050\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.4815 - acc: 0.7150 - val_loss: 7.5020 - val_acc: 0.0050\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.4478 - acc: 0.7325 - val_loss: 8.1097 - val_acc: 0.0050\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.3913 - acc: 0.7413 - val_loss: 8.0365 - val_acc: 0.0050\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.3332 - acc: 0.7563 - val_loss: 8.0929 - val_acc: 0.0050\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.3086 - acc: 0.7625 - val_loss: 7.5928 - val_acc: 0.0050\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.2655 - acc: 0.7787 - val_loss: 7.9640 - val_acc: 0.0050\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.2053 - acc: 0.7812 - val_loss: 7.9580 - val_acc: 0.0050\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.1627 - acc: 0.7937 - val_loss: 8.3552 - val_acc: 0.0050\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.1605 - acc: 0.7950 - val_loss: 8.0226 - val_acc: 0.0200\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.0709 - acc: 0.8175 - val_loss: 8.0160 - val_acc: 0.0150\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 2.0286 - acc: 0.8300 - val_loss: 8.0590 - val_acc: 0.0000e+00\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.9785 - acc: 0.8400 - val_loss: 8.0939 - val_acc: 0.0200\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.9497 - acc: 0.8475 - val_loss: 7.9773 - val_acc: 0.0000e+00\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.9059 - acc: 0.8575 - val_loss: 8.0351 - val_acc: 0.0000e+00\n",
            "\n",
            "---------- Second training run with dictionary and named inputs ------------------------------------------------------------\n",
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.8732 - acc: 0.8550 - val_loss: 7.9335 - val_acc: 0.0050\n",
            "Epoch 2/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.8556 - acc: 0.8663 - val_loss: 8.1583 - val_acc: 0.0100\n",
            "Epoch 3/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7786 - acc: 0.8750 - val_loss: 8.0299 - val_acc: 0.0100\n",
            "Epoch 4/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7666 - acc: 0.8775 - val_loss: 8.1522 - val_acc: 0.0100\n",
            "Epoch 5/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6972 - acc: 0.8850 - val_loss: 8.2442 - val_acc: 0.0100\n",
            "Epoch 6/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6584 - acc: 0.8938 - val_loss: 8.0858 - val_acc: 0.0150\n",
            "Epoch 7/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6301 - acc: 0.8950 - val_loss: 8.3307 - val_acc: 0.0100\n",
            "Epoch 8/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.5878 - acc: 0.8987 - val_loss: 7.9909 - val_acc: 0.0000e+00\n",
            "Epoch 9/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.5363 - acc: 0.9263 - val_loss: 8.0981 - val_acc: 0.0000e+00\n",
            "Epoch 10/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.4972 - acc: 0.9175 - val_loss: 8.1427 - val_acc: 0.0000e+00\n",
            "Epoch 11/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.4587 - acc: 0.9275 - val_loss: 7.9031 - val_acc: 0.0050\n",
            "Epoch 12/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.4776 - acc: 0.9175 - val_loss: 8.0698 - val_acc: 0.0100\n",
            "Epoch 13/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.4129 - acc: 0.9363 - val_loss: 7.9940 - val_acc: 0.0000e+00\n",
            "Epoch 14/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.3578 - acc: 0.9375 - val_loss: 8.1230 - val_acc: 0.0000e+00\n",
            "Epoch 15/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.3427 - acc: 0.9387 - val_loss: 7.7947 - val_acc: 0.0050\n",
            "Epoch 16/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.2971 - acc: 0.9487 - val_loss: 8.3775 - val_acc: 0.0050\n",
            "Epoch 17/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.2732 - acc: 0.9462 - val_loss: 7.9944 - val_acc: 0.0050\n",
            "Epoch 18/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.2265 - acc: 0.9587 - val_loss: 8.2038 - val_acc: 0.0100\n",
            "Epoch 19/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1955 - acc: 0.9612 - val_loss: 8.0077 - val_acc: 0.0050\n",
            "Epoch 20/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1705 - acc: 0.9612 - val_loss: 8.1910 - val_acc: 0.0000e+00\n",
            "Epoch 21/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1698 - acc: 0.9575 - val_loss: 8.1159 - val_acc: 0.0050\n",
            "Epoch 22/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1181 - acc: 0.9625 - val_loss: 8.2847 - val_acc: 0.0000e+00\n",
            "Epoch 23/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0827 - acc: 0.9688 - val_loss: 8.0461 - val_acc: 0.0050\n",
            "Epoch 24/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0625 - acc: 0.9700 - val_loss: 8.3428 - val_acc: 0.0050\n",
            "Epoch 25/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0265 - acc: 0.9725 - val_loss: 7.7965 - val_acc: 0.0100\n",
            "Epoch 26/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.0077 - acc: 0.9775 - val_loss: 8.1997 - val_acc: 0.0100\n",
            "Epoch 27/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9759 - acc: 0.9775 - val_loss: 8.2198 - val_acc: 0.0000e+00\n",
            "Epoch 28/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9408 - acc: 0.9838 - val_loss: 8.4032 - val_acc: 0.0000e+00\n",
            "Epoch 29/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9130 - acc: 0.9812 - val_loss: 8.2159 - val_acc: 0.0000e+00\n",
            "Epoch 30/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.9437 - acc: 0.9688 - val_loss: 8.1062 - val_acc: 0.0000e+00\n",
            "Epoch 31/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8958 - acc: 0.9750 - val_loss: 8.4539 - val_acc: 0.0000e+00\n",
            "Epoch 32/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8561 - acc: 0.9800 - val_loss: 8.3927 - val_acc: 0.0000e+00\n",
            "Epoch 33/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8382 - acc: 0.9825 - val_loss: 7.9784 - val_acc: 0.0000e+00\n",
            "Epoch 34/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.8219 - acc: 0.9825 - val_loss: 8.2902 - val_acc: 0.0050\n",
            "Epoch 35/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.7871 - acc: 0.9862 - val_loss: 8.5562 - val_acc: 0.0000e+00\n",
            "Epoch 36/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.7636 - acc: 0.9812 - val_loss: 8.2991 - val_acc: 0.0050\n",
            "Epoch 37/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.7329 - acc: 0.9875 - val_loss: 8.2115 - val_acc: 0.0050\n",
            "Epoch 38/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.7102 - acc: 0.9888 - val_loss: 8.2607 - val_acc: 0.0000e+00\n",
            "Epoch 39/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.7784 - acc: 0.9700 - val_loss: 8.0899 - val_acc: 0.0000e+00\n",
            "Epoch 40/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6979 - acc: 0.9825 - val_loss: 7.9613 - val_acc: 0.0050\n",
            "Epoch 41/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6641 - acc: 0.9850 - val_loss: 8.3338 - val_acc: 0.0000e+00\n",
            "Epoch 42/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6385 - acc: 0.9875 - val_loss: 8.3399 - val_acc: 0.0050\n",
            "Epoch 43/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6215 - acc: 0.9913 - val_loss: 8.3168 - val_acc: 0.0050\n",
            "Epoch 44/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6019 - acc: 0.9888 - val_loss: 8.3182 - val_acc: 0.0000e+00\n",
            "Epoch 45/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5856 - acc: 0.9875 - val_loss: 8.2278 - val_acc: 0.0050\n",
            "Epoch 46/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5749 - acc: 0.9875 - val_loss: 8.2603 - val_acc: 0.0000e+00\n",
            "Epoch 47/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.6198 - acc: 0.9788 - val_loss: 8.2954 - val_acc: 0.0000e+00\n",
            "Epoch 48/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5423 - acc: 0.9900 - val_loss: 8.3208 - val_acc: 0.0050\n",
            "Epoch 49/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5179 - acc: 0.9900 - val_loss: 8.2194 - val_acc: 0.0050\n",
            "Epoch 50/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5023 - acc: 0.9900 - val_loss: 8.3658 - val_acc: 0.0050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f356a7b27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "G6nTCpjeCT8-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 使用真實文本資料 -Training the multi-input model\n",
        "\n",
        "在使用模擬資料後, 來試試真實的文字資料吧! \n",
        "\n",
        "1.   Facebook, The (20) QA bAbI tasks\n",
        "\n",
        "\n",
        "> Sngle supporting fact (task #1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "H0pA6DWmCTV7",
        "colab_type": "code",
        "outputId": "20423321-7bf3-4e86-e1d9-54acffc30345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7017
        }
      },
      "cell_type": "code",
      "source": [
        "#先下載文本資料\n",
        "!wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\n",
        "!tar -xvzf tasks_1-20_v1-2.tar.gz\n",
        "\n",
        "#安裝自然語言處理的套件\n",
        "!pip install -q nltk \n",
        "import nltk\n",
        "#安裝nltk所需的\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-15 14:29:45--  http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\n",
            "Resolving www.thespermwhale.com (www.thespermwhale.com)... 69.65.3.210\n",
            "Connecting to www.thespermwhale.com (www.thespermwhale.com)|69.65.3.210|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15719851 (15M) [application/x-gzip]\n",
            "Saving to: ‘tasks_1-20_v1-2.tar.gz.1’\n",
            "\n",
            "tasks_1-20_v1-2.tar 100%[===================>]  14.99M  7.11MB/s    in 2.1s    \n",
            "\n",
            "2018-11-15 14:29:48 (7.11 MB/s) - ‘tasks_1-20_v1-2.tar.gz.1’ saved [15719851/15719851]\n",
            "\n",
            "tasks_1-20_v1-2/\n",
            "tasks_1-20_v1-2/hn/\n",
            "tasks_1-20_v1-2/hn/qa16_basic-induction_train.txt\n",
            "tasks_1-20_v1-2/hn/qa13_compound-coreference_train.txt\n",
            "tasks_1-20_v1-2/hn/qa13_compound-coreference_test.txt\n",
            "tasks_1-20_v1-2/hn/qa14_time-reasoning_test.txt\n",
            "tasks_1-20_v1-2/hn/qa5_three-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/hn/qa17_positional-reasoning_train.txt\n",
            "tasks_1-20_v1-2/hn/qa9_simple-negation_train.txt\n",
            "tasks_1-20_v1-2/hn/qa12_conjunction_train.txt\n",
            "tasks_1-20_v1-2/hn/qa6_yes-no-questions_train.txt\n",
            "tasks_1-20_v1-2/hn/qa2_two-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/hn/qa20_agents-motivations_train.txt\n",
            "tasks_1-20_v1-2/hn/qa7_counting_train.txt\n",
            "tasks_1-20_v1-2/hn/qa18_size-reasoning_test.txt\n",
            "tasks_1-20_v1-2/hn/qa1_single-supporting-fact_train.txt\n",
            "tasks_1-20_v1-2/hn/qa18_size-reasoning_train.txt\n",
            "tasks_1-20_v1-2/hn/qa1_single-supporting-fact_test.txt\n",
            "tasks_1-20_v1-2/hn/qa16_basic-induction_test.txt\n",
            "tasks_1-20_v1-2/hn/qa8_lists-sets_train.txt\n",
            "tasks_1-20_v1-2/hn/qa15_basic-deduction_test.txt\n",
            "tasks_1-20_v1-2/hn/qa11_basic-coreference_train.txt\n",
            "tasks_1-20_v1-2/hn/qa12_conjunction_test.txt\n",
            "tasks_1-20_v1-2/hn/qa10_indefinite-knowledge_test.txt\n",
            "tasks_1-20_v1-2/hn/qa19_path-finding_test.txt\n",
            "tasks_1-20_v1-2/hn/qa8_lists-sets_test.txt\n",
            "tasks_1-20_v1-2/hn/qa4_two-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/hn/qa10_indefinite-knowledge_train.txt\n",
            "tasks_1-20_v1-2/hn/qa19_path-finding_train.txt\n",
            "tasks_1-20_v1-2/hn/qa20_agents-motivations_test.txt\n",
            "tasks_1-20_v1-2/hn/qa5_three-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/hn/qa7_counting_test.txt\n",
            "tasks_1-20_v1-2/hn/qa3_three-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/hn/qa14_time-reasoning_train.txt\n",
            "tasks_1-20_v1-2/hn/qa17_positional-reasoning_test.txt\n",
            "tasks_1-20_v1-2/hn/qa9_simple-negation_test.txt\n",
            "tasks_1-20_v1-2/hn/qa4_two-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/hn/qa6_yes-no-questions_test.txt\n",
            "tasks_1-20_v1-2/hn/qa15_basic-deduction_train.txt\n",
            "tasks_1-20_v1-2/hn/qa3_three-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/hn/qa2_two-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/hn/qa11_basic-coreference_test.txt\n",
            "tasks_1-20_v1-2/shuffled/\n",
            "tasks_1-20_v1-2/shuffled/qa16_basic-induction_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa13_compound-coreference_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa13_compound-coreference_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa14_time-reasoning_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa5_three-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa17_positional-reasoning_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa9_simple-negation_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa12_conjunction_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa6_yes-no-questions_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa2_two-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa20_agents-motivations_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa7_counting_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa18_size-reasoning_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa1_single-supporting-fact_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa18_size-reasoning_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa1_single-supporting-fact_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa16_basic-induction_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa8_lists-sets_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa15_basic-deduction_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa11_basic-coreference_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa12_conjunction_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa10_indefinite-knowledge_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa19_path-finding_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa8_lists-sets_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa4_two-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa10_indefinite-knowledge_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa19_path-finding_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa20_agents-motivations_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa5_three-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa7_counting_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa3_three-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa14_time-reasoning_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa17_positional-reasoning_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa9_simple-negation_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa4_two-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa6_yes-no-questions_test.txt\n",
            "tasks_1-20_v1-2/shuffled/qa15_basic-deduction_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa3_three-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa2_two-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/shuffled/qa11_basic-coreference_test.txt\n",
            "tasks_1-20_v1-2/en-10k/\n",
            "tasks_1-20_v1-2/en-10k/qa16_basic-induction_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa13_compound-coreference_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa13_compound-coreference_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa14_time-reasoning_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa5_three-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa17_positional-reasoning_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa9_simple-negation_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa12_conjunction_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa6_yes-no-questions_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa20_agents-motivations_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa7_counting_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa18_size-reasoning_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa18_size-reasoning_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa16_basic-induction_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa8_lists-sets_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa15_basic-deduction_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa11_basic-coreference_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa12_conjunction_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa10_indefinite-knowledge_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa19_path-finding_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa8_lists-sets_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa4_two-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa10_indefinite-knowledge_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa19_path-finding_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa20_agents-motivations_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa5_three-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa7_counting_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa3_three-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa14_time-reasoning_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa17_positional-reasoning_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa9_simple-negation_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa4_two-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa6_yes-no-questions_test.txt\n",
            "tasks_1-20_v1-2/en-10k/qa15_basic-deduction_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa3_three-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/en-10k/qa11_basic-coreference_test.txt\n",
            "tasks_1-20_v1-2/en-valid/\n",
            "tasks_1-20_v1-2/en-valid/qa8_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa11_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa7_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa13_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa7_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa19_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa12_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa18_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa6_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa9_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa8_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa2_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa12_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa11_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa9_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa1_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa7_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa16_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa4_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa2_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa5_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa16_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa18_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa13_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa11_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa1_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa5_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa15_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa20_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa18_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa19_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa9_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa17_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa15_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa5_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa20_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa14_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa4_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa15_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa10_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa8_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa6_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa17_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa10_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa3_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa3_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa16_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa3_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa14_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa19_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa4_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa1_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa2_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa13_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa20_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa6_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa14_train.txt\n",
            "tasks_1-20_v1-2/en-valid/qa12_valid.txt\n",
            "tasks_1-20_v1-2/en-valid/qa17_test.txt\n",
            "tasks_1-20_v1-2/en-valid/qa10_valid.txt\n",
            "tasks_1-20_v1-2/hn-10k/\n",
            "tasks_1-20_v1-2/hn-10k/qa16_basic-induction_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa13_compound-coreference_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa13_compound-coreference_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa14_time-reasoning_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa5_three-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa17_positional-reasoning_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa9_simple-negation_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa12_conjunction_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa6_yes-no-questions_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa2_two-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa20_agents-motivations_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa7_counting_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa18_size-reasoning_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa1_single-supporting-fact_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa18_size-reasoning_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa1_single-supporting-fact_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa16_basic-induction_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa8_lists-sets_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa15_basic-deduction_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa11_basic-coreference_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa12_conjunction_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa10_indefinite-knowledge_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa19_path-finding_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa8_lists-sets_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa4_two-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa10_indefinite-knowledge_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa19_path-finding_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa20_agents-motivations_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa5_three-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa7_counting_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa3_three-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa14_time-reasoning_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa17_positional-reasoning_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa9_simple-negation_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa4_two-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa6_yes-no-questions_test.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa15_basic-deduction_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa3_three-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa2_two-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/hn-10k/qa11_basic-coreference_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/\n",
            "tasks_1-20_v1-2/shuffled-10k/qa16_basic-induction_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa13_compound-coreference_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa13_compound-coreference_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa14_time-reasoning_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa5_three-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa17_positional-reasoning_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa9_simple-negation_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa12_conjunction_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa6_yes-no-questions_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa2_two-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa20_agents-motivations_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa7_counting_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa18_size-reasoning_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa1_single-supporting-fact_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa18_size-reasoning_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa1_single-supporting-fact_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa16_basic-induction_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa8_lists-sets_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa15_basic-deduction_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa11_basic-coreference_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa12_conjunction_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa10_indefinite-knowledge_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa19_path-finding_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa8_lists-sets_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa4_two-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa10_indefinite-knowledge_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa19_path-finding_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa20_agents-motivations_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa5_three-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa7_counting_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa3_three-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa14_time-reasoning_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa17_positional-reasoning_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa9_simple-negation_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa4_two-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa6_yes-no-questions_test.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa15_basic-deduction_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa3_three-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa2_two-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/shuffled-10k/qa11_basic-coreference_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/\n",
            "tasks_1-20_v1-2/en-valid-10k/qa8_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa11_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa7_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa13_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa7_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa19_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa12_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa18_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa6_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa9_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa8_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa2_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa12_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa11_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa9_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa1_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa7_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa16_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa4_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa2_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa5_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa16_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa18_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa13_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa11_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa1_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa5_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa15_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa20_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa18_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa19_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa9_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa17_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa15_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa5_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa20_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa14_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa4_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa15_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa10_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa8_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa6_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa17_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa10_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa3_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa3_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa16_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa3_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa14_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa19_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa4_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa1_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa2_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa13_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa20_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa6_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa14_train.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa12_valid.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa17_test.txt\n",
            "tasks_1-20_v1-2/en-valid-10k/qa10_valid.txt\n",
            "tasks_1-20_v1-2/en/\n",
            "tasks_1-20_v1-2/en/qa16_basic-induction_train.txt\n",
            "tasks_1-20_v1-2/en/qa13_compound-coreference_train.txt\n",
            "tasks_1-20_v1-2/en/qa13_compound-coreference_test.txt\n",
            "tasks_1-20_v1-2/en/qa14_time-reasoning_test.txt\n",
            "tasks_1-20_v1-2/en/qa5_three-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/en/qa17_positional-reasoning_train.txt\n",
            "tasks_1-20_v1-2/en/qa9_simple-negation_train.txt\n",
            "tasks_1-20_v1-2/en/qa12_conjunction_train.txt\n",
            "tasks_1-20_v1-2/en/qa6_yes-no-questions_train.txt\n",
            "tasks_1-20_v1-2/en/qa2_two-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/en/qa20_agents-motivations_train.txt\n",
            "tasks_1-20_v1-2/en/qa7_counting_train.txt\n",
            "tasks_1-20_v1-2/en/qa18_size-reasoning_test.txt\n",
            "tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\n",
            "tasks_1-20_v1-2/en/qa18_size-reasoning_train.txt\n",
            "tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\n",
            "tasks_1-20_v1-2/en/qa16_basic-induction_test.txt\n",
            "tasks_1-20_v1-2/en/qa8_lists-sets_train.txt\n",
            "tasks_1-20_v1-2/en/qa15_basic-deduction_test.txt\n",
            "tasks_1-20_v1-2/en/qa11_basic-coreference_train.txt\n",
            "tasks_1-20_v1-2/en/qa12_conjunction_test.txt\n",
            "tasks_1-20_v1-2/en/qa10_indefinite-knowledge_test.txt\n",
            "tasks_1-20_v1-2/en/qa19_path-finding_test.txt\n",
            "tasks_1-20_v1-2/en/qa8_lists-sets_test.txt\n",
            "tasks_1-20_v1-2/en/qa4_two-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/en/qa10_indefinite-knowledge_train.txt\n",
            "tasks_1-20_v1-2/en/qa19_path-finding_train.txt\n",
            "tasks_1-20_v1-2/en/qa20_agents-motivations_test.txt\n",
            "tasks_1-20_v1-2/en/qa5_three-arg-relations_train.txt\n",
            "tasks_1-20_v1-2/en/qa7_counting_test.txt\n",
            "tasks_1-20_v1-2/en/qa3_three-supporting-facts_test.txt\n",
            "tasks_1-20_v1-2/en/qa14_time-reasoning_train.txt\n",
            "tasks_1-20_v1-2/en/qa17_positional-reasoning_test.txt\n",
            "tasks_1-20_v1-2/en/qa9_simple-negation_test.txt\n",
            "tasks_1-20_v1-2/en/qa4_two-arg-relations_test.txt\n",
            "tasks_1-20_v1-2/en/qa6_yes-no-questions_test.txt\n",
            "tasks_1-20_v1-2/en/qa15_basic-deduction_train.txt\n",
            "tasks_1-20_v1-2/en/qa3_three-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/en/qa2_two-supporting-facts_train.txt\n",
            "tasks_1-20_v1-2/en/qa11_basic-coreference_test.txt\n",
            "tasks_1-20_v1-2/LICENSE.txt\n",
            "tasks_1-20_v1-2/README.txt\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "uVmnoIp4DsJx",
        "colab_type": "code",
        "outputId": "ec96e268-5370-4227-8aed-55c5903edbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#資料前處理所需的function\n",
        "\n",
        "from __future__ import division, print_function\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Activation, Dense, Dropout, Permute\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.merge import add, concatenate, dot\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils\n",
        "import collections\n",
        "import itertools\n",
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def get_data(infile):\n",
        "    stories, questions, answers = [], [], []\n",
        "    story_text = []\n",
        "    fin = open(TRAIN_FILE, \"rb\")\n",
        "    for line in fin:\n",
        "        line = line.decode(\"utf-8\").strip()\n",
        "        lno, text = line.split(\" \", 1)\n",
        "        if \"\\t\" in text:\n",
        "            question, answer, _ = text.split(\"\\t\")\n",
        "            stories.append(story_text)\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "            story_text = []\n",
        "        else:\n",
        "            story_text.append(text)\n",
        "    fin.close()\n",
        "    return stories, questions, answers\n",
        "\n",
        "\n",
        "def build_vocab(train_data, test_data):\n",
        "    counter = collections.Counter()\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            for sent in story:\n",
        "                for word in nltk.word_tokenize(sent):\n",
        "                    counter[word.lower()] += 1\n",
        "        for question in questions:\n",
        "            for word in nltk.word_tokenize(question):\n",
        "                counter[word.lower()] += 1\n",
        "        for answer in answers:\n",
        "            for word in nltk.word_tokenize(answer):\n",
        "                counter[word.lower()] += 1\n",
        "    # no OOV here because there are not too many words in dataset\n",
        "    word2idx = {w: (i+1) for i, (w, _) in enumerate(counter.most_common())}\n",
        "    word2idx[\"PAD\"] = 0\n",
        "    idx2word = {v: k for k, v in word2idx.items()}\n",
        "    return word2idx, idx2word\n",
        "\n",
        "\n",
        "def get_maxlens(train_data, test_data):\n",
        "    story_maxlen, question_maxlen = 0, 0\n",
        "    for stories, questions, _ in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            story_len = 0\n",
        "            for sent in story:\n",
        "                swords = nltk.word_tokenize(sent)\n",
        "                story_len += len(swords)\n",
        "            if story_len > story_maxlen:\n",
        "                story_maxlen = story_len\n",
        "        for question in questions:\n",
        "            question_len = len(nltk.word_tokenize(question))\n",
        "            if question_len > question_maxlen:\n",
        "                question_maxlen = question_len\n",
        "    return story_maxlen, question_maxlen\n",
        "\n",
        "\n",
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        print ('Story:',story)\n",
        "        print ('Question:',question)\n",
        "        print ('Answer:',answer)\n",
        "        xs = [[word2idx[w.lower()] for w in nltk.word_tokenize(s)]\n",
        "              for s in story]\n",
        "        xs = list(itertools.chain.from_iterable(xs))\n",
        "        xq = [word2idx[w.lower()] for w in nltk.word_tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer.lower()])\n",
        "        pad_sequences_Xs = pad_sequences(Xs, maxlen=story_maxlen)\n",
        "        pad_sequences_Xq = pad_sequences(Xq, maxlen=question_maxlen)\n",
        "        categorical_Y = np_utils.to_categorical(Y, num_classes=len(word2idx))\n",
        "\n",
        "    return pad_sequences_Xs, pad_sequences_Xq, categorical_Y\n",
        "  \n",
        "  \n",
        "  \n",
        "# Tensorboard\n",
        "\n",
        "#安裝tensorboard colab\n",
        "!pip install tensorboardcolab\n",
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorboardcolab import *\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tbc=TensorBoardColab()\n",
        "    #tensorboard = TensorBoard(log_dir=log_dir)\n",
        "    tensorboard = TensorBoardColabCallback(tbc,histogram_freq=1,embeddings_freq=1,  embeddings_layer_names = ['embedded_text','embedded_question'], embeddings_data = [Xstrain, Xqtrain] ) #, embeddings_metadata = '/content/logs/' + meta_file\n",
        "    # ['embedded_text','embedded_question']\n",
        "    return tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kwgmCfsRD4WX",
        "colab_type": "code",
        "outputId": "0c9583b0-5ecf-461d-bd71-27130f87e25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "DATA_DIR = \"tasks_1-20_v1-2/en\"\n",
        "\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")\n",
        "\n",
        "# get the data\n",
        "data_train = get_data(TRAIN_FILE)\n",
        "data_test = get_data(TEST_FILE)\n",
        "\n",
        "print(len(data_train[0]), len(data_test[0]))\n",
        "\n",
        "# build vocabulary from all the data\n",
        "word2idx, idx2word = build_vocab(data_train, data_test)\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "print(\"vocab size: {:d}\".format(len(word2idx)))\n",
        "\n",
        "# compute max sequence length for each entity\n",
        "story_maxlen, question_maxlen = get_maxlens(data_train, data_test)\n",
        "print(\"story maxlen: {:d}, \"\n",
        "      \"question maxlen: {:d}\".format(story_maxlen, question_maxlen))\n",
        "\n",
        "meta_file = \"w2v_metadata.tsv\"\n",
        "# 按照 id 排序\n",
        "word2idx_sorted = [(k, word2idx[k]) for k in sorted(word2idx, key = word2idx.get, reverse = False)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 1000\n",
            "vocab size: 22\n",
            "story maxlen: 14, question maxlen: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kuxOTNwe-jKV",
        "colab_type": "code",
        "outputId": "3ae40434-2cf3-494f-9089-e317c7f215fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "word2idx_sorted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('PAD', 0),\n",
              " ('to', 1),\n",
              " ('the', 2),\n",
              " ('.', 3),\n",
              " ('where', 4),\n",
              " ('is', 5),\n",
              " ('?', 6),\n",
              " ('went', 7),\n",
              " ('sandra', 8),\n",
              " ('john', 9),\n",
              " ('daniel', 10),\n",
              " ('mary', 11),\n",
              " ('hallway', 12),\n",
              " ('kitchen', 13),\n",
              " ('garden', 14),\n",
              " ('office', 15),\n",
              " ('bedroom', 16),\n",
              " ('bathroom', 17),\n",
              " ('journeyed', 18),\n",
              " ('travelled', 19),\n",
              " ('moved', 20),\n",
              " ('back', 21)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "PTKHA-UKFSKt",
        "colab_type": "code",
        "outputId": "b1e60063-5fb6-4b98-ad59-b48c285f9b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109126
        }
      },
      "cell_type": "code",
      "source": [
        "# vectorize the data\n",
        "Xstrain, Xqtrain, Ytrain = \\\n",
        "    vectorize(data_train, word2idx, story_maxlen, question_maxlen)\n",
        "Xstest, Xqtest, Ytest = \\\n",
        "    vectorize(data_test, word2idx, story_maxlen, question_maxlen)\n",
        "\n",
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape,\n",
        "      Xstest.shape, Xqtest.shape, Ytest.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Story: ['Mary moved to the bathroom.', 'John went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the office.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the hallway.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'John moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the office.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the garden.', 'John travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went to the bedroom.', 'John travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the bedroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'John journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the bedroom.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the office.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the garden.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the office.', 'John moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the hallway.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'John moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the kitchen.', 'John went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the office.', 'Daniel went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the hallway.', 'Mary went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bedroom.', 'John travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John moved to the bedroom.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the bedroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the garden.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bathroom.', 'Mary moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the kitchen.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bedroom.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the hallway.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra went back to the bathroom.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bedroom.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the garden.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the garden.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the bathroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the kitchen.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the garden.', 'John went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bathroom.', 'Mary moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the hallway.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went to the office.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the office.', 'John went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went to the hallway.', 'Mary journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the hallway.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'Sandra went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the hallway.', 'John moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the bedroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the garden.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the kitchen.', 'Mary travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the hallway.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the kitchen.', 'Sandra went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the office.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the kitchen.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the garden.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the bedroom.', 'Mary journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'Sandra went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the bathroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the bedroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the bathroom.', 'John went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel moved to the bathroom.', 'Daniel went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the office.', 'Sandra went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'John journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bathroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the garden.', 'Sandra moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the kitchen.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the hallway.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the garden.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bedroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the office.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'John moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the hallway.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the office.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the garden.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the office.', 'John travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the hallway.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the bathroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the office.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the hallway.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bedroom.', 'John travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went back to the kitchen.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the hallway.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the bathroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bedroom.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bathroom.', 'John went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the office.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the garden.', 'John travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the office.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the kitchen.', 'Daniel travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the bathroom.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'John went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the hallway.', 'Mary travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the bedroom.', 'John went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the bathroom.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John went to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the garden.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the hallway.', 'Mary moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the kitchen.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the kitchen.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the office.', 'John journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John travelled to the bathroom.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the office.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John moved to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the hallway.', 'Sandra went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the office.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'Daniel moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the bathroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'Mary went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the office.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bedroom.', 'John went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the kitchen.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the office.', 'John went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Daniel moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the kitchen.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the garden.', 'Sandra went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the bedroom.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the hallway.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the office.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the garden.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the bathroom.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bathroom.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the hallway.', 'John travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'John moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the bathroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Mary moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the office.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bathroom.', 'John moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the office.', 'John went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the office.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary travelled to the hallway.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bedroom.', 'Mary went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the hallway.', 'John travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bathroom.', 'John journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the office.', 'John travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the office.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the bathroom.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the office.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the garden.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Daniel travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the office.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary went to the bathroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the office.', 'John went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John moved to the office.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the hallway.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bedroom.', 'Daniel travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the hallway.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bedroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'John journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bathroom.', 'Mary moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bedroom.', 'John moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the hallway.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the office.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the bedroom.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the hallway.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the kitchen.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the garden.', 'John moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the garden.', 'Daniel went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the kitchen.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the bathroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary moved to the hallway.', 'Mary went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bathroom.', 'Mary journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the garden.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went back to the hallway.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the bathroom.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the office.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the bathroom.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bathroom.', 'Sandra went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the hallway.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the bedroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'Mary went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bathroom.', 'Mary went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the office.', 'Mary went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the garden.', 'John moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the bathroom.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the garden.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the bathroom.', 'John moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the kitchen.', 'Daniel travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the office.', 'Mary went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the bedroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the hallway.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John went back to the garden.', 'John travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the garden.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the bathroom.', 'John went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the hallway.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the kitchen.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'John moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel moved to the hallway.', 'John moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the kitchen.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bathroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the hallway.', 'John travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bedroom.', 'Daniel went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the hallway.', 'Mary went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary journeyed to the garden.', 'John went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the bathroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the office.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bathroom.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the kitchen.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the bathroom.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the kitchen.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the garden.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the kitchen.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bedroom.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went back to the kitchen.', 'Mary went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Sandra went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went to the office.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John travelled to the hallway.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bathroom.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the garden.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the bathroom.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the kitchen.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the kitchen.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the garden.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the hallway.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Mary went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the bedroom.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the garden.', 'Mary went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bedroom.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the garden.', 'Daniel went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the garden.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the office.', 'Mary moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the kitchen.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the kitchen.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the kitchen.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the office.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the bedroom.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the bedroom.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bedroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went to the hallway.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the hallway.', 'John went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the office.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the garden.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the garden.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the hallway.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the hallway.', 'Daniel went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the garden.', 'John moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the office.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Sandra went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the bathroom.', 'John journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the hallway.', 'John moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the garden.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the kitchen.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the office.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bedroom.', 'John went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'Sandra travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the hallway.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the hallway.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the kitchen.', 'John went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the office.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the office.', 'Mary went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the bedroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bedroom.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'Mary moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the bathroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the office.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the garden.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the bathroom.', 'Mary moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went to the hallway.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Daniel went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the garden.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the hallway.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the garden.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the garden.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the bathroom.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the office.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the hallway.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the bedroom.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the office.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John travelled to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the office.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Mary journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bathroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bedroom.', 'Mary went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John travelled to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the hallway.', 'Mary went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'Mary went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the hallway.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the hallway.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the office.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the bedroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the office.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bathroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'Sandra went to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Mary travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bedroom.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the bedroom.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Mary moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the bedroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the garden.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bedroom.', 'John went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the kitchen.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the garden.', 'Daniel went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the office.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the office.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the bathroom.', 'John went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the office.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the garden.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the hallway.', 'John went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bedroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the garden.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Mary travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John went back to the bathroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the office.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the bedroom.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the garden.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the office.', 'John moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bedroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the kitchen.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bedroom.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the hallway.', 'John went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the garden.', 'Mary went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the hallway.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the hallway.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the office.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John went to the bedroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Mary went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the bathroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the hallway.', 'John went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went to the hallway.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bathroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the bedroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the hallway.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the kitchen.', 'John went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the office.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the office.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'John moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the bathroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the kitchen.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the bedroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the office.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the kitchen.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the hallway.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the bedroom.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the bedroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Sandra went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the kitchen.', 'Daniel went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the office.', 'John travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the bedroom.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the office.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the office.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the office.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the kitchen.', 'Mary went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John moved to the bathroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the garden.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the hallway.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bathroom.', 'Mary went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the office.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the garden.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the bedroom.', 'Mary went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the hallway.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'John went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the hallway.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'Mary went to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the office.', 'Mary went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the kitchen.', 'John moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the garden.', 'John moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bathroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the garden.', 'Mary travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the kitchen.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the kitchen.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bedroom.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bathroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the office.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the hallway.', 'John moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary travelled to the bedroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the hallway.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the kitchen.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the garden.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the office.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the office.', 'Mary moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Mary journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the bathroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the kitchen.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John travelled to the bedroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John travelled to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the bedroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the hallway.', 'Mary journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the bathroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the office.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the office.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the garden.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the office.', 'Mary went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the bathroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the hallway.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the bathroom.', 'Daniel went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the kitchen.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the office.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John moved to the hallway.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the garden.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary journeyed to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the office.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the office.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the bedroom.', 'Sandra went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the hallway.', 'Sandra went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the bedroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the kitchen.', 'Sandra went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the bedroom.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the garden.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the bedroom.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the garden.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the garden.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the office.', 'Mary journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the bedroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the office.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the garden.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the hallway.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the office.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the office.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the garden.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the garden.', 'Mary went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the kitchen.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the garden.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the office.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the bathroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the garden.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the bathroom.', 'John moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the kitchen.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the office.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the bedroom.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the garden.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the kitchen.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the office.', 'Daniel moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the kitchen.', 'John travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the kitchen.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the hallway.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the hallway.', 'Sandra went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the garden.', 'Sandra went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the garden.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the bedroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'Sandra went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the hallway.', 'John moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the bedroom.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the office.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the bathroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the garden.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the garden.', 'Mary went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the kitchen.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the hallway.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the hallway.', 'John travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel travelled to the garden.', 'Mary moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the garden.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the hallway.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the office.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the garden.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the hallway.', 'Mary moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the garden.', 'Mary went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bedroom.', 'John went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went back to the hallway.', 'John went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the office.', 'John travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the bedroom.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the office.', 'John moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the hallway.', 'Daniel moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bathroom.', 'Mary went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bathroom.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the hallway.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John went to the kitchen.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the kitchen.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the hallway.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the garden.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the kitchen.', 'Sandra moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bedroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the hallway.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the office.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the kitchen.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'John journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the hallway.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'Daniel went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel went back to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bathroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the kitchen.', 'Sandra went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bedroom.', 'Mary moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the kitchen.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the office.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the office.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the office.', 'Sandra journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the garden.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the kitchen.', 'Sandra went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the kitchen.', 'John went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the garden.', 'Mary journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the hallway.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Mary moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the kitchen.', 'John went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the kitchen.', 'John journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the office.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the bedroom.', 'John went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the bedroom.', 'Mary travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went back to the kitchen.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the bathroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'John went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the office.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John moved to the bedroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the garden.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the office.', 'Daniel moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the hallway.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the kitchen.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Daniel went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the bedroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bedroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bedroom.', 'Sandra moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the bathroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the hallway.', 'John went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the kitchen.', 'John went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the bathroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the garden.', 'Mary went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the kitchen.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bathroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Daniel went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Mary went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the office.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the garden.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bathroom.', 'Mary went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the garden.', 'John moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the hallway.', 'John journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the garden.', 'Sandra went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Mary went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the hallway.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went to the kitchen.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the garden.', 'Mary went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the hallway.', 'Mary went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the office.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the garden.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the office.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the bedroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the hallway.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the hallway.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'John went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the garden.', 'Sandra went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the hallway.', 'Mary went back to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the kitchen.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'John journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the office.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the kitchen.', 'John went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went back to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the hallway.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the garden.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the office.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the bedroom.', 'John went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the garden.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went to the garden.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the bathroom.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary moved to the bedroom.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the office.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the office.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the bathroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the kitchen.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the kitchen.', 'Daniel moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the hallway.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the hallway.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the kitchen.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the garden.', 'John journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the garden.', 'Daniel went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'Daniel moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the hallway.', 'John went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the kitchen.', 'Mary travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bathroom.', 'John went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bathroom.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the garden.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the office.', 'Mary travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the garden.', 'John moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the bedroom.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John moved to the office.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'John travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the kitchen.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bedroom.', 'Daniel went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Daniel went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'Daniel went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the bathroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the hallway.', 'John went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bedroom.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the garden.', 'John travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the hallway.', 'Sandra went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bathroom.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the bathroom.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the bathroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the hallway.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the bedroom.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the office.', 'John went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the bedroom.', 'John went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John moved to the hallway.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the garden.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the hallway.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went to the kitchen.', 'John went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the office.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the bedroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John moved to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bedroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the office.', 'John went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the hallway.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the garden.', 'Daniel journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the kitchen.', 'Daniel went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the bedroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the garden.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the hallway.', 'John went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the hallway.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel moved to the hallway.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the bathroom.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the garden.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the bathroom.', 'John went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went to the hallway.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary journeyed to the bathroom.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the garden.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the office.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the hallway.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the kitchen.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the hallway.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the bedroom.', 'John travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary travelled to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the hallway.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the hallway.', 'John went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bedroom.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the office.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the garden.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the kitchen.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the bathroom.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bedroom.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the bathroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the kitchen.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the bathroom.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the kitchen.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the garden.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bedroom.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the hallway.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bedroom.', 'Daniel travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the garden.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bedroom.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the bathroom.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'John journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the bedroom.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the office.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the office.', 'John went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the garden.', 'Mary went back to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the hallway.', 'John travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the garden.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the kitchen.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the bedroom.', 'Mary moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the bedroom.', 'Sandra went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the hallway.', 'Mary went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the kitchen.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the bedroom.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the kitchen.', 'John journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the bedroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the bedroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the garden.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the hallway.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bathroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the office.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the garden.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went to the bedroom.', 'John went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the garden.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bathroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the garden.', 'John journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the kitchen.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bedroom.', 'John went to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John moved to the garden.', 'Daniel went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the office.', 'Mary went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the bathroom.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the bathroom.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the office.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the office.', 'Mary travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the garden.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bathroom.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John moved to the hallway.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the office.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the bedroom.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'Mary went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the office.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'Daniel moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the office.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bedroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the garden.', 'Mary travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the office.', 'Sandra went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the office.', 'Sandra went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the bedroom.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the kitchen.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the office.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the bedroom.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the office.', 'Mary went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the kitchen.', 'John went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the hallway.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary moved to the bathroom.', 'John went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the office.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the hallway.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'John moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the office.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the garden.', 'John travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went to the bedroom.', 'John travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the bedroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'John journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the bedroom.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the office.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the garden.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the office.', 'John moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the hallway.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'John moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the kitchen.', 'John went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the office.', 'Daniel went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the hallway.', 'Mary went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bedroom.', 'John travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John moved to the bedroom.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the bedroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the garden.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bathroom.', 'Mary moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the kitchen.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bedroom.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the hallway.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra went back to the bathroom.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bedroom.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the garden.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the garden.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the bathroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the kitchen.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the garden.', 'John went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bathroom.', 'Mary moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the hallway.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went to the office.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the office.', 'John went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went to the hallway.', 'Mary journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the hallway.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'Sandra went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the hallway.', 'John moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the bedroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the garden.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the kitchen.', 'Mary travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the hallway.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the kitchen.', 'Sandra went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the office.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the kitchen.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the garden.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the bedroom.', 'Mary journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'Sandra went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the bathroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the bedroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the bathroom.', 'John went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel moved to the bathroom.', 'Daniel went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the office.', 'Sandra went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'John journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bathroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the garden.', 'Sandra moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the kitchen.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the hallway.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the garden.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bedroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the office.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'John moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the hallway.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the office.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the garden.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the office.', 'John travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the hallway.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the bathroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the office.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the hallway.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bedroom.', 'John travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went back to the kitchen.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the hallway.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the bathroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bedroom.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bathroom.', 'John went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the office.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the garden.', 'John travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the office.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the kitchen.', 'Daniel travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the bathroom.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'John went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the hallway.', 'Mary travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the bedroom.', 'John went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the bathroom.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John went to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the garden.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the hallway.', 'Mary moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the kitchen.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the kitchen.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the office.', 'John journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John travelled to the bathroom.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the office.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John moved to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the hallway.', 'Sandra went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the office.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'Daniel moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the bathroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'Mary went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the office.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bedroom.', 'John went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the kitchen.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the office.', 'John went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Daniel moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the kitchen.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the garden.', 'Sandra went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the bedroom.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the hallway.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the office.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the garden.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the bathroom.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bathroom.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the hallway.', 'John travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'John moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the bathroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Mary moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the office.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bathroom.', 'John moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the office.', 'John went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the office.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary travelled to the hallway.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bedroom.', 'Mary went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the hallway.', 'John travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bathroom.', 'John journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the office.', 'John travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the office.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the bathroom.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the office.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the garden.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Daniel travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the office.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary went to the bathroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the office.', 'John went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John moved to the office.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the hallway.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bedroom.', 'Daniel travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the hallway.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bedroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'John journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bathroom.', 'Mary moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bedroom.', 'John moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the hallway.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the office.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the bedroom.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the hallway.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the kitchen.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the garden.', 'John moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the garden.', 'Daniel went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the kitchen.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the bathroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary moved to the hallway.', 'Mary went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bathroom.', 'Mary journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the garden.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went back to the hallway.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the bathroom.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the office.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the bathroom.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bathroom.', 'Sandra went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the hallway.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the bedroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'Mary went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bathroom.', 'Mary went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the office.', 'Mary went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the garden.', 'John moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the bathroom.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the garden.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the bathroom.', 'John moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the kitchen.', 'Daniel travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the office.', 'Mary went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the bedroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the hallway.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John went back to the garden.', 'John travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the garden.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the bathroom.', 'John went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the hallway.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the kitchen.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'John moved to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel moved to the hallway.', 'John moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the kitchen.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bathroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the hallway.', 'John travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bedroom.', 'Daniel went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the hallway.', 'Mary went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary journeyed to the garden.', 'John went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the bathroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the office.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bathroom.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the kitchen.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the bathroom.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the kitchen.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the garden.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the kitchen.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bedroom.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went back to the kitchen.', 'Mary went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Sandra went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went to the office.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John travelled to the hallway.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bathroom.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the garden.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the bathroom.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the kitchen.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the kitchen.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the garden.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the hallway.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Mary went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the bedroom.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the garden.', 'Mary went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bedroom.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the garden.', 'Daniel went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the garden.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the office.', 'Mary moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the kitchen.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the kitchen.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the kitchen.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the office.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the bedroom.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the bedroom.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bedroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went to the hallway.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the hallway.', 'John went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the office.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the garden.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the garden.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the hallway.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the hallway.', 'Daniel went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the garden.', 'John moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the office.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Sandra went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the bathroom.', 'John journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the hallway.', 'John moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the garden.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the kitchen.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the office.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bedroom.', 'John went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'Sandra travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the hallway.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the hallway.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the kitchen.', 'John went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the office.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the office.', 'Mary went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the bedroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bedroom.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'Mary moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the bathroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the office.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the garden.', 'John journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the bathroom.', 'Mary moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went to the hallway.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Daniel went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the garden.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the hallway.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the garden.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the garden.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the bathroom.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the office.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the hallway.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the bedroom.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the office.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John travelled to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the office.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Mary journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bathroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bedroom.', 'Mary went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John travelled to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the hallway.', 'Mary went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the office.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the office.', 'Mary went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the hallway.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the hallway.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the office.', 'Daniel travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the bedroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the office.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bathroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'Sandra went to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Mary travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bedroom.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the bedroom.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Mary moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the bedroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the garden.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bedroom.', 'John went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the kitchen.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the garden.', 'Daniel went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the office.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the office.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the bathroom.', 'John went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the office.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the garden.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the hallway.', 'John went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bedroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the garden.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Mary travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John went back to the bathroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the office.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the bedroom.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the garden.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the office.', 'John moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bedroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the kitchen.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bedroom.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the hallway.', 'John went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the garden.', 'Mary went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the hallway.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the hallway.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bedroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the office.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John went to the bedroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the garden.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Mary went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the bathroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the hallway.', 'John went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went to the hallway.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went back to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bathroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the bedroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the hallway.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the kitchen.', 'John went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the office.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the office.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'John moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the bathroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the kitchen.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the bedroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the office.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the kitchen.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the kitchen.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the hallway.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the bedroom.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the bedroom.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Sandra went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the kitchen.', 'Daniel went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the office.', 'John travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the bedroom.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the office.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the office.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the office.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the kitchen.', 'Mary went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John moved to the bathroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the hallway.', 'John went back to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the garden.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the hallway.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bathroom.', 'Mary went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the office.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the garden.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the bedroom.', 'Mary went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the hallway.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'John went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the hallway.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'Mary went to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the office.', 'Mary went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the kitchen.', 'John moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the garden.', 'John moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bathroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the garden.', 'Mary travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the kitchen.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the kitchen.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bedroom.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bathroom.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the office.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the kitchen.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the hallway.', 'John moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary travelled to the bedroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the hallway.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the kitchen.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the garden.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the office.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the office.', 'Mary moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Mary journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the bathroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the kitchen.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John travelled to the bedroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John travelled to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the bedroom.', 'Daniel moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the hallway.', 'Mary journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the bathroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the office.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the office.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the garden.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the office.', 'Mary went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the bathroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the bedroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the hallway.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the bathroom.', 'Daniel went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the kitchen.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the garden.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the office.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the kitchen.', 'Mary moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John moved to the hallway.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the garden.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary journeyed to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the office.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the office.', 'Sandra went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the bedroom.', 'Sandra went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the hallway.', 'Sandra went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the bedroom.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the bedroom.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the bedroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the kitchen.', 'Sandra went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the bedroom.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the garden.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the bedroom.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the garden.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the garden.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the office.', 'Mary journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the bedroom.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the office.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel journeyed to the garden.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the hallway.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the office.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the office.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the garden.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the garden.', 'Mary went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the kitchen.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the garden.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the office.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the bathroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the garden.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the bathroom.', 'John moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the kitchen.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the office.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the bedroom.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Daniel went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary travelled to the garden.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the kitchen.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the office.', 'Daniel moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the kitchen.', 'John travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the kitchen.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the office.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the hallway.', 'Daniel journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the hallway.', 'Sandra went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the garden.', 'Sandra went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the garden.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the bedroom.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'Sandra went back to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the hallway.', 'John moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the bedroom.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the office.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the bathroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the garden.', 'John moved to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the garden.', 'Mary went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the kitchen.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the hallway.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the hallway.', 'John travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel travelled to the garden.', 'Mary moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the garden.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the hallway.', 'John travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the office.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the garden.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the hallway.', 'Mary moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the garden.', 'Mary went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the bedroom.', 'John went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went back to the hallway.', 'John went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the office.', 'John travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the bedroom.', 'Daniel journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the hallway.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John went to the office.', 'John moved to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the hallway.', 'Daniel moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bathroom.', 'Mary went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the garden.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bathroom.', 'Sandra travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the hallway.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John went to the kitchen.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the kitchen.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the hallway.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the garden.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the kitchen.', 'Sandra moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bedroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went back to the hallway.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the office.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the kitchen.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'John journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the kitchen.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the hallway.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'Daniel went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the kitchen.', 'Daniel went back to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'John went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bedroom.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bathroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra moved to the kitchen.', 'Sandra went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bedroom.', 'Mary moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the kitchen.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the kitchen.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the office.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John travelled to the office.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the bedroom.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the office.', 'Sandra journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the garden.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the kitchen.', 'Sandra went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the kitchen.', 'John went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the garden.', 'Mary journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John went to the hallway.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the hallway.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Mary moved to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the kitchen.', 'John went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the kitchen.', 'John journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the office.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Sandra travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the bedroom.', 'John went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the bedroom.', 'Mary travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the office.', 'Sandra went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went back to the kitchen.', 'Mary went back to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Mary journeyed to the bathroom.', 'Daniel travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bathroom.', 'John went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the bathroom.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the office.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['John moved to the bedroom.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the garden.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the office.', 'Daniel moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the hallway.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel moved to the kitchen.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel travelled to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Daniel went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the bedroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bedroom.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the hallway.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the bedroom.', 'Sandra moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went to the bathroom.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the hallway.', 'John went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the kitchen.', 'John went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the bathroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the office.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the garden.', 'Mary went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bedroom.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the kitchen.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the kitchen.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bathroom.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Daniel went back to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra moved to the bathroom.', 'Mary went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the office.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'John moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the garden.', 'Sandra journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bathroom.', 'Mary went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the garden.', 'John moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the office.', 'Mary went to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went back to the hallway.', 'John journeyed to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the garden.', 'Sandra went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the garden.', 'Mary journeyed to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the bedroom.', 'Mary went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the hallway.', 'Mary travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John went to the kitchen.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the garden.', 'Mary went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the hallway.', 'Mary went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the office.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the garden.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the office.', 'Mary travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the bedroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the hallway.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the garden.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the hallway.', 'John journeyed to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'John went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the garden.', 'Sandra went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John travelled to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the hallway.', 'Mary went back to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary went back to the kitchen.', 'John went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the kitchen.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the office.', 'John journeyed to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the office.', 'Mary moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Sandra went to the kitchen.', 'John went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra went back to the hallway.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the hallway.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the garden.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary journeyed to the garden.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the office.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the bedroom.', 'John went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['John moved to the garden.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went to the garden.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the bathroom.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary moved to the bedroom.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the garden.', 'John went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the office.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the office.', 'Mary travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the bathroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the kitchen.', 'Mary went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the kitchen.', 'Daniel moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the hallway.', 'Mary moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the hallway.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went to the bedroom.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the kitchen.', 'Sandra travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary moved to the garden.', 'John journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the bedroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the garden.', 'Daniel went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the office.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went back to the garden.', 'Daniel moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the hallway.', 'John went back to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the kitchen.', 'Mary travelled to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bathroom.', 'John went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the bathroom.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the garden.', 'Mary went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went to the office.', 'Mary travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel journeyed to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['John went to the garden.', 'John moved to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the bedroom.', 'Mary went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John moved to the office.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the office.', 'John travelled to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the kitchen.', 'Sandra journeyed to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the kitchen.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the bedroom.', 'Daniel went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the garden.', 'Daniel went back to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went to the kitchen.', 'Daniel went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the bathroom.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the hallway.', 'John went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bedroom.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the garden.', 'Daniel moved to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the hallway.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the garden.', 'John travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['John journeyed to the office.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the hallway.', 'Sandra went to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the hallway.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the bathroom.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the bathroom.', 'Daniel went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the kitchen.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the bathroom.', 'John travelled to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel went to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the hallway.', 'John journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John went to the bedroom.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['John travelled to the office.', 'John went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the bedroom.', 'John went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John moved to the hallway.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the garden.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went to the hallway.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John went to the kitchen.', 'John went back to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the office.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the hallway.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary journeyed to the bedroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the garden.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['John moved to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the bedroom.', 'Sandra moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel travelled to the office.', 'John went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John moved to the hallway.', 'Sandra went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the garden.', 'Daniel journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the bedroom.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the kitchen.', 'Daniel went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary travelled to the bedroom.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the garden.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Sandra journeyed to the hallway.', 'John went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['John moved to the hallway.', 'Daniel journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Daniel moved to the hallway.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the bathroom.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the garden.', 'Sandra moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel journeyed to the bathroom.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went to the bathroom.', 'John went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra went to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went to the hallway.', 'Daniel travelled to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary journeyed to the bathroom.', 'Daniel journeyed to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went back to the garden.', 'Daniel travelled to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Mary went to the office.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['Mary went to the hallway.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['John travelled to the kitchen.', 'Daniel went to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John went back to the hallway.', 'John moved to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the bedroom.', 'John travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the bathroom.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Mary travelled to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra journeyed to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the hallway.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary moved to the bathroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the hallway.', 'John went to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Sandra travelled to the bedroom.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the garden.', 'Daniel went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel moved to the garden.', 'Sandra travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the office.', 'Daniel moved to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the garden.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the kitchen.', 'Sandra moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the kitchen.', 'Daniel went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the bathroom.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra went back to the bedroom.', 'Mary went back to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary moved to the bathroom.', 'Mary went to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bathroom.', 'Sandra went back to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bathroom\n",
            "Story: ['Mary moved to the kitchen.', 'John journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary moved to the bathroom.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John went to the kitchen.', 'John went to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra moved to the garden.', 'Sandra went back to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the bedroom.', 'Sandra went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the hallway.', 'Daniel journeyed to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Daniel travelled to the bedroom.', 'Daniel travelled to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the garden.', 'Daniel went back to the kitchen.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the bedroom.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the hallway.', 'John went back to the bedroom.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel journeyed to the bathroom.', 'John went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['John went to the kitchen.', 'John journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the bedroom.', 'John journeyed to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the office.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bathroom\n",
            "Story: ['John journeyed to the garden.', 'Sandra went to the bathroom.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the office.', 'John went back to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary journeyed to the bedroom.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the garden.', 'Mary went back to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Daniel went to the hallway.', 'John travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: hallway\n",
            "Story: ['Mary went to the garden.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John moved to the kitchen.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the bedroom.', 'Mary moved to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the bathroom.', 'Mary travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the bedroom.', 'Sandra went back to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the bathroom.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the hallway.', 'Mary went to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the kitchen.', 'Sandra moved to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary went back to the bedroom.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the bedroom.', 'Daniel went to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra journeyed to the garden.', 'Sandra travelled to the office.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Mary travelled to the office.', 'Mary journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: office\n",
            "Story: ['Daniel journeyed to the kitchen.', 'John journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the bedroom.', 'Sandra journeyed to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary travelled to the bedroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the garden.', 'Sandra went back to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Daniel moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra journeyed to the hallway.', 'Mary moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went back to the office.', 'Sandra moved to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra moved to the kitchen.', 'Daniel moved to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra went to the hallway.', 'Mary journeyed to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: hallway\n",
            "Story: ['John went back to the bathroom.', 'John travelled to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra moved to the office.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John travelled to the garden.', 'Mary moved to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went to the bedroom.', 'John went back to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the garden.', 'John went to the office.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bathroom.', 'Sandra journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['Mary went back to the bedroom.', 'Daniel travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel went back to the garden.', 'John journeyed to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel moved to the kitchen.', 'Mary journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bedroom.', 'John went to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['John journeyed to the bathroom.', 'Sandra journeyed to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['John moved to the garden.', 'Daniel went back to the office.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the office.', 'Mary went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Daniel went back to the hallway.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra journeyed to the bathroom.', 'Sandra went to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went to the bathroom.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['Sandra went to the bathroom.', 'John journeyed to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Daniel went to the office.', 'John went to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel travelled to the kitchen.', 'Mary journeyed to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went back to the office.', 'Mary travelled to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the hallway.', 'John travelled to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: garden\n",
            "Story: ['Sandra went to the kitchen.', 'John journeyed to the kitchen.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the garden.', 'Mary travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra went back to the bathroom.', 'Daniel journeyed to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "Story: ['John moved to the hallway.', 'Mary moved to the bathroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bathroom\n",
            "Story: ['John went back to the office.', 'Mary went to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Sandra moved to the bedroom.', 'John travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the hallway.', 'Mary went to the hallway.']\n",
            "Question: Where is Daniel? \n",
            "Answer: hallway\n",
            "Story: ['Mary travelled to the office.', 'Sandra moved to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['John went back to the hallway.', 'Daniel moved to the garden.']\n",
            "Question: Where is Sandra? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel moved to the office.', 'Daniel travelled to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: bedroom\n",
            "Story: ['Mary went to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is John? \n",
            "Answer: hallway\n",
            "Story: ['Sandra went back to the bedroom.', 'John travelled to the kitchen.']\n",
            "Question: Where is Mary? \n",
            "Answer: kitchen\n",
            "Story: ['Mary went back to the garden.', 'Mary travelled to the office.']\n",
            "Question: Where is John? \n",
            "Answer: kitchen\n",
            "Story: ['John journeyed to the office.', 'Sandra went to the office.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Sandra journeyed to the kitchen.', 'John travelled to the hallway.']\n",
            "Question: Where is Mary? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the office.', 'Sandra went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['John journeyed to the bedroom.', 'Mary went back to the bathroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel went back to the kitchen.', 'Mary travelled to the bedroom.']\n",
            "Question: Where is Mary? \n",
            "Answer: bedroom\n",
            "Story: ['John went back to the office.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: kitchen\n",
            "Story: ['Daniel went to the bedroom.', 'John went back to the garden.']\n",
            "Question: Where is John? \n",
            "Answer: garden\n",
            "Story: ['Sandra travelled to the hallway.', 'Sandra went to the bedroom.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Daniel moved to the office.', 'Mary went to the hallway.']\n",
            "Question: Where is Sandra? \n",
            "Answer: bedroom\n",
            "Story: ['Mary journeyed to the kitchen.', 'John went back to the bedroom.']\n",
            "Question: Where is Daniel? \n",
            "Answer: office\n",
            "Story: ['Daniel travelled to the kitchen.', 'Sandra travelled to the kitchen.']\n",
            "Question: Where is John? \n",
            "Answer: bedroom\n",
            "Story: ['Sandra travelled to the hallway.', 'Daniel went to the garden.']\n",
            "Question: Where is Daniel? \n",
            "Answer: garden\n",
            "(1000, 14) (1000, 4) (1000, 22) (1000, 14) (1000, 4) (1000, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-mee_PSIFoxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists, join\n",
        "from os import makedirs\n",
        "import keras.backend as K\n",
        "K.clear_session()\n",
        "# define network\n",
        "EMBEDDING_SIZE = 64\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 400\n",
        "log_dir = './logs'\n",
        "if not exists(log_dir):\n",
        "    makedirs(log_dir)\n",
        "    \n",
        "\n",
        "meta_file = \"w2v_metadata.tsv\"    \n",
        "with open(os.path.join(log_dir, meta_file), 'w+') as file_metadata:\n",
        "    for word in word2idx_sorted:\n",
        "        if word[0] == '':\n",
        "            print(\"Emply Line, should replecaed by any thing else, or will cause a bug of tensorboard\")\n",
        "            file_metadata.write('<Empty Line>' + '\\n')\n",
        "        else:\n",
        "            file_metadata.write(word[0] + '\\n')\n",
        "\n",
        "# inputs\n",
        "story_input = Input(shape=(story_maxlen,), name='text')\n",
        "question_input = Input(shape=(question_maxlen,), name='question')\n",
        "\n",
        "\n",
        "\n",
        "embedded_text = layers.Embedding(input_dim=vocab_size,\n",
        "                          output_dim=EMBEDDING_SIZE,\n",
        "                          input_length=story_maxlen, name='embedded_text')(story_input)\n",
        "#embedded_text = Dropout(0.3)(embedded_text)\n",
        "\n",
        "\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "\n",
        "\n",
        "#question_input = Input(shape=(None,),dtype='int32', name='question')\n",
        "embedded_question = layers.Embedding(input_dim=vocab_size,\n",
        "                             output_dim=EMBEDDING_SIZE,\n",
        "                             input_length=question_maxlen, name='embedded_question')(question_input)\n",
        "#embedded_question = Dropout(0.3)(embedded_question)\n",
        "\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question],axis=-1)\n",
        "answer = layers.Dense(vocab_size,\n",
        "activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([story_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['acc'])\n",
        "                         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtqTzuP_m9Nu",
        "colab_type": "code",
        "outputId": "4c3c6730-832a-4033-c591-e03d2001e397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               (None, 14)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedded_text (Embedding)       (None, 14, 64)       1408        text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedded_question (Embedding)   (None, 4, 64)        1408        question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           12416       embedded_text[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 16)           5184        embedded_question[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 48)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 22)           1078        concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,494\n",
            "Trainable params: 21,494\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"387pt\" viewBox=\"0.00 0.00 725.50 387.00\" width=\"726pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 721.5,-383 721.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140556876168832 -->\n<g class=\"node\" id=\"node1\">\n<title>140556876168832</title>\n<polygon fill=\"none\" points=\"46,-332.5 46,-378.5 293,-378.5 293,-332.5 46,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"100.5\" y=\"-351.8\">text: InputLayer</text>\n<polyline fill=\"none\" points=\"155,-332.5 155,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"155,-355.5 213,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"213,-332.5 213,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253\" y=\"-363.3\">(None, 14)</text>\n<polyline fill=\"none\" points=\"213,-355.5 293,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253\" y=\"-340.3\">(None, 14)</text>\n</g>\n<!-- 140556876168720 -->\n<g class=\"node\" id=\"node3\">\n<title>140556876168720</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 339,-295.5 339,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-268.8\">embedded_text: Embedding</text>\n<polyline fill=\"none\" points=\"179,-249.5 179,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"179,-272.5 237,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"237,-249.5 237,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-280.3\">(None, 14)</text>\n<polyline fill=\"none\" points=\"237,-272.5 339,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-257.3\">(None, 14, 64)</text>\n</g>\n<!-- 140556876168832&#45;&gt;140556876168720 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140556876168832-&gt;140556876168720</title>\n<path d=\"M169.5,-332.3799C169.5,-324.1745 169.5,-314.7679 169.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"173.0001,-305.784 169.5,-295.784 166.0001,-305.784 173.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140556875818320 -->\n<g class=\"node\" id=\"node2\">\n<title>140556875818320</title>\n<polygon fill=\"none\" points=\"404,-332.5 404,-378.5 671,-378.5 671,-332.5 404,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-351.8\">question: InputLayer</text>\n<polyline fill=\"none\" points=\"541,-332.5 541,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"541,-355.5 599,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"599,-332.5 599,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635\" y=\"-363.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"599,-355.5 671,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635\" y=\"-340.3\">(None, 4)</text>\n</g>\n<!-- 140556875820952 -->\n<g class=\"node\" id=\"node4\">\n<title>140556875820952</title>\n<polygon fill=\"none\" points=\"357.5,-249.5 357.5,-295.5 717.5,-295.5 717.5,-249.5 357.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-268.8\">embedded_question: Embedding</text>\n<polyline fill=\"none\" points=\"564.5,-249.5 564.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"593.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"564.5,-272.5 622.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"593.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"622.5,-249.5 622.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"670\" y=\"-280.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"622.5,-272.5 717.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"670\" y=\"-257.3\">(None, 4, 64)</text>\n</g>\n<!-- 140556875818320&#45;&gt;140556875820952 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140556875818320-&gt;140556875820952</title>\n<path d=\"M537.5,-332.3799C537.5,-324.1745 537.5,-314.7679 537.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"541.0001,-305.784 537.5,-295.784 534.0001,-305.784 541.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140556875817928 -->\n<g class=\"node\" id=\"node5\">\n<title>140556875817928</title>\n<polygon fill=\"none\" points=\"83.5,-166.5 83.5,-212.5 345.5,-212.5 345.5,-166.5 83.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-185.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"185.5,-166.5 185.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"185.5,-189.5 243.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"243.5,-166.5 243.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294.5\" y=\"-197.3\">(None, 14, 64)</text>\n<polyline fill=\"none\" points=\"243.5,-189.5 345.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 140556876168720&#45;&gt;140556875817928 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140556876168720-&gt;140556875817928</title>\n<path d=\"M182.035,-249.3799C186.6771,-240.8178 192.0284,-230.9477 197.0301,-221.7222\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"200.1867,-223.2433 201.8761,-212.784 194.033,-219.9069 200.1867,-223.2433\" stroke=\"#000000\"/>\n</g>\n<!-- 140556864648192 -->\n<g class=\"node\" id=\"node6\">\n<title>140556864648192</title>\n<polygon fill=\"none\" points=\"387,-166.5 387,-212.5 642,-212.5 642,-166.5 387,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"438\" y=\"-185.8\">lstm_2: LSTM</text>\n<polyline fill=\"none\" points=\"489,-166.5 489,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"489,-189.5 547,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"547,-166.5 547,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594.5\" y=\"-197.3\">(None, 4, 64)</text>\n<polyline fill=\"none\" points=\"547,-189.5 642,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594.5\" y=\"-174.3\">(None, 16)</text>\n</g>\n<!-- 140556875820952&#45;&gt;140556864648192 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140556875820952-&gt;140556864648192</title>\n<path d=\"M531.0932,-249.3799C528.7947,-241.0854 526.1561,-231.5633 523.6692,-222.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"526.9956,-221.4862 520.9522,-212.784 520.2498,-223.3555 526.9956,-221.4862\" stroke=\"#000000\"/>\n</g>\n<!-- 140556875772760 -->\n<g class=\"node\" id=\"node7\">\n<title>140556875772760</title>\n<polygon fill=\"none\" points=\"156.5,-83.5 156.5,-129.5 548.5,-129.5 548.5,-83.5 156.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-102.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"331.5,-83.5 331.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"331.5,-106.5 389.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"389.5,-83.5 389.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469\" y=\"-114.3\">[(None, 32), (None, 16)]</text>\n<polyline fill=\"none\" points=\"389.5,-106.5 548.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469\" y=\"-91.3\">(None, 48)</text>\n</g>\n<!-- 140556875817928&#45;&gt;140556875772760 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140556875817928-&gt;140556875772760</title>\n<path d=\"M252.9407,-166.3799C269.1042,-156.6583 288.0714,-145.2505 305.09,-135.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"307.0213,-137.9375 313.7868,-129.784 303.4134,-131.9388 307.0213,-137.9375\" stroke=\"#000000\"/>\n</g>\n<!-- 140556864648192&#45;&gt;140556875772760 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140556864648192-&gt;140556875772760</title>\n<path d=\"M469.374,-166.3799C449.9701,-156.4384 427.1242,-144.7334 406.8026,-134.3217\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.1606,-131.0849 397.6647,-129.6399 404.9687,-137.3148 408.1606,-131.0849\" stroke=\"#000000\"/>\n</g>\n<!-- 140556875817760 -->\n<g class=\"node\" id=\"node8\">\n<title>140556875817760</title>\n<polygon fill=\"none\" points=\"230,-.5 230,-46.5 475,-46.5 475,-.5 230,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"337,-.5 337,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"337,-23.5 395,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"395,-.5 395,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-31.3\">(None, 48)</text>\n<polyline fill=\"none\" points=\"395,-23.5 475,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-8.3\">(None, 22)</text>\n</g>\n<!-- 140556875772760&#45;&gt;140556875817760 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140556875772760-&gt;140556875817760</title>\n<path d=\"M352.5,-83.3799C352.5,-75.1745 352.5,-65.7679 352.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"356.0001,-56.784 352.5,-46.784 349.0001,-56.784 356.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "JWXxhWwSq7Q0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='qa_model.png')\n",
        "from google.colab import files\n",
        "files.download('qa_model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFP1NSjsC2W9",
        "colab_type": "code",
        "outputId": "b8032889-6420-4145-d7ae-bcfa88a266a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "Xstrain[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0, 11, 20,  1,  2, 17,  3,  9,  7,  1,  2, 12,  3],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "odPXHipCT540",
        "colab_type": "code",
        "outputId": "a71bd0ab-e39c-4ce6-c213-49e490f6683e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "Xqtrain.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "qsfAW4MuQQRb",
        "colab_type": "code",
        "outputId": "2d1fdd74-9b08-4d65-b199-e15ad6cff08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "Xstrain.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Tu7Q4GxrJM_C",
        "colab_type": "code",
        "outputId": "d25bfae5-4e2a-4ac6-9741-aa9233ae50f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print (layer.name)\n",
        "  if layer.name =='embedded_text':\n",
        "    embedding_input = model.get_layer(layer.name).output\n",
        "    print (embedding_input.shape[1:])\n",
        "    embedding_size = np.prod(embedding_input.shape[1:])\n",
        "    print (embedding_size)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text\n",
            "question\n",
            "embedded_text\n",
            "(14, 64)\n",
            "896\n",
            "embedded_question\n",
            "lstm_1\n",
            "lstm_2\n",
            "concatenate_1\n",
            "dense_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvZ9dSobGrMX",
        "colab_type": "code",
        "outputId": "77d0956f-d616-4d4f-c9a6-038cdac6551d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14635
        }
      },
      "cell_type": "code",
      "source": [
        "#啟動Tensobard\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "tensorboard = make_tensorboard(set_dir_name='mem-network')\n",
        "\n",
        "#開始訓練模型\n",
        "history = model.fit([Xstrain, Xqtrain], [Ytrain], batch_size=BATCH_SIZE,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=[tensorboard],\n",
        "                    validation_data=([Xstest, Xqtest], [Ytest]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://8882a16a.ngrok.io\n",
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/400\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.4402 - acc: 0.1660 - val_loss: 1.9202 - val_acc: 0.1660\n",
            "Epoch 2/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.8571 - acc: 0.1780 - val_loss: 1.8116 - val_acc: 0.1730\n",
            "Epoch 3/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.8007 - acc: 0.1890 - val_loss: 1.7768 - val_acc: 0.2610\n",
            "Epoch 4/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7562 - acc: 0.2650 - val_loss: 1.7292 - val_acc: 0.3040\n",
            "Epoch 5/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6956 - acc: 0.3290 - val_loss: 1.6507 - val_acc: 0.3390\n",
            "Epoch 6/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6333 - acc: 0.3710 - val_loss: 1.6238 - val_acc: 0.3610\n",
            "Epoch 7/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5776 - acc: 0.4200 - val_loss: 1.5708 - val_acc: 0.4530\n",
            "Epoch 8/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5138 - acc: 0.4380 - val_loss: 1.4906 - val_acc: 0.4370\n",
            "Epoch 9/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4688 - acc: 0.4510 - val_loss: 1.4896 - val_acc: 0.4500\n",
            "Epoch 10/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4286 - acc: 0.4630 - val_loss: 1.4418 - val_acc: 0.4240\n",
            "Epoch 11/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4070 - acc: 0.4660 - val_loss: 1.4214 - val_acc: 0.4940\n",
            "Epoch 12/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3735 - acc: 0.4890 - val_loss: 1.3908 - val_acc: 0.4930\n",
            "Epoch 13/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3678 - acc: 0.4970 - val_loss: 1.3699 - val_acc: 0.4910\n",
            "Epoch 14/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3375 - acc: 0.4930 - val_loss: 1.4139 - val_acc: 0.4160\n",
            "Epoch 15/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3335 - acc: 0.4860 - val_loss: 1.3133 - val_acc: 0.5420\n",
            "Epoch 16/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3154 - acc: 0.5000 - val_loss: 1.3307 - val_acc: 0.5100\n",
            "Epoch 17/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2949 - acc: 0.5310 - val_loss: 1.2627 - val_acc: 0.5260\n",
            "Epoch 18/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2672 - acc: 0.5240 - val_loss: 1.2578 - val_acc: 0.5490\n",
            "Epoch 19/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2565 - acc: 0.5300 - val_loss: 1.2481 - val_acc: 0.5390\n",
            "Epoch 20/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2388 - acc: 0.5320 - val_loss: 1.2193 - val_acc: 0.5490\n",
            "Epoch 21/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2231 - acc: 0.5380 - val_loss: 1.2107 - val_acc: 0.5390\n",
            "Epoch 22/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2089 - acc: 0.5350 - val_loss: 1.2051 - val_acc: 0.5700\n",
            "Epoch 23/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1969 - acc: 0.5510 - val_loss: 1.2030 - val_acc: 0.5460\n",
            "Epoch 24/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1905 - acc: 0.5540 - val_loss: 1.1993 - val_acc: 0.5510\n",
            "Epoch 25/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1836 - acc: 0.5460 - val_loss: 1.1551 - val_acc: 0.5660\n",
            "Epoch 26/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1766 - acc: 0.5570 - val_loss: 1.1748 - val_acc: 0.5690\n",
            "Epoch 27/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1717 - acc: 0.5550 - val_loss: 1.1892 - val_acc: 0.5650\n",
            "Epoch 28/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1655 - acc: 0.5530 - val_loss: 1.1288 - val_acc: 0.5730\n",
            "Epoch 29/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1535 - acc: 0.5580 - val_loss: 1.1544 - val_acc: 0.5570\n",
            "Epoch 30/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1553 - acc: 0.5670 - val_loss: 1.1746 - val_acc: 0.5620\n",
            "Epoch 31/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1528 - acc: 0.5640 - val_loss: 1.1582 - val_acc: 0.5620\n",
            "Epoch 32/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1448 - acc: 0.5720 - val_loss: 1.1355 - val_acc: 0.5790\n",
            "Epoch 33/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1404 - acc: 0.5700 - val_loss: 1.1497 - val_acc: 0.5750\n",
            "Epoch 34/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1345 - acc: 0.5770 - val_loss: 1.1235 - val_acc: 0.5780\n",
            "Epoch 35/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1332 - acc: 0.5770 - val_loss: 1.1069 - val_acc: 0.5860\n",
            "Epoch 36/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1306 - acc: 0.5760 - val_loss: 1.1181 - val_acc: 0.5910\n",
            "Epoch 37/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1284 - acc: 0.5750 - val_loss: 1.1077 - val_acc: 0.5730\n",
            "Epoch 38/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1237 - acc: 0.5750 - val_loss: 1.1004 - val_acc: 0.5900\n",
            "Epoch 39/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1161 - acc: 0.5740 - val_loss: 1.1351 - val_acc: 0.5780\n",
            "Epoch 40/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1205 - acc: 0.5720 - val_loss: 1.1360 - val_acc: 0.5520\n",
            "Epoch 41/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1212 - acc: 0.5630 - val_loss: 1.0943 - val_acc: 0.5940\n",
            "Epoch 42/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1117 - acc: 0.5760 - val_loss: 1.1291 - val_acc: 0.5510\n",
            "Epoch 43/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1180 - acc: 0.5640 - val_loss: 1.0928 - val_acc: 0.5980\n",
            "Epoch 44/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1070 - acc: 0.5850 - val_loss: 1.0902 - val_acc: 0.5860\n",
            "Epoch 45/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1103 - acc: 0.5800 - val_loss: 1.0796 - val_acc: 0.6080\n",
            "Epoch 46/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1062 - acc: 0.5780 - val_loss: 1.0918 - val_acc: 0.5990\n",
            "Epoch 47/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0989 - acc: 0.5930 - val_loss: 1.0918 - val_acc: 0.5960\n",
            "Epoch 48/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0977 - acc: 0.5830 - val_loss: 1.0753 - val_acc: 0.5910\n",
            "Epoch 49/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0987 - acc: 0.5910 - val_loss: 1.0700 - val_acc: 0.5950\n",
            "Epoch 50/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0886 - acc: 0.5970 - val_loss: 1.0752 - val_acc: 0.5900\n",
            "Epoch 51/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0882 - acc: 0.5870 - val_loss: 1.0767 - val_acc: 0.5950\n",
            "Epoch 52/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0842 - acc: 0.5820 - val_loss: 1.0596 - val_acc: 0.6060\n",
            "Epoch 53/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0869 - acc: 0.5930 - val_loss: 1.0663 - val_acc: 0.5950\n",
            "Epoch 54/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0774 - acc: 0.6000 - val_loss: 1.0502 - val_acc: 0.6130\n",
            "Epoch 55/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0741 - acc: 0.5990 - val_loss: 1.0964 - val_acc: 0.5790\n",
            "Epoch 56/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0771 - acc: 0.5920 - val_loss: 1.0516 - val_acc: 0.6090\n",
            "Epoch 57/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0667 - acc: 0.5980 - val_loss: 1.0672 - val_acc: 0.5910\n",
            "Epoch 58/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0659 - acc: 0.5960 - val_loss: 1.0638 - val_acc: 0.6000\n",
            "Epoch 59/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0618 - acc: 0.5930 - val_loss: 1.0492 - val_acc: 0.6030\n",
            "Epoch 60/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0642 - acc: 0.6030 - val_loss: 1.0539 - val_acc: 0.6090\n",
            "Epoch 61/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0579 - acc: 0.5980 - val_loss: 1.0427 - val_acc: 0.5960\n",
            "Epoch 62/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0572 - acc: 0.5970 - val_loss: 1.0244 - val_acc: 0.6220\n",
            "Epoch 63/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0504 - acc: 0.5950 - val_loss: 1.0443 - val_acc: 0.6090\n",
            "Epoch 64/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0501 - acc: 0.6050 - val_loss: 1.0306 - val_acc: 0.6120\n",
            "Epoch 65/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0417 - acc: 0.6120 - val_loss: 1.0535 - val_acc: 0.6050\n",
            "Epoch 66/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0436 - acc: 0.6150 - val_loss: 1.0208 - val_acc: 0.6170\n",
            "Epoch 67/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0434 - acc: 0.6090 - val_loss: 1.0555 - val_acc: 0.5820\n",
            "Epoch 68/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0344 - acc: 0.6130 - val_loss: 1.0376 - val_acc: 0.6040\n",
            "Epoch 69/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0345 - acc: 0.6120 - val_loss: 0.9999 - val_acc: 0.6270\n",
            "Epoch 70/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0282 - acc: 0.6180 - val_loss: 1.0077 - val_acc: 0.6260\n",
            "Epoch 71/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0274 - acc: 0.6080 - val_loss: 1.0054 - val_acc: 0.6200\n",
            "Epoch 72/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0223 - acc: 0.6160 - val_loss: 1.0165 - val_acc: 0.6240\n",
            "Epoch 73/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0110 - acc: 0.6200 - val_loss: 1.0038 - val_acc: 0.6320\n",
            "Epoch 74/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0118 - acc: 0.6130 - val_loss: 0.9855 - val_acc: 0.6390\n",
            "Epoch 75/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0088 - acc: 0.6190 - val_loss: 0.9977 - val_acc: 0.6150\n",
            "Epoch 76/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0042 - acc: 0.6250 - val_loss: 0.9787 - val_acc: 0.6400\n",
            "Epoch 77/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9972 - acc: 0.6200 - val_loss: 0.9878 - val_acc: 0.6450\n",
            "Epoch 78/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9965 - acc: 0.6280 - val_loss: 0.9909 - val_acc: 0.6330\n",
            "Epoch 79/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9965 - acc: 0.6290 - val_loss: 0.9747 - val_acc: 0.6300\n",
            "Epoch 80/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9900 - acc: 0.6290 - val_loss: 0.9715 - val_acc: 0.6300\n",
            "Epoch 81/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9847 - acc: 0.6330 - val_loss: 0.9561 - val_acc: 0.6450\n",
            "Epoch 82/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9750 - acc: 0.6410 - val_loss: 1.0113 - val_acc: 0.6180\n",
            "Epoch 83/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9742 - acc: 0.6380 - val_loss: 0.9448 - val_acc: 0.6590\n",
            "Epoch 84/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9685 - acc: 0.6530 - val_loss: 0.9451 - val_acc: 0.6520\n",
            "Epoch 85/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9631 - acc: 0.6490 - val_loss: 0.9486 - val_acc: 0.6550\n",
            "Epoch 86/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9665 - acc: 0.6450 - val_loss: 0.9302 - val_acc: 0.6670\n",
            "Epoch 87/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9559 - acc: 0.6510 - val_loss: 0.9251 - val_acc: 0.6610\n",
            "Epoch 88/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9471 - acc: 0.6510 - val_loss: 0.9344 - val_acc: 0.6590\n",
            "Epoch 89/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9472 - acc: 0.6550 - val_loss: 0.9284 - val_acc: 0.6570\n",
            "Epoch 90/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9439 - acc: 0.6460 - val_loss: 0.9150 - val_acc: 0.6700\n",
            "Epoch 91/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9317 - acc: 0.6640 - val_loss: 0.9128 - val_acc: 0.6630\n",
            "Epoch 92/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9297 - acc: 0.6590 - val_loss: 0.9077 - val_acc: 0.6610\n",
            "Epoch 93/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9227 - acc: 0.6590 - val_loss: 0.9163 - val_acc: 0.6670\n",
            "Epoch 94/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9258 - acc: 0.6590 - val_loss: 0.9087 - val_acc: 0.6760\n",
            "Epoch 95/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9159 - acc: 0.6760 - val_loss: 0.9627 - val_acc: 0.6390\n",
            "Epoch 96/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9113 - acc: 0.6680 - val_loss: 0.8829 - val_acc: 0.6790\n",
            "Epoch 97/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9077 - acc: 0.6580 - val_loss: 0.8822 - val_acc: 0.6800\n",
            "Epoch 98/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9041 - acc: 0.6750 - val_loss: 0.8798 - val_acc: 0.6780\n",
            "Epoch 99/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8986 - acc: 0.6720 - val_loss: 0.8802 - val_acc: 0.6780\n",
            "Epoch 100/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8946 - acc: 0.6670 - val_loss: 0.8614 - val_acc: 0.6940\n",
            "Epoch 101/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8894 - acc: 0.6770 - val_loss: 0.8900 - val_acc: 0.6700\n",
            "Epoch 102/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8802 - acc: 0.6770 - val_loss: 0.8497 - val_acc: 0.7040\n",
            "Epoch 103/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8797 - acc: 0.6880 - val_loss: 0.8567 - val_acc: 0.6960\n",
            "Epoch 104/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8769 - acc: 0.6740 - val_loss: 0.8473 - val_acc: 0.7050\n",
            "Epoch 105/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8686 - acc: 0.6810 - val_loss: 0.8793 - val_acc: 0.6860\n",
            "Epoch 106/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8602 - acc: 0.6860 - val_loss: 0.8378 - val_acc: 0.6810\n",
            "Epoch 107/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8589 - acc: 0.6880 - val_loss: 0.8451 - val_acc: 0.6980\n",
            "Epoch 108/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8529 - acc: 0.6790 - val_loss: 0.8158 - val_acc: 0.7090\n",
            "Epoch 109/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8482 - acc: 0.6970 - val_loss: 0.8185 - val_acc: 0.7120\n",
            "Epoch 110/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8400 - acc: 0.6940 - val_loss: 0.8263 - val_acc: 0.7160\n",
            "Epoch 111/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8356 - acc: 0.7000 - val_loss: 0.8160 - val_acc: 0.7050\n",
            "Epoch 112/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8315 - acc: 0.7030 - val_loss: 0.8093 - val_acc: 0.7220\n",
            "Epoch 113/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8243 - acc: 0.7130 - val_loss: 0.8119 - val_acc: 0.7010\n",
            "Epoch 114/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8204 - acc: 0.7070 - val_loss: 0.7889 - val_acc: 0.7300\n",
            "Epoch 115/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8132 - acc: 0.7020 - val_loss: 0.7890 - val_acc: 0.7230\n",
            "Epoch 116/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8056 - acc: 0.7100 - val_loss: 0.7843 - val_acc: 0.7300\n",
            "Epoch 117/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8049 - acc: 0.7200 - val_loss: 0.7797 - val_acc: 0.7330\n",
            "Epoch 118/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7981 - acc: 0.7200 - val_loss: 0.7732 - val_acc: 0.7220\n",
            "Epoch 119/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7954 - acc: 0.7070 - val_loss: 0.8031 - val_acc: 0.7150\n",
            "Epoch 120/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7946 - acc: 0.7210 - val_loss: 0.7722 - val_acc: 0.7250\n",
            "Epoch 121/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7767 - acc: 0.7310 - val_loss: 0.7644 - val_acc: 0.7200\n",
            "Epoch 122/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7792 - acc: 0.7240 - val_loss: 0.7548 - val_acc: 0.7420\n",
            "Epoch 123/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7665 - acc: 0.7300 - val_loss: 0.7371 - val_acc: 0.7520\n",
            "Epoch 124/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7614 - acc: 0.7380 - val_loss: 0.7456 - val_acc: 0.7380\n",
            "Epoch 125/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7601 - acc: 0.7360 - val_loss: 0.7329 - val_acc: 0.7370\n",
            "Epoch 126/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7483 - acc: 0.7340 - val_loss: 0.7305 - val_acc: 0.7470\n",
            "Epoch 127/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7441 - acc: 0.7380 - val_loss: 0.7404 - val_acc: 0.7440\n",
            "Epoch 128/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7383 - acc: 0.7310 - val_loss: 0.7112 - val_acc: 0.7620\n",
            "Epoch 129/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7286 - acc: 0.7350 - val_loss: 0.7085 - val_acc: 0.7560\n",
            "Epoch 130/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7205 - acc: 0.7540 - val_loss: 0.6952 - val_acc: 0.7590\n",
            "Epoch 131/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7211 - acc: 0.7430 - val_loss: 0.6944 - val_acc: 0.7560\n",
            "Epoch 132/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7146 - acc: 0.7540 - val_loss: 0.6798 - val_acc: 0.7630\n",
            "Epoch 133/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7074 - acc: 0.7480 - val_loss: 0.7023 - val_acc: 0.7550\n",
            "Epoch 134/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7003 - acc: 0.7620 - val_loss: 0.6654 - val_acc: 0.7810\n",
            "Epoch 135/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6933 - acc: 0.7600 - val_loss: 0.6787 - val_acc: 0.7660\n",
            "Epoch 136/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.7620 - val_loss: 0.6646 - val_acc: 0.7750\n",
            "Epoch 137/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6812 - acc: 0.7640 - val_loss: 0.6575 - val_acc: 0.7970\n",
            "Epoch 138/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6701 - acc: 0.7780 - val_loss: 0.6631 - val_acc: 0.7650\n",
            "Epoch 139/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6673 - acc: 0.7730 - val_loss: 0.6626 - val_acc: 0.7690\n",
            "Epoch 140/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6641 - acc: 0.7770 - val_loss: 0.6410 - val_acc: 0.7860\n",
            "Epoch 141/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6551 - acc: 0.7750 - val_loss: 0.6436 - val_acc: 0.7760\n",
            "Epoch 142/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6548 - acc: 0.7710 - val_loss: 0.6268 - val_acc: 0.7900\n",
            "Epoch 143/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6396 - acc: 0.7820 - val_loss: 0.6122 - val_acc: 0.8060\n",
            "Epoch 144/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6368 - acc: 0.7850 - val_loss: 0.6055 - val_acc: 0.8070\n",
            "Epoch 145/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6322 - acc: 0.7860 - val_loss: 0.6133 - val_acc: 0.7870\n",
            "Epoch 146/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6248 - acc: 0.7890 - val_loss: 0.5942 - val_acc: 0.8120\n",
            "Epoch 147/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6166 - acc: 0.7970 - val_loss: 0.5936 - val_acc: 0.7900\n",
            "Epoch 148/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6130 - acc: 0.7880 - val_loss: 0.5912 - val_acc: 0.8040\n",
            "Epoch 149/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6028 - acc: 0.8000 - val_loss: 0.6012 - val_acc: 0.7950\n",
            "Epoch 150/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5961 - acc: 0.7930 - val_loss: 0.5720 - val_acc: 0.8050\n",
            "Epoch 151/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5906 - acc: 0.8060 - val_loss: 0.5691 - val_acc: 0.8150\n",
            "Epoch 152/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5871 - acc: 0.8020 - val_loss: 0.5589 - val_acc: 0.8280\n",
            "Epoch 153/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5828 - acc: 0.7980 - val_loss: 0.5546 - val_acc: 0.8180\n",
            "Epoch 154/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5735 - acc: 0.8060 - val_loss: 0.5425 - val_acc: 0.8290\n",
            "Epoch 155/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5664 - acc: 0.8060 - val_loss: 0.5541 - val_acc: 0.8180\n",
            "Epoch 156/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5596 - acc: 0.8100 - val_loss: 0.5398 - val_acc: 0.8220\n",
            "Epoch 157/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5548 - acc: 0.8180 - val_loss: 0.5528 - val_acc: 0.8170\n",
            "Epoch 158/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5449 - acc: 0.8090 - val_loss: 0.5130 - val_acc: 0.8340\n",
            "Epoch 159/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5424 - acc: 0.8170 - val_loss: 0.5239 - val_acc: 0.8300\n",
            "Epoch 160/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5361 - acc: 0.8140 - val_loss: 0.5082 - val_acc: 0.8440\n",
            "Epoch 161/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5311 - acc: 0.8240 - val_loss: 0.5036 - val_acc: 0.8420\n",
            "Epoch 162/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5207 - acc: 0.8270 - val_loss: 0.4911 - val_acc: 0.8440\n",
            "Epoch 163/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5178 - acc: 0.8240 - val_loss: 0.4926 - val_acc: 0.8430\n",
            "Epoch 164/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5139 - acc: 0.8300 - val_loss: 0.4866 - val_acc: 0.8390\n",
            "Epoch 165/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4999 - acc: 0.8340 - val_loss: 0.5350 - val_acc: 0.8280\n",
            "Epoch 166/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4998 - acc: 0.8370 - val_loss: 0.4776 - val_acc: 0.8440\n",
            "Epoch 167/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4916 - acc: 0.8330 - val_loss: 0.4628 - val_acc: 0.8490\n",
            "Epoch 168/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4914 - acc: 0.8310 - val_loss: 0.4720 - val_acc: 0.8500\n",
            "Epoch 169/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4780 - acc: 0.8430 - val_loss: 0.4621 - val_acc: 0.8460\n",
            "Epoch 170/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4806 - acc: 0.8430 - val_loss: 0.5034 - val_acc: 0.8380\n",
            "Epoch 171/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4691 - acc: 0.8540 - val_loss: 0.4445 - val_acc: 0.8490\n",
            "Epoch 172/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4672 - acc: 0.8450 - val_loss: 0.4297 - val_acc: 0.8670\n",
            "Epoch 173/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4575 - acc: 0.8480 - val_loss: 0.4377 - val_acc: 0.8550\n",
            "Epoch 174/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4551 - acc: 0.8480 - val_loss: 0.4294 - val_acc: 0.8630\n",
            "Epoch 175/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4470 - acc: 0.8600 - val_loss: 0.4348 - val_acc: 0.8610\n",
            "Epoch 176/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4399 - acc: 0.8520 - val_loss: 0.4200 - val_acc: 0.8590\n",
            "Epoch 177/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4338 - acc: 0.8670 - val_loss: 0.4344 - val_acc: 0.8640\n",
            "Epoch 178/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4327 - acc: 0.8600 - val_loss: 0.4332 - val_acc: 0.8630\n",
            "Epoch 179/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4275 - acc: 0.8620 - val_loss: 0.4042 - val_acc: 0.8830\n",
            "Epoch 180/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4197 - acc: 0.8650 - val_loss: 0.4204 - val_acc: 0.8660\n",
            "Epoch 181/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4124 - acc: 0.8730 - val_loss: 0.3943 - val_acc: 0.8800\n",
            "Epoch 182/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4105 - acc: 0.8740 - val_loss: 0.3890 - val_acc: 0.8800\n",
            "Epoch 183/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4030 - acc: 0.8750 - val_loss: 0.3805 - val_acc: 0.8860\n",
            "Epoch 184/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3987 - acc: 0.8730 - val_loss: 0.3927 - val_acc: 0.8720\n",
            "Epoch 185/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3955 - acc: 0.8720 - val_loss: 0.3818 - val_acc: 0.8790\n",
            "Epoch 186/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3947 - acc: 0.8750 - val_loss: 0.4220 - val_acc: 0.8620\n",
            "Epoch 187/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3829 - acc: 0.8820 - val_loss: 0.3742 - val_acc: 0.8810\n",
            "Epoch 188/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3836 - acc: 0.8810 - val_loss: 0.3743 - val_acc: 0.8830\n",
            "Epoch 189/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3841 - acc: 0.8820 - val_loss: 0.3478 - val_acc: 0.8910\n",
            "Epoch 190/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3712 - acc: 0.8840 - val_loss: 0.3482 - val_acc: 0.8940\n",
            "Epoch 191/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3661 - acc: 0.8810 - val_loss: 0.3474 - val_acc: 0.8900\n",
            "Epoch 192/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3652 - acc: 0.8870 - val_loss: 0.3442 - val_acc: 0.8940\n",
            "Epoch 193/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3596 - acc: 0.8870 - val_loss: 0.3641 - val_acc: 0.8780\n",
            "Epoch 194/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3541 - acc: 0.8850 - val_loss: 0.3323 - val_acc: 0.8950\n",
            "Epoch 195/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - acc: 0.8880 - val_loss: 0.3374 - val_acc: 0.9000\n",
            "Epoch 196/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3481 - acc: 0.8930 - val_loss: 0.3263 - val_acc: 0.8930\n",
            "Epoch 197/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3406 - acc: 0.8940 - val_loss: 0.3178 - val_acc: 0.9050\n",
            "Epoch 198/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - acc: 0.8920 - val_loss: 0.3369 - val_acc: 0.8930\n",
            "Epoch 199/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3315 - acc: 0.9000 - val_loss: 0.3589 - val_acc: 0.8950\n",
            "Epoch 200/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3301 - acc: 0.9010 - val_loss: 0.3613 - val_acc: 0.8750\n",
            "Epoch 201/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3266 - acc: 0.8960 - val_loss: 0.3345 - val_acc: 0.8960\n",
            "Epoch 202/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3166 - acc: 0.9080 - val_loss: 0.3109 - val_acc: 0.9050\n",
            "Epoch 203/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3157 - acc: 0.9020 - val_loss: 0.3163 - val_acc: 0.9040\n",
            "Epoch 204/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3130 - acc: 0.8990 - val_loss: 0.2882 - val_acc: 0.9150\n",
            "Epoch 205/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3066 - acc: 0.9080 - val_loss: 0.2959 - val_acc: 0.9130\n",
            "Epoch 206/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3025 - acc: 0.9000 - val_loss: 0.2795 - val_acc: 0.9230\n",
            "Epoch 207/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2962 - acc: 0.9140 - val_loss: 0.2758 - val_acc: 0.9190\n",
            "Epoch 208/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2942 - acc: 0.9120 - val_loss: 0.2854 - val_acc: 0.9140\n",
            "Epoch 209/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2864 - acc: 0.9170 - val_loss: 0.2795 - val_acc: 0.9110\n",
            "Epoch 210/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2903 - acc: 0.9110 - val_loss: 0.2619 - val_acc: 0.9220\n",
            "Epoch 211/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2807 - acc: 0.9150 - val_loss: 0.2653 - val_acc: 0.9270\n",
            "Epoch 212/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2751 - acc: 0.9200 - val_loss: 0.2650 - val_acc: 0.9310\n",
            "Epoch 213/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2723 - acc: 0.9190 - val_loss: 0.2740 - val_acc: 0.9170\n",
            "Epoch 214/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2723 - acc: 0.9200 - val_loss: 0.2564 - val_acc: 0.9320\n",
            "Epoch 215/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2634 - acc: 0.9240 - val_loss: 0.2562 - val_acc: 0.9340\n",
            "Epoch 216/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2581 - acc: 0.9280 - val_loss: 0.2549 - val_acc: 0.9220\n",
            "Epoch 217/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2592 - acc: 0.9270 - val_loss: 0.2414 - val_acc: 0.9350\n",
            "Epoch 218/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2515 - acc: 0.9320 - val_loss: 0.2388 - val_acc: 0.9300\n",
            "Epoch 219/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2514 - acc: 0.9300 - val_loss: 0.2391 - val_acc: 0.9330\n",
            "Epoch 220/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2431 - acc: 0.9320 - val_loss: 0.2306 - val_acc: 0.9380\n",
            "Epoch 221/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2426 - acc: 0.9330 - val_loss: 0.2536 - val_acc: 0.9250\n",
            "Epoch 222/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2430 - acc: 0.9300 - val_loss: 0.2295 - val_acc: 0.9350\n",
            "Epoch 223/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2316 - acc: 0.9310 - val_loss: 0.2327 - val_acc: 0.9400\n",
            "Epoch 224/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2309 - acc: 0.9430 - val_loss: 0.2169 - val_acc: 0.9460\n",
            "Epoch 225/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2265 - acc: 0.9400 - val_loss: 0.2146 - val_acc: 0.9380\n",
            "Epoch 226/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2214 - acc: 0.9370 - val_loss: 0.2301 - val_acc: 0.9350\n",
            "Epoch 227/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2188 - acc: 0.9360 - val_loss: 0.2113 - val_acc: 0.9400\n",
            "Epoch 228/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2176 - acc: 0.9390 - val_loss: 0.2215 - val_acc: 0.9390\n",
            "Epoch 229/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2156 - acc: 0.9440 - val_loss: 0.2117 - val_acc: 0.9490\n",
            "Epoch 230/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2156 - acc: 0.9440 - val_loss: 0.1890 - val_acc: 0.9550\n",
            "Epoch 231/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2046 - acc: 0.9440 - val_loss: 0.2307 - val_acc: 0.9360\n",
            "Epoch 232/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2051 - acc: 0.9450 - val_loss: 0.2067 - val_acc: 0.9490\n",
            "Epoch 233/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2024 - acc: 0.9440 - val_loss: 0.2367 - val_acc: 0.9410\n",
            "Epoch 234/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2026 - acc: 0.9470 - val_loss: 0.1848 - val_acc: 0.9570\n",
            "Epoch 235/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1950 - acc: 0.9540 - val_loss: 0.1730 - val_acc: 0.9590\n",
            "Epoch 236/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1909 - acc: 0.9520 - val_loss: 0.1928 - val_acc: 0.9620\n",
            "Epoch 237/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1938 - acc: 0.9530 - val_loss: 0.1697 - val_acc: 0.9650\n",
            "Epoch 238/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1853 - acc: 0.9540 - val_loss: 0.1754 - val_acc: 0.9580\n",
            "Epoch 239/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1840 - acc: 0.9480 - val_loss: 0.1822 - val_acc: 0.9530\n",
            "Epoch 240/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1792 - acc: 0.9600 - val_loss: 0.1775 - val_acc: 0.9570\n",
            "Epoch 241/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1817 - acc: 0.9600 - val_loss: 0.1627 - val_acc: 0.9650\n",
            "Epoch 242/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1727 - acc: 0.9650 - val_loss: 0.1671 - val_acc: 0.9630\n",
            "Epoch 243/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1729 - acc: 0.9590 - val_loss: 0.1655 - val_acc: 0.9630\n",
            "Epoch 244/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1729 - acc: 0.9600 - val_loss: 0.1611 - val_acc: 0.9690\n",
            "Epoch 245/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1624 - acc: 0.9630 - val_loss: 0.1695 - val_acc: 0.9560\n",
            "Epoch 246/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1651 - acc: 0.9600 - val_loss: 0.1480 - val_acc: 0.9700\n",
            "Epoch 247/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1613 - acc: 0.9650 - val_loss: 0.1567 - val_acc: 0.9670\n",
            "Epoch 248/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1636 - acc: 0.9600 - val_loss: 0.1502 - val_acc: 0.9620\n",
            "Epoch 249/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1542 - acc: 0.9670 - val_loss: 0.1651 - val_acc: 0.9650\n",
            "Epoch 250/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1546 - acc: 0.9680 - val_loss: 0.1399 - val_acc: 0.9720\n",
            "Epoch 251/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1542 - acc: 0.9710 - val_loss: 0.1385 - val_acc: 0.9760\n",
            "Epoch 252/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1459 - acc: 0.9720 - val_loss: 0.1373 - val_acc: 0.9770\n",
            "Epoch 253/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1439 - acc: 0.9690 - val_loss: 0.1392 - val_acc: 0.9700\n",
            "Epoch 254/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1456 - acc: 0.9670 - val_loss: 0.1784 - val_acc: 0.9570\n",
            "Epoch 255/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1462 - acc: 0.9710 - val_loss: 0.1267 - val_acc: 0.9780\n",
            "Epoch 256/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1365 - acc: 0.9680 - val_loss: 0.1331 - val_acc: 0.9750\n",
            "Epoch 257/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1342 - acc: 0.9750 - val_loss: 0.1294 - val_acc: 0.9740\n",
            "Epoch 258/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1351 - acc: 0.9770 - val_loss: 0.1398 - val_acc: 0.9710\n",
            "Epoch 259/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1309 - acc: 0.9740 - val_loss: 0.1419 - val_acc: 0.9630\n",
            "Epoch 260/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1292 - acc: 0.9720 - val_loss: 0.1320 - val_acc: 0.9750\n",
            "Epoch 261/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1258 - acc: 0.9710 - val_loss: 0.1308 - val_acc: 0.9750\n",
            "Epoch 262/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1226 - acc: 0.9740 - val_loss: 0.1076 - val_acc: 0.9810\n",
            "Epoch 263/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1222 - acc: 0.9720 - val_loss: 0.1205 - val_acc: 0.9800\n",
            "Epoch 264/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1198 - acc: 0.9740 - val_loss: 0.1061 - val_acc: 0.9820\n",
            "Epoch 265/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1178 - acc: 0.9740 - val_loss: 0.1111 - val_acc: 0.9820\n",
            "Epoch 266/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1250 - acc: 0.9730 - val_loss: 0.1048 - val_acc: 0.9810\n",
            "Epoch 267/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1090 - acc: 0.9780 - val_loss: 0.1304 - val_acc: 0.9750\n",
            "Epoch 268/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1101 - acc: 0.9780 - val_loss: 0.0992 - val_acc: 0.9850\n",
            "Epoch 269/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1145 - acc: 0.9770 - val_loss: 0.0988 - val_acc: 0.9830\n",
            "Epoch 270/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1044 - acc: 0.9830 - val_loss: 0.1018 - val_acc: 0.9830\n",
            "Epoch 271/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1072 - acc: 0.9790 - val_loss: 0.1155 - val_acc: 0.9780\n",
            "Epoch 272/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1066 - acc: 0.9800 - val_loss: 0.0928 - val_acc: 0.9860\n",
            "Epoch 273/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1046 - acc: 0.9780 - val_loss: 0.1023 - val_acc: 0.9820\n",
            "Epoch 274/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0987 - acc: 0.9820 - val_loss: 0.1050 - val_acc: 0.9800\n",
            "Epoch 275/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1014 - acc: 0.9790 - val_loss: 0.0931 - val_acc: 0.9840\n",
            "Epoch 276/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0968 - acc: 0.9820 - val_loss: 0.1024 - val_acc: 0.9790\n",
            "Epoch 277/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0939 - acc: 0.9790 - val_loss: 0.0825 - val_acc: 0.9870\n",
            "Epoch 278/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0975 - acc: 0.9800 - val_loss: 0.0872 - val_acc: 0.9860\n",
            "Epoch 279/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0900 - acc: 0.9830 - val_loss: 0.0827 - val_acc: 0.9870\n",
            "Epoch 280/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0934 - acc: 0.9810 - val_loss: 0.0867 - val_acc: 0.9830\n",
            "Epoch 281/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - acc: 0.9850 - val_loss: 0.0807 - val_acc: 0.9860\n",
            "Epoch 282/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - acc: 0.9850 - val_loss: 0.0912 - val_acc: 0.9830\n",
            "Epoch 283/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - acc: 0.9820 - val_loss: 0.0804 - val_acc: 0.9870\n",
            "Epoch 284/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0910 - acc: 0.9810 - val_loss: 0.0743 - val_acc: 0.9880\n",
            "Epoch 285/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - acc: 0.9830 - val_loss: 0.0773 - val_acc: 0.9860\n",
            "Epoch 286/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - acc: 0.9800 - val_loss: 0.0754 - val_acc: 0.9870\n",
            "Epoch 287/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - acc: 0.9810 - val_loss: 0.0786 - val_acc: 0.9880\n",
            "Epoch 288/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - acc: 0.9840 - val_loss: 0.0840 - val_acc: 0.9800\n",
            "Epoch 289/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - acc: 0.9860 - val_loss: 0.0759 - val_acc: 0.9890\n",
            "Epoch 290/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - acc: 0.9870 - val_loss: 0.0766 - val_acc: 0.9890\n",
            "Epoch 291/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - acc: 0.9840 - val_loss: 0.0802 - val_acc: 0.9860\n",
            "Epoch 292/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0764 - acc: 0.9820 - val_loss: 0.0958 - val_acc: 0.9750\n",
            "Epoch 293/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - acc: 0.9860 - val_loss: 0.0696 - val_acc: 0.9870\n",
            "Epoch 294/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0724 - acc: 0.9840 - val_loss: 0.0796 - val_acc: 0.9830\n",
            "Epoch 295/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - acc: 0.9880 - val_loss: 0.0785 - val_acc: 0.9820\n",
            "Epoch 296/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - acc: 0.9860 - val_loss: 0.0743 - val_acc: 0.9850\n",
            "Epoch 297/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - acc: 0.9840 - val_loss: 0.0566 - val_acc: 0.9880\n",
            "Epoch 298/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0636 - acc: 0.9850 - val_loss: 0.0624 - val_acc: 0.9860\n",
            "Epoch 299/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - acc: 0.9820 - val_loss: 0.0652 - val_acc: 0.9890\n",
            "Epoch 300/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - acc: 0.9830 - val_loss: 0.0619 - val_acc: 0.9880\n",
            "Epoch 301/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0622 - acc: 0.9890 - val_loss: 0.0563 - val_acc: 0.9900\n",
            "Epoch 302/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0643 - acc: 0.9880 - val_loss: 0.0545 - val_acc: 0.9890\n",
            "Epoch 303/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0651 - acc: 0.9840 - val_loss: 0.0573 - val_acc: 0.9910\n",
            "Epoch 304/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0665 - acc: 0.9830 - val_loss: 0.0669 - val_acc: 0.9840\n",
            "Epoch 305/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0604 - acc: 0.9840 - val_loss: 0.0686 - val_acc: 0.9850\n",
            "Epoch 306/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0639 - acc: 0.9850 - val_loss: 0.0542 - val_acc: 0.9900\n",
            "Epoch 307/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 0.9870 - val_loss: 0.0709 - val_acc: 0.9860\n",
            "Epoch 308/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0607 - acc: 0.9870 - val_loss: 0.0750 - val_acc: 0.9870\n",
            "Epoch 309/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0616 - acc: 0.9870 - val_loss: 0.0554 - val_acc: 0.9890\n",
            "Epoch 310/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0562 - acc: 0.9880 - val_loss: 0.0597 - val_acc: 0.9890\n",
            "Epoch 311/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0638 - acc: 0.9880 - val_loss: 0.0699 - val_acc: 0.9860\n",
            "Epoch 312/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0579 - acc: 0.9860 - val_loss: 0.0470 - val_acc: 0.9890\n",
            "Epoch 313/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0528 - acc: 0.9870 - val_loss: 0.0718 - val_acc: 0.9860\n",
            "Epoch 314/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0588 - acc: 0.9860 - val_loss: 0.0781 - val_acc: 0.9800\n",
            "Epoch 315/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0601 - acc: 0.9860 - val_loss: 0.0471 - val_acc: 0.9910\n",
            "Epoch 316/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0517 - acc: 0.9870 - val_loss: 0.0543 - val_acc: 0.9900\n",
            "Epoch 317/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0633 - acc: 0.9830 - val_loss: 0.0461 - val_acc: 0.9930\n",
            "Epoch 318/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0493 - acc: 0.9880 - val_loss: 0.0487 - val_acc: 0.9910\n",
            "Epoch 319/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0542 - acc: 0.9850 - val_loss: 0.0640 - val_acc: 0.9850\n",
            "Epoch 320/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0531 - acc: 0.9900 - val_loss: 0.0588 - val_acc: 0.9870\n",
            "Epoch 321/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0495 - acc: 0.9870 - val_loss: 0.0501 - val_acc: 0.9900\n",
            "Epoch 322/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0503 - acc: 0.9880 - val_loss: 0.0497 - val_acc: 0.9890\n",
            "Epoch 323/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0511 - acc: 0.9850 - val_loss: 0.0406 - val_acc: 0.9930\n",
            "Epoch 324/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0494 - acc: 0.9860 - val_loss: 0.0520 - val_acc: 0.9880\n",
            "Epoch 325/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0516 - acc: 0.9870 - val_loss: 0.0455 - val_acc: 0.9900\n",
            "Epoch 326/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0545 - acc: 0.9880 - val_loss: 0.0365 - val_acc: 0.9930\n",
            "Epoch 327/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0437 - acc: 0.9850 - val_loss: 0.0545 - val_acc: 0.9900\n",
            "Epoch 328/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0451 - acc: 0.9900 - val_loss: 0.0393 - val_acc: 0.9930\n",
            "Epoch 329/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0449 - acc: 0.9920 - val_loss: 0.0536 - val_acc: 0.9880\n",
            "Epoch 330/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0425 - acc: 0.9920 - val_loss: 0.0394 - val_acc: 0.9920\n",
            "Epoch 331/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0529 - acc: 0.9880 - val_loss: 0.0522 - val_acc: 0.9910\n",
            "Epoch 332/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0399 - acc: 0.9930 - val_loss: 0.0351 - val_acc: 0.9950\n",
            "Epoch 333/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0447 - acc: 0.9890 - val_loss: 0.0468 - val_acc: 0.9910\n",
            "Epoch 334/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0407 - acc: 0.9920 - val_loss: 0.0353 - val_acc: 0.9940\n",
            "Epoch 335/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0445 - acc: 0.9880 - val_loss: 0.0346 - val_acc: 0.9950\n",
            "Epoch 336/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0373 - acc: 0.9930 - val_loss: 0.0351 - val_acc: 0.9920\n",
            "Epoch 337/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0389 - acc: 0.9940 - val_loss: 0.0389 - val_acc: 0.9910\n",
            "Epoch 338/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0376 - acc: 0.9900 - val_loss: 0.0332 - val_acc: 0.9940\n",
            "Epoch 339/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0404 - acc: 0.9910 - val_loss: 0.0452 - val_acc: 0.9900\n",
            "Epoch 340/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0397 - acc: 0.9920 - val_loss: 0.0382 - val_acc: 0.9920\n",
            "Epoch 341/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0387 - acc: 0.9930 - val_loss: 0.0318 - val_acc: 0.9950\n",
            "Epoch 342/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0365 - acc: 0.9920 - val_loss: 0.0318 - val_acc: 0.9940\n",
            "Epoch 343/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0338 - acc: 0.9920 - val_loss: 0.0391 - val_acc: 0.9920\n",
            "Epoch 344/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0406 - acc: 0.9890 - val_loss: 0.0317 - val_acc: 0.9940\n",
            "Epoch 345/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0389 - acc: 0.9910 - val_loss: 0.0450 - val_acc: 0.9880\n",
            "Epoch 346/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0429 - acc: 0.9870 - val_loss: 0.0286 - val_acc: 0.9960\n",
            "Epoch 347/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0319 - acc: 0.9930 - val_loss: 0.0291 - val_acc: 0.9960\n",
            "Epoch 348/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0313 - acc: 0.9930 - val_loss: 0.2111 - val_acc: 0.9480\n",
            "Epoch 349/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0629 - acc: 0.9840 - val_loss: 0.0337 - val_acc: 0.9930\n",
            "Epoch 350/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0375 - acc: 0.9890 - val_loss: 0.0314 - val_acc: 0.9950\n",
            "Epoch 351/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0382 - acc: 0.9920 - val_loss: 0.0272 - val_acc: 0.9960\n",
            "Epoch 352/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0318 - acc: 0.9930 - val_loss: 0.0357 - val_acc: 0.9930\n",
            "Epoch 353/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0318 - acc: 0.9930 - val_loss: 0.0286 - val_acc: 0.9950\n",
            "Epoch 354/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0350 - acc: 0.9920 - val_loss: 0.0254 - val_acc: 0.9950\n",
            "Epoch 355/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0311 - acc: 0.9920 - val_loss: 0.0423 - val_acc: 0.9930\n",
            "Epoch 356/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0314 - acc: 0.9940 - val_loss: 0.0449 - val_acc: 0.9900\n",
            "Epoch 357/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0317 - acc: 0.9920 - val_loss: 0.0266 - val_acc: 0.9950\n",
            "Epoch 358/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0422 - acc: 0.9890 - val_loss: 0.0254 - val_acc: 0.9940\n",
            "Epoch 359/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0275 - acc: 0.9930 - val_loss: 0.0254 - val_acc: 0.9940\n",
            "Epoch 360/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0425 - acc: 0.9900 - val_loss: 0.0264 - val_acc: 0.9960\n",
            "Epoch 361/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0273 - acc: 0.9930 - val_loss: 0.0330 - val_acc: 0.9950\n",
            "Epoch 362/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0322 - acc: 0.9920 - val_loss: 0.0296 - val_acc: 0.9940\n",
            "Epoch 363/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0283 - acc: 0.9930 - val_loss: 0.0228 - val_acc: 0.9970\n",
            "Epoch 364/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0285 - acc: 0.9930 - val_loss: 0.0251 - val_acc: 0.9960\n",
            "Epoch 365/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0320 - acc: 0.9910 - val_loss: 0.0514 - val_acc: 0.9890\n",
            "Epoch 366/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0408 - acc: 0.9920 - val_loss: 0.0211 - val_acc: 0.9960\n",
            "Epoch 367/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0234 - acc: 0.9940 - val_loss: 0.0231 - val_acc: 0.9970\n",
            "Epoch 368/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0289 - acc: 0.9920 - val_loss: 0.0492 - val_acc: 0.9880\n",
            "Epoch 369/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0288 - acc: 0.9940 - val_loss: 0.0228 - val_acc: 0.9960\n",
            "Epoch 370/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0261 - acc: 0.9930 - val_loss: 0.0422 - val_acc: 0.9910\n",
            "Epoch 371/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0302 - acc: 0.9920 - val_loss: 0.0199 - val_acc: 0.9960\n",
            "Epoch 372/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0232 - acc: 0.9950 - val_loss: 0.0214 - val_acc: 0.9950\n",
            "Epoch 373/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0293 - acc: 0.9890 - val_loss: 0.0291 - val_acc: 0.9950\n",
            "Epoch 374/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0400 - acc: 0.9900 - val_loss: 0.0274 - val_acc: 0.9930\n",
            "Epoch 375/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0231 - acc: 0.9940 - val_loss: 0.0214 - val_acc: 0.9940\n",
            "Epoch 376/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0265 - acc: 0.9930 - val_loss: 0.0295 - val_acc: 0.9910\n",
            "Epoch 377/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0202 - val_acc: 0.9970\n",
            "Epoch 378/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0295 - acc: 0.9920 - val_loss: 0.0224 - val_acc: 0.9960\n",
            "Epoch 379/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0280 - acc: 0.9900 - val_loss: 0.0218 - val_acc: 0.9960\n",
            "Epoch 380/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0222 - acc: 0.9970 - val_loss: 0.0216 - val_acc: 0.9950\n",
            "Epoch 381/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0260 - acc: 0.9920 - val_loss: 0.0188 - val_acc: 0.9950\n",
            "Epoch 382/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9950 - val_loss: 0.0248 - val_acc: 0.9940\n",
            "Epoch 383/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0293 - acc: 0.9930 - val_loss: 0.0287 - val_acc: 0.9930\n",
            "Epoch 384/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0233 - acc: 0.9930 - val_loss: 0.0209 - val_acc: 0.9960\n",
            "Epoch 385/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0247 - acc: 0.9930 - val_loss: 0.0185 - val_acc: 0.9980\n",
            "Epoch 386/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0232 - acc: 0.9940 - val_loss: 0.0191 - val_acc: 0.9980\n",
            "Epoch 387/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0231 - acc: 0.9930 - val_loss: 0.0193 - val_acc: 0.9970\n",
            "Epoch 388/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0214 - acc: 0.9960 - val_loss: 0.0220 - val_acc: 0.9970\n",
            "Epoch 389/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0209 - acc: 0.9940 - val_loss: 0.0195 - val_acc: 0.9960\n",
            "Epoch 390/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0325 - acc: 0.9910 - val_loss: 0.0178 - val_acc: 0.9960\n",
            "Epoch 391/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0199 - acc: 0.9940 - val_loss: 0.0172 - val_acc: 0.9960\n",
            "Epoch 392/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0201 - acc: 0.9950 - val_loss: 0.0170 - val_acc: 0.9970\n",
            "Epoch 393/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0224 - acc: 0.9950 - val_loss: 0.0192 - val_acc: 0.9970\n",
            "Epoch 394/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0246 - acc: 0.9930 - val_loss: 0.0201 - val_acc: 0.9970\n",
            "Epoch 395/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0206 - acc: 0.9950 - val_loss: 0.0210 - val_acc: 0.9960\n",
            "Epoch 396/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0156 - val_acc: 0.9970\n",
            "Epoch 397/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0241 - acc: 0.9960 - val_loss: 0.0165 - val_acc: 0.9960\n",
            "Epoch 398/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0194 - acc: 0.9930 - val_loss: 0.0171 - val_acc: 0.9960\n",
            "Epoch 399/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0254 - acc: 0.9920 - val_loss: 0.0178 - val_acc: 0.9960\n",
            "Epoch 400/400\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0190 - acc: 0.9950 - val_loss: 0.0157 - val_acc: 0.9970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JJcRUiHMUNPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AN-R557nImB2",
        "colab_type": "code",
        "outputId": "f284632d-35cf-4adb-a209-85dcc392382e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "#針對測試集進行模型的測試\n",
        "\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)\n",
        "\n",
        "NUM_DISPLAY = 10\n",
        "\n",
        "for i in range(NUM_DISPLAY):\n",
        "    story = \" \".join([idx2word[x] for x in Xstest[i].tolist() if x != 0])\n",
        "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
        "    label = idx2word[ytest[i]]\n",
        "    prediction = idx2word[ytest_[i]]\n",
        "    print(story, question, label, prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mary moved to the bathroom . john went to the hallway . where is mary ? bathroom bathroom\n",
            "daniel went back to the hallway . sandra moved to the garden . where is daniel ? hallway hallway\n",
            "john moved to the office . sandra journeyed to the bathroom . where is daniel ? hallway hallway\n",
            "mary moved to the hallway . daniel travelled to the office . where is daniel ? office office\n",
            "john went back to the garden . john moved to the bedroom . where is sandra ? bathroom bathroom\n",
            "sandra travelled to the office . sandra went to the bathroom . where is sandra ? bathroom bathroom\n",
            "mary went to the bedroom . daniel moved to the hallway . where is sandra ? bathroom bathroom\n",
            "john went to the garden . john travelled to the office . where is sandra ? bathroom bathroom\n",
            "daniel journeyed to the bedroom . daniel travelled to the hallway . where is john ? office office\n",
            "john went to the bedroom . john travelled to the office . where is daniel ? hallway office\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tzJywFmLMHDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#儲存訓練好的模型\n",
        "import h5py\n",
        "model.save('qa_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LEnHjjN-OCCn",
        "colab_type": "code",
        "outputId": "3bfd081a-cd6a-432f-da82-48ac4e175ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "my_model = load_model('qa_model.h5')\n",
        "\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = my_model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)\n",
        "\n",
        "NUM_DISPLAY = 10\n",
        "\n",
        "for i in range(NUM_DISPLAY):\n",
        "    story = \" \".join([idx2word[x] for x in Xstest[i].tolist() if x != 0])\n",
        "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
        "    label = idx2word[ytest[i]]\n",
        "    prediction = idx2word[ytest_[i]]\n",
        "    print(story, question, label, prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mary moved to the bathroom . john went to the hallway . where is mary ? bathroom bathroom\n",
            "daniel went back to the hallway . sandra moved to the garden . where is daniel ? hallway hallway\n",
            "john moved to the office . sandra journeyed to the bathroom . where is daniel ? hallway hallway\n",
            "mary moved to the hallway . daniel travelled to the office . where is daniel ? office office\n",
            "john went back to the garden . john moved to the bedroom . where is sandra ? bathroom bathroom\n",
            "sandra travelled to the office . sandra went to the bathroom . where is sandra ? bathroom bathroom\n",
            "mary went to the bedroom . daniel moved to the hallway . where is sandra ? bathroom bathroom\n",
            "john went to the garden . john travelled to the office . where is sandra ? bathroom bathroom\n",
            "daniel journeyed to the bedroom . daniel travelled to the hallway . where is john ? office office\n",
            "john went to the bedroom . john travelled to the office . where is daniel ? hallway office\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gtP7xJb_0LtH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### **來試試加入Google word2vec的embeddings 來做模型的訓練**"
      ]
    },
    {
      "metadata": {
        "id": "p3E8xaHd0Lpb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "wBAYhF3dIRM_",
        "colab_type": "code",
        "outputId": "e940f2ed-805a-42a4-eec4-85dc4f3fb0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from __future__ import division, print_function\n",
        "from gensim.models import Word2Vec\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Dense, Dropout, Reshape, Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from sklearn.cross_validation import train_test_split\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "#下載Google word embeedings\n",
        "!wget --no-check-certificate -r 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz' -O GoogleNews-vectors-negative300.bin.gz\n",
        "\n",
        "\n",
        "#https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
        "WORD2VEC_BIN = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n",
        "#設定資料(word2vec)存放目錄\n",
        "DATA_DIR  = \"./\"\n",
        "\n",
        "word2vec = KeyedVectors.load_word2vec_format(\n",
        "    os.path.join(DATA_DIR, WORD2VEC_BIN), binary=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.45)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.45 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.45)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.45->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.45->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2018-11-15 06:38:01--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.158\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  77.3MB/s    in 20s     \n",
            "\n",
            "2018-11-15 06:38:21 (76.7 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n",
            "FINISHED --2018-11-15 06:38:21--\n",
            "Total wall clock time: 21s\n",
            "Downloaded: 1 files, 1.5G in 20s (76.7 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GkjLMMWcLCuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "WORD2VEC_EMBED_SIZE = 300\n",
        "embedding_weights = np.zeros((vocab_size, WORD2VEC_EMBED_SIZE))\n",
        "for word, index in word2idx.items():\n",
        "    try:\n",
        "        embedding_weights[index, :] = word2vec[word.lower()]\n",
        "    except KeyError:\n",
        "        pass  # keep as zero (not ideal, but what else can we do?)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1dUlIq4L6iP",
        "colab_type": "code",
        "outputId": "9870bcff-5250-4a71-845d-2fb691eb1f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Dropout, Reshape, Flatten\n",
        "import keras.backend as K\n",
        "K.clear_session()\n",
        "# define network\n",
        "EMBEDDING_SIZE = 300\n",
        "LATENT_SIZE = 32\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 400\n",
        "\n",
        "# inputs\n",
        "story_input = Input(shape=(story_maxlen,), name ='story')\n",
        "question_input = Input(shape=(question_maxlen,), name ='question')\n",
        "\n",
        "\n",
        "#text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "embedded_text = layers.Embedding(input_dim=vocab_size,\n",
        "                          output_dim=EMBEDDING_SIZE,\n",
        "                          input_length=story_maxlen, weights=[embedding_weights], trainable=False)(story_input)\n",
        "#embedded_text = Dropout(0.3)(embedded_text)\n",
        "\n",
        "\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "\n",
        "\n",
        "#question_input = Input(shape=(None,),dtype='int32', name='question')\n",
        "embedded_question = layers.Embedding(input_dim=vocab_size,\n",
        "                             output_dim=EMBEDDING_SIZE,\n",
        "                             input_length=question_maxlen, weights=[embedding_weights],  trainable=False)(question_input)\n",
        "#embedded_question = Dropout(0.3)(embedded_question)\n",
        "\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "#Merge([qenc, aenc], mode=\"dot\", dot_axes=[1, 1])\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question],axis=-1)\n",
        "answer = layers.Dense(vocab_size,\n",
        "activation='softmax')(concatenated)\n",
        "model = Model([story_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['acc'])\n",
        "model.summary()\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "story (InputLayer)              (None, 14)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 14, 300)      6600        story[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 4, 300)       6600        question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 16)           20288       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 48)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 22)           1078        concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 77,190\n",
            "Trainable params: 63,990\n",
            "Non-trainable params: 13,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"387pt\" viewBox=\"0.00 0.00 696.00 387.00\" width=\"696pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 692,-383 692,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140178357671136 -->\n<g class=\"node\" id=\"node1\">\n<title>140178357671136</title>\n<polygon fill=\"none\" points=\"42.5,-332.5 42.5,-378.5 296.5,-378.5 296.5,-332.5 42.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"100.5\" y=\"-351.8\">story: InputLayer</text>\n<polyline fill=\"none\" points=\"158.5,-332.5 158.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"158.5,-355.5 216.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"216.5,-332.5 216.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-363.3\">(None, 14)</text>\n<polyline fill=\"none\" points=\"216.5,-355.5 296.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-340.3\">(None, 14)</text>\n</g>\n<!-- 140178357672704 -->\n<g class=\"node\" id=\"node3\">\n<title>140178357672704</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 339,-295.5 339,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-268.8\">embedding_1: Embedding</text>\n<polyline fill=\"none\" points=\"171,-249.5 171,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"171,-272.5 229,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"229,-249.5 229,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284\" y=\"-280.3\">(None, 14)</text>\n<polyline fill=\"none\" points=\"229,-272.5 339,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284\" y=\"-257.3\">(None, 14, 300)</text>\n</g>\n<!-- 140178357671136&#45;&gt;140178357672704 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140178357671136-&gt;140178357672704</title>\n<path d=\"M169.5,-332.3799C169.5,-324.1745 169.5,-314.7679 169.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"173.0001,-305.784 169.5,-295.784 166.0001,-305.784 173.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178357671528 -->\n<g class=\"node\" id=\"node2\">\n<title>140178357671528</title>\n<polygon fill=\"none\" points=\"389,-332.5 389,-378.5 656,-378.5 656,-332.5 389,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457.5\" y=\"-351.8\">question: InputLayer</text>\n<polyline fill=\"none\" points=\"526,-332.5 526,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"526,-355.5 584,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"584,-332.5 584,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-363.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"584,-355.5 656,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-340.3\">(None, 4)</text>\n</g>\n<!-- 140178357671864 -->\n<g class=\"node\" id=\"node4\">\n<title>140178357671864</title>\n<polygon fill=\"none\" points=\"357,-249.5 357,-295.5 688,-295.5 688,-249.5 357,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442.5\" y=\"-268.8\">embedding_2: Embedding</text>\n<polyline fill=\"none\" points=\"528,-249.5 528,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"528,-272.5 586,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"586,-249.5 586,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637\" y=\"-280.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"586,-272.5 688,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637\" y=\"-257.3\">(None, 4, 300)</text>\n</g>\n<!-- 140178357671528&#45;&gt;140178357671864 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140178357671528-&gt;140178357671864</title>\n<path d=\"M522.5,-332.3799C522.5,-324.1745 522.5,-314.7679 522.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"526.0001,-305.784 522.5,-295.784 519.0001,-305.784 526.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178357671696 -->\n<g class=\"node\" id=\"node5\">\n<title>140178357671696</title>\n<polygon fill=\"none\" points=\"68.5,-166.5 68.5,-212.5 338.5,-212.5 338.5,-166.5 68.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.5\" y=\"-185.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"170.5,-166.5 170.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"170.5,-189.5 228.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"228.5,-166.5 228.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-197.3\">(None, 14, 300)</text>\n<polyline fill=\"none\" points=\"228.5,-189.5 338.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 140178357672704&#45;&gt;140178357671696 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140178357672704-&gt;140178357671696</title>\n<path d=\"M178.9709,-249.3799C182.4052,-240.9962 186.3532,-231.3584 190.064,-222.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"193.41,-223.3645 193.962,-212.784 186.9324,-220.7109 193.41,-223.3645\" stroke=\"#000000\"/>\n</g>\n<!-- 140178358505032 -->\n<g class=\"node\" id=\"node6\">\n<title>140178358505032</title>\n<polygon fill=\"none\" points=\"373.5,-166.5 373.5,-212.5 635.5,-212.5 635.5,-166.5 373.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-185.8\">lstm_2: LSTM</text>\n<polyline fill=\"none\" points=\"475.5,-166.5 475.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"475.5,-189.5 533.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"533.5,-166.5 533.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"584.5\" y=\"-197.3\">(None, 4, 300)</text>\n<polyline fill=\"none\" points=\"533.5,-189.5 635.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"584.5\" y=\"-174.3\">(None, 16)</text>\n</g>\n<!-- 140178357671864&#45;&gt;140178358505032 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140178357671864-&gt;140178358505032</title>\n<path d=\"M517.486,-249.3799C515.6872,-241.0854 513.6222,-231.5633 511.6759,-222.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"515.0895,-221.815 509.5495,-212.784 508.2485,-223.2987 515.0895,-221.815\" stroke=\"#000000\"/>\n</g>\n<!-- 140178357796088 -->\n<g class=\"node\" id=\"node7\">\n<title>140178357796088</title>\n<polygon fill=\"none\" points=\"149.5,-83.5 149.5,-129.5 541.5,-129.5 541.5,-83.5 149.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-102.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"324.5,-83.5 324.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"324.5,-106.5 382.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"382.5,-83.5 382.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"462\" y=\"-114.3\">[(None, 32), (None, 16)]</text>\n<polyline fill=\"none\" points=\"382.5,-106.5 541.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"462\" y=\"-91.3\">(None, 48)</text>\n</g>\n<!-- 140178357671696&#45;&gt;140178357796088 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140178357671696-&gt;140178357796088</title>\n<path d=\"M243.0549,-166.3799C259.6869,-156.6583 279.2039,-145.2505 296.7158,-135.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"298.7975,-137.852 305.6647,-129.784 295.2651,-131.8086 298.7975,-137.852\" stroke=\"#000000\"/>\n</g>\n<!-- 140178358505032&#45;&gt;140178357796088 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140178358505032-&gt;140178357796088</title>\n<path d=\"M460.2096,-166.3799C441.1651,-156.4384 418.7423,-144.7334 398.797,-134.3217\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"400.3129,-131.1649 389.8283,-129.6399 397.0735,-137.3703 400.3129,-131.1649\" stroke=\"#000000\"/>\n</g>\n<!-- 140178357672984 -->\n<g class=\"node\" id=\"node8\">\n<title>140178357672984</title>\n<polygon fill=\"none\" points=\"223,-.5 223,-46.5 468,-46.5 468,-.5 223,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"330,-.5 330,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"330,-23.5 388,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"388,-.5 388,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"428\" y=\"-31.3\">(None, 48)</text>\n<polyline fill=\"none\" points=\"388,-23.5 468,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"428\" y=\"-8.3\">(None, 22)</text>\n</g>\n<!-- 140178357796088&#45;&gt;140178357672984 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140178357796088-&gt;140178357672984</title>\n<path d=\"M345.5,-83.3799C345.5,-75.1745 345.5,-65.7679 345.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"349.0001,-56.784 345.5,-46.784 342.0001,-56.784 349.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "AfdF-vd6IGg5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tbc=TensorBoardColab()\n",
        "    #tensorboard = TensorBoard(log_dir=log_dir)\n",
        "    tensorboard = TensorBoardColabCallback(tbc,histogram_freq=1,embeddings_freq=0,  embeddings_layer_names = ['embedded_text','embedded_question'] ) #, embeddings_metadata = '/content/logs/' + meta_file\n",
        "    # ['embedded_text','embedded_question']\n",
        "    return tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHkzv3j6P_gk",
        "colab_type": "code",
        "outputId": "206a8db2-fe21-4d76-bdea-002dfe86ff66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13685
        }
      },
      "cell_type": "code",
      "source": [
        "tensorboard = make_tensorboard(set_dir_name='network')\n",
        "\n",
        "#開始訓練模型\n",
        "history = model.fit([Xstrain, Xqtrain], [Ytrain], batch_size=BATCH_SIZE,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=[tensorboard],\n",
        "                    validation_data=([Xstest, Xqtest], [Ytest]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://05f9b0a2.ngrok.io\n",
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/400\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3178 - acc: 0.2010 - val_loss: 1.8685 - val_acc: 0.3140\n",
            "Epoch 2/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7379 - acc: 0.3840 - val_loss: 1.6171 - val_acc: 0.4190\n",
            "Epoch 3/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5276 - acc: 0.5070 - val_loss: 1.4546 - val_acc: 0.5230\n",
            "Epoch 4/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4010 - acc: 0.5500 - val_loss: 1.3965 - val_acc: 0.5120\n",
            "Epoch 5/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3299 - acc: 0.5460 - val_loss: 1.3570 - val_acc: 0.5220\n",
            "Epoch 6/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2821 - acc: 0.5450 - val_loss: 1.2508 - val_acc: 0.5660\n",
            "Epoch 7/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2381 - acc: 0.5460 - val_loss: 1.2589 - val_acc: 0.5390\n",
            "Epoch 8/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2136 - acc: 0.5500 - val_loss: 1.1760 - val_acc: 0.5620\n",
            "Epoch 9/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1913 - acc: 0.5610 - val_loss: 1.1995 - val_acc: 0.5440\n",
            "Epoch 10/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1741 - acc: 0.5590 - val_loss: 1.1693 - val_acc: 0.5700\n",
            "Epoch 11/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1684 - acc: 0.5550 - val_loss: 1.1749 - val_acc: 0.5430\n",
            "Epoch 12/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1611 - acc: 0.5550 - val_loss: 1.1780 - val_acc: 0.5410\n",
            "Epoch 13/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1436 - acc: 0.5510 - val_loss: 1.1256 - val_acc: 0.5800\n",
            "Epoch 14/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1335 - acc: 0.5760 - val_loss: 1.1417 - val_acc: 0.5850\n",
            "Epoch 15/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1261 - acc: 0.5720 - val_loss: 1.1080 - val_acc: 0.5880\n",
            "Epoch 16/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1213 - acc: 0.5860 - val_loss: 1.1072 - val_acc: 0.5930\n",
            "Epoch 17/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1221 - acc: 0.5750 - val_loss: 1.0952 - val_acc: 0.5850\n",
            "Epoch 18/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1064 - acc: 0.5770 - val_loss: 1.0805 - val_acc: 0.5960\n",
            "Epoch 19/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1002 - acc: 0.5760 - val_loss: 1.0853 - val_acc: 0.6080\n",
            "Epoch 20/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0952 - acc: 0.5930 - val_loss: 1.0707 - val_acc: 0.6090\n",
            "Epoch 21/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0909 - acc: 0.5910 - val_loss: 1.0756 - val_acc: 0.6000\n",
            "Epoch 22/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0800 - acc: 0.5980 - val_loss: 1.0609 - val_acc: 0.6060\n",
            "Epoch 23/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0760 - acc: 0.6070 - val_loss: 1.0539 - val_acc: 0.6230\n",
            "Epoch 24/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0619 - acc: 0.6190 - val_loss: 1.0502 - val_acc: 0.6230\n",
            "Epoch 25/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0639 - acc: 0.6100 - val_loss: 1.0410 - val_acc: 0.6190\n",
            "Epoch 26/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0597 - acc: 0.6040 - val_loss: 1.0652 - val_acc: 0.6010\n",
            "Epoch 27/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0508 - acc: 0.6180 - val_loss: 1.0230 - val_acc: 0.6230\n",
            "Epoch 28/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0422 - acc: 0.6190 - val_loss: 1.0384 - val_acc: 0.6120\n",
            "Epoch 29/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0408 - acc: 0.6120 - val_loss: 1.0124 - val_acc: 0.6340\n",
            "Epoch 30/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0287 - acc: 0.6180 - val_loss: 1.0401 - val_acc: 0.6270\n",
            "Epoch 31/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0207 - acc: 0.6140 - val_loss: 1.0301 - val_acc: 0.6080\n",
            "Epoch 32/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0180 - acc: 0.6180 - val_loss: 0.9914 - val_acc: 0.6300\n",
            "Epoch 33/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0067 - acc: 0.6460 - val_loss: 0.9857 - val_acc: 0.6420\n",
            "Epoch 34/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0050 - acc: 0.6370 - val_loss: 0.9732 - val_acc: 0.6470\n",
            "Epoch 35/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9989 - acc: 0.6250 - val_loss: 0.9715 - val_acc: 0.6460\n",
            "Epoch 36/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9859 - acc: 0.6320 - val_loss: 1.0002 - val_acc: 0.6350\n",
            "Epoch 37/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9910 - acc: 0.6450 - val_loss: 0.9741 - val_acc: 0.6630\n",
            "Epoch 38/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9757 - acc: 0.6490 - val_loss: 0.9579 - val_acc: 0.6520\n",
            "Epoch 39/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9705 - acc: 0.6490 - val_loss: 0.9617 - val_acc: 0.6380\n",
            "Epoch 40/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9641 - acc: 0.6500 - val_loss: 0.9263 - val_acc: 0.6700\n",
            "Epoch 41/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9585 - acc: 0.6440 - val_loss: 0.9472 - val_acc: 0.6670\n",
            "Epoch 42/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9543 - acc: 0.6510 - val_loss: 0.9530 - val_acc: 0.6460\n",
            "Epoch 43/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9455 - acc: 0.6530 - val_loss: 0.9277 - val_acc: 0.6550\n",
            "Epoch 44/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9349 - acc: 0.6640 - val_loss: 0.9089 - val_acc: 0.6830\n",
            "Epoch 45/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9329 - acc: 0.6670 - val_loss: 0.8973 - val_acc: 0.6820\n",
            "Epoch 46/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9222 - acc: 0.6760 - val_loss: 0.9277 - val_acc: 0.6700\n",
            "Epoch 47/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9107 - acc: 0.6740 - val_loss: 0.9006 - val_acc: 0.6780\n",
            "Epoch 48/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9156 - acc: 0.6830 - val_loss: 0.8825 - val_acc: 0.6830\n",
            "Epoch 49/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9030 - acc: 0.6790 - val_loss: 0.9115 - val_acc: 0.6660\n",
            "Epoch 50/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9043 - acc: 0.6830 - val_loss: 0.8698 - val_acc: 0.6890\n",
            "Epoch 51/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8851 - acc: 0.6920 - val_loss: 0.8900 - val_acc: 0.6770\n",
            "Epoch 52/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8815 - acc: 0.6930 - val_loss: 0.8533 - val_acc: 0.7080\n",
            "Epoch 53/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8723 - acc: 0.7010 - val_loss: 0.8669 - val_acc: 0.6930\n",
            "Epoch 54/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8643 - acc: 0.7100 - val_loss: 0.8514 - val_acc: 0.7030\n",
            "Epoch 55/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8605 - acc: 0.6990 - val_loss: 0.8165 - val_acc: 0.7300\n",
            "Epoch 56/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8521 - acc: 0.7090 - val_loss: 0.8247 - val_acc: 0.7130\n",
            "Epoch 57/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8474 - acc: 0.7030 - val_loss: 0.8300 - val_acc: 0.7080\n",
            "Epoch 58/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8304 - acc: 0.7200 - val_loss: 0.8689 - val_acc: 0.6890\n",
            "Epoch 59/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8298 - acc: 0.7120 - val_loss: 0.8523 - val_acc: 0.6980\n",
            "Epoch 60/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8212 - acc: 0.7130 - val_loss: 0.7881 - val_acc: 0.7300\n",
            "Epoch 61/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8095 - acc: 0.7230 - val_loss: 0.8287 - val_acc: 0.7000\n",
            "Epoch 62/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8055 - acc: 0.7180 - val_loss: 0.7846 - val_acc: 0.7300\n",
            "Epoch 63/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7950 - acc: 0.7310 - val_loss: 0.8152 - val_acc: 0.7060\n",
            "Epoch 64/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7837 - acc: 0.7230 - val_loss: 0.7915 - val_acc: 0.7260\n",
            "Epoch 65/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7810 - acc: 0.7360 - val_loss: 0.7717 - val_acc: 0.7360\n",
            "Epoch 66/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7734 - acc: 0.7390 - val_loss: 0.7500 - val_acc: 0.7500\n",
            "Epoch 67/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7659 - acc: 0.7390 - val_loss: 0.7371 - val_acc: 0.7600\n",
            "Epoch 68/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7600 - acc: 0.7500 - val_loss: 0.7353 - val_acc: 0.7430\n",
            "Epoch 69/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7519 - acc: 0.7550 - val_loss: 0.7214 - val_acc: 0.7530\n",
            "Epoch 70/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7454 - acc: 0.7480 - val_loss: 0.7166 - val_acc: 0.7630\n",
            "Epoch 71/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7268 - acc: 0.7520 - val_loss: 0.7231 - val_acc: 0.7500\n",
            "Epoch 72/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7290 - acc: 0.7570 - val_loss: 0.7222 - val_acc: 0.7530\n",
            "Epoch 73/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7133 - acc: 0.7570 - val_loss: 0.7188 - val_acc: 0.7540\n",
            "Epoch 74/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7105 - acc: 0.7510 - val_loss: 0.6868 - val_acc: 0.7660\n",
            "Epoch 75/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6983 - acc: 0.7670 - val_loss: 0.6926 - val_acc: 0.7690\n",
            "Epoch 76/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6928 - acc: 0.7630 - val_loss: 0.6580 - val_acc: 0.7810\n",
            "Epoch 77/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6853 - acc: 0.7670 - val_loss: 0.6492 - val_acc: 0.7880\n",
            "Epoch 78/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6737 - acc: 0.7750 - val_loss: 0.6853 - val_acc: 0.7590\n",
            "Epoch 79/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6739 - acc: 0.7730 - val_loss: 0.6774 - val_acc: 0.7700\n",
            "Epoch 80/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6706 - acc: 0.7790 - val_loss: 0.6495 - val_acc: 0.7950\n",
            "Epoch 81/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6567 - acc: 0.7780 - val_loss: 0.6368 - val_acc: 0.7910\n",
            "Epoch 82/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6559 - acc: 0.7840 - val_loss: 0.6439 - val_acc: 0.7790\n",
            "Epoch 83/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6460 - acc: 0.7880 - val_loss: 0.6403 - val_acc: 0.7880\n",
            "Epoch 84/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6401 - acc: 0.7860 - val_loss: 0.6158 - val_acc: 0.8030\n",
            "Epoch 85/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6278 - acc: 0.7950 - val_loss: 0.5895 - val_acc: 0.8130\n",
            "Epoch 86/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6240 - acc: 0.7940 - val_loss: 0.5941 - val_acc: 0.8130\n",
            "Epoch 87/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6158 - acc: 0.8010 - val_loss: 0.6482 - val_acc: 0.7790\n",
            "Epoch 88/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6119 - acc: 0.7950 - val_loss: 0.5745 - val_acc: 0.8150\n",
            "Epoch 89/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6103 - acc: 0.7940 - val_loss: 0.5821 - val_acc: 0.8060\n",
            "Epoch 90/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5981 - acc: 0.8050 - val_loss: 0.5915 - val_acc: 0.8040\n",
            "Epoch 91/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5840 - acc: 0.8150 - val_loss: 0.5579 - val_acc: 0.8240\n",
            "Epoch 92/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5862 - acc: 0.8000 - val_loss: 0.5594 - val_acc: 0.8160\n",
            "Epoch 93/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5702 - acc: 0.8140 - val_loss: 0.5764 - val_acc: 0.8040\n",
            "Epoch 94/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5729 - acc: 0.8200 - val_loss: 0.5900 - val_acc: 0.7910\n",
            "Epoch 95/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5611 - acc: 0.8100 - val_loss: 0.5568 - val_acc: 0.8120\n",
            "Epoch 96/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5580 - acc: 0.8120 - val_loss: 0.5525 - val_acc: 0.8200\n",
            "Epoch 97/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5521 - acc: 0.8250 - val_loss: 0.5460 - val_acc: 0.8160\n",
            "Epoch 98/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5477 - acc: 0.8150 - val_loss: 0.5082 - val_acc: 0.8430\n",
            "Epoch 99/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5364 - acc: 0.8230 - val_loss: 0.4905 - val_acc: 0.8460\n",
            "Epoch 100/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5301 - acc: 0.8280 - val_loss: 0.5005 - val_acc: 0.8270\n",
            "Epoch 101/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5230 - acc: 0.8280 - val_loss: 0.5203 - val_acc: 0.8270\n",
            "Epoch 102/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5189 - acc: 0.8280 - val_loss: 0.5336 - val_acc: 0.8220\n",
            "Epoch 103/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5098 - acc: 0.8340 - val_loss: 0.4849 - val_acc: 0.8440\n",
            "Epoch 104/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5038 - acc: 0.8310 - val_loss: 0.4867 - val_acc: 0.8500\n",
            "Epoch 105/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4962 - acc: 0.8310 - val_loss: 0.4911 - val_acc: 0.8420\n",
            "Epoch 106/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4854 - acc: 0.8500 - val_loss: 0.4546 - val_acc: 0.8620\n",
            "Epoch 107/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4845 - acc: 0.8460 - val_loss: 0.4988 - val_acc: 0.8390\n",
            "Epoch 108/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4833 - acc: 0.8440 - val_loss: 0.4427 - val_acc: 0.8610\n",
            "Epoch 109/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4675 - acc: 0.8490 - val_loss: 0.4672 - val_acc: 0.8420\n",
            "Epoch 110/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4702 - acc: 0.8490 - val_loss: 0.4836 - val_acc: 0.8500\n",
            "Epoch 111/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4586 - acc: 0.8510 - val_loss: 0.4827 - val_acc: 0.8430\n",
            "Epoch 112/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4507 - acc: 0.8530 - val_loss: 0.4830 - val_acc: 0.8360\n",
            "Epoch 113/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4485 - acc: 0.8530 - val_loss: 0.4426 - val_acc: 0.8590\n",
            "Epoch 114/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4441 - acc: 0.8590 - val_loss: 0.4097 - val_acc: 0.8820\n",
            "Epoch 115/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4344 - acc: 0.8590 - val_loss: 0.4031 - val_acc: 0.8700\n",
            "Epoch 116/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4304 - acc: 0.8660 - val_loss: 0.3982 - val_acc: 0.8860\n",
            "Epoch 117/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4172 - acc: 0.8710 - val_loss: 0.4385 - val_acc: 0.8490\n",
            "Epoch 118/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4188 - acc: 0.8670 - val_loss: 0.3913 - val_acc: 0.8730\n",
            "Epoch 119/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4153 - acc: 0.8670 - val_loss: 0.3989 - val_acc: 0.8790\n",
            "Epoch 120/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4037 - acc: 0.8720 - val_loss: 0.3842 - val_acc: 0.8820\n",
            "Epoch 121/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3981 - acc: 0.8730 - val_loss: 0.3734 - val_acc: 0.8870\n",
            "Epoch 122/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3975 - acc: 0.8730 - val_loss: 0.3744 - val_acc: 0.8780\n",
            "Epoch 123/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3874 - acc: 0.8850 - val_loss: 0.4164 - val_acc: 0.8660\n",
            "Epoch 124/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3837 - acc: 0.8740 - val_loss: 0.3789 - val_acc: 0.8700\n",
            "Epoch 125/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3765 - acc: 0.8810 - val_loss: 0.3497 - val_acc: 0.9010\n",
            "Epoch 126/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3681 - acc: 0.8880 - val_loss: 0.3492 - val_acc: 0.8960\n",
            "Epoch 127/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3704 - acc: 0.8840 - val_loss: 0.3561 - val_acc: 0.8910\n",
            "Epoch 128/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3602 - acc: 0.8930 - val_loss: 0.3625 - val_acc: 0.8830\n",
            "Epoch 129/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3523 - acc: 0.8780 - val_loss: 0.3298 - val_acc: 0.9020\n",
            "Epoch 130/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3419 - acc: 0.8910 - val_loss: 0.3655 - val_acc: 0.8880\n",
            "Epoch 131/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - acc: 0.8970 - val_loss: 0.3189 - val_acc: 0.9070\n",
            "Epoch 132/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3471 - acc: 0.8910 - val_loss: 0.3215 - val_acc: 0.8990\n",
            "Epoch 133/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3379 - acc: 0.8920 - val_loss: 0.3162 - val_acc: 0.9050\n",
            "Epoch 134/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3249 - acc: 0.8970 - val_loss: 0.3072 - val_acc: 0.9150\n",
            "Epoch 135/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3193 - acc: 0.9060 - val_loss: 0.3068 - val_acc: 0.9110\n",
            "Epoch 136/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3237 - acc: 0.9010 - val_loss: 0.2891 - val_acc: 0.9160\n",
            "Epoch 137/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3154 - acc: 0.8990 - val_loss: 0.4164 - val_acc: 0.8530\n",
            "Epoch 138/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3130 - acc: 0.9080 - val_loss: 0.3138 - val_acc: 0.9030\n",
            "Epoch 139/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3060 - acc: 0.9120 - val_loss: 0.3213 - val_acc: 0.8990\n",
            "Epoch 140/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3009 - acc: 0.9070 - val_loss: 0.2981 - val_acc: 0.9140\n",
            "Epoch 141/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3000 - acc: 0.9060 - val_loss: 0.3157 - val_acc: 0.8980\n",
            "Epoch 142/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2990 - acc: 0.9150 - val_loss: 0.2931 - val_acc: 0.9150\n",
            "Epoch 143/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2905 - acc: 0.9100 - val_loss: 0.2937 - val_acc: 0.9130\n",
            "Epoch 144/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2800 - acc: 0.9160 - val_loss: 0.3241 - val_acc: 0.9070\n",
            "Epoch 145/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2808 - acc: 0.9180 - val_loss: 0.2601 - val_acc: 0.9250\n",
            "Epoch 146/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2769 - acc: 0.9190 - val_loss: 0.2610 - val_acc: 0.9290\n",
            "Epoch 147/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2722 - acc: 0.9210 - val_loss: 0.2728 - val_acc: 0.9220\n",
            "Epoch 148/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2678 - acc: 0.9220 - val_loss: 0.2387 - val_acc: 0.9320\n",
            "Epoch 149/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2703 - acc: 0.9250 - val_loss: 0.2452 - val_acc: 0.9350\n",
            "Epoch 150/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2529 - acc: 0.9310 - val_loss: 0.2594 - val_acc: 0.9230\n",
            "Epoch 151/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2606 - acc: 0.9290 - val_loss: 0.2490 - val_acc: 0.9280\n",
            "Epoch 152/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2500 - acc: 0.9330 - val_loss: 0.2436 - val_acc: 0.9370\n",
            "Epoch 153/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2523 - acc: 0.9330 - val_loss: 0.2398 - val_acc: 0.9380\n",
            "Epoch 154/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2472 - acc: 0.9280 - val_loss: 0.2253 - val_acc: 0.9440\n",
            "Epoch 155/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2396 - acc: 0.9350 - val_loss: 0.2643 - val_acc: 0.9240\n",
            "Epoch 156/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2422 - acc: 0.9350 - val_loss: 0.2214 - val_acc: 0.9520\n",
            "Epoch 157/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2310 - acc: 0.9420 - val_loss: 0.2321 - val_acc: 0.9410\n",
            "Epoch 158/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2321 - acc: 0.9380 - val_loss: 0.3210 - val_acc: 0.8970\n",
            "Epoch 159/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2275 - acc: 0.9370 - val_loss: 0.2620 - val_acc: 0.9230\n",
            "Epoch 160/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2188 - acc: 0.9470 - val_loss: 0.2129 - val_acc: 0.9510\n",
            "Epoch 161/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2240 - acc: 0.9360 - val_loss: 0.2095 - val_acc: 0.9420\n",
            "Epoch 162/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2138 - acc: 0.9500 - val_loss: 0.2124 - val_acc: 0.9470\n",
            "Epoch 163/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2132 - acc: 0.9490 - val_loss: 0.2101 - val_acc: 0.9470\n",
            "Epoch 164/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2063 - acc: 0.9500 - val_loss: 0.1912 - val_acc: 0.9570\n",
            "Epoch 165/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2073 - acc: 0.9530 - val_loss: 0.2152 - val_acc: 0.9470\n",
            "Epoch 166/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2048 - acc: 0.9490 - val_loss: 0.1815 - val_acc: 0.9610\n",
            "Epoch 167/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1970 - acc: 0.9520 - val_loss: 0.1959 - val_acc: 0.9550\n",
            "Epoch 168/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1926 - acc: 0.9560 - val_loss: 0.1993 - val_acc: 0.9510\n",
            "Epoch 169/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1978 - acc: 0.9480 - val_loss: 0.1763 - val_acc: 0.9600\n",
            "Epoch 170/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1846 - acc: 0.9570 - val_loss: 0.1718 - val_acc: 0.9610\n",
            "Epoch 171/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1866 - acc: 0.9530 - val_loss: 0.1893 - val_acc: 0.9510\n",
            "Epoch 172/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1785 - acc: 0.9620 - val_loss: 0.1785 - val_acc: 0.9550\n",
            "Epoch 173/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1802 - acc: 0.9590 - val_loss: 0.1711 - val_acc: 0.9560\n",
            "Epoch 174/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1739 - acc: 0.9560 - val_loss: 0.1766 - val_acc: 0.9540\n",
            "Epoch 175/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1717 - acc: 0.9590 - val_loss: 0.1690 - val_acc: 0.9560\n",
            "Epoch 176/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1730 - acc: 0.9610 - val_loss: 0.1590 - val_acc: 0.9600\n",
            "Epoch 177/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1649 - acc: 0.9600 - val_loss: 0.1457 - val_acc: 0.9690\n",
            "Epoch 178/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1662 - acc: 0.9630 - val_loss: 0.1642 - val_acc: 0.9600\n",
            "Epoch 179/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1649 - acc: 0.9640 - val_loss: 0.1436 - val_acc: 0.9670\n",
            "Epoch 180/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1560 - acc: 0.9650 - val_loss: 0.1539 - val_acc: 0.9650\n",
            "Epoch 181/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1594 - acc: 0.9660 - val_loss: 0.1610 - val_acc: 0.9630\n",
            "Epoch 182/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1546 - acc: 0.9610 - val_loss: 0.1482 - val_acc: 0.9680\n",
            "Epoch 183/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1458 - acc: 0.9720 - val_loss: 0.1420 - val_acc: 0.9700\n",
            "Epoch 184/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1477 - acc: 0.9680 - val_loss: 0.1329 - val_acc: 0.9730\n",
            "Epoch 185/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1464 - acc: 0.9660 - val_loss: 0.1303 - val_acc: 0.9730\n",
            "Epoch 186/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1418 - acc: 0.9680 - val_loss: 0.1800 - val_acc: 0.9530\n",
            "Epoch 187/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1429 - acc: 0.9700 - val_loss: 0.1502 - val_acc: 0.9680\n",
            "Epoch 188/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1435 - acc: 0.9730 - val_loss: 0.1227 - val_acc: 0.9790\n",
            "Epoch 189/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1409 - acc: 0.9670 - val_loss: 0.1259 - val_acc: 0.9740\n",
            "Epoch 190/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1327 - acc: 0.9730 - val_loss: 0.1210 - val_acc: 0.9720\n",
            "Epoch 191/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1345 - acc: 0.9680 - val_loss: 0.1206 - val_acc: 0.9800\n",
            "Epoch 192/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1280 - acc: 0.9730 - val_loss: 0.1263 - val_acc: 0.9780\n",
            "Epoch 193/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1316 - acc: 0.9730 - val_loss: 0.1320 - val_acc: 0.9760\n",
            "Epoch 194/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1190 - acc: 0.9740 - val_loss: 0.1351 - val_acc: 0.9690\n",
            "Epoch 195/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1296 - acc: 0.9750 - val_loss: 0.1063 - val_acc: 0.9820\n",
            "Epoch 196/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1147 - acc: 0.9790 - val_loss: 0.1644 - val_acc: 0.9620\n",
            "Epoch 197/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1213 - acc: 0.9760 - val_loss: 0.1016 - val_acc: 0.9810\n",
            "Epoch 198/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1123 - acc: 0.9770 - val_loss: 0.1109 - val_acc: 0.9780\n",
            "Epoch 199/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1168 - acc: 0.9790 - val_loss: 0.1609 - val_acc: 0.9620\n",
            "Epoch 200/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1212 - acc: 0.9740 - val_loss: 0.1117 - val_acc: 0.9800\n",
            "Epoch 201/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1061 - acc: 0.9790 - val_loss: 0.1065 - val_acc: 0.9810\n",
            "Epoch 202/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1163 - acc: 0.9820 - val_loss: 0.1085 - val_acc: 0.9830\n",
            "Epoch 203/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1046 - acc: 0.9810 - val_loss: 0.1088 - val_acc: 0.9780\n",
            "Epoch 204/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1060 - acc: 0.9810 - val_loss: 0.1270 - val_acc: 0.9740\n",
            "Epoch 205/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1069 - acc: 0.9720 - val_loss: 0.1129 - val_acc: 0.9800\n",
            "Epoch 206/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1023 - acc: 0.9780 - val_loss: 0.0864 - val_acc: 0.9850\n",
            "Epoch 207/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0975 - acc: 0.9830 - val_loss: 0.0977 - val_acc: 0.9830\n",
            "Epoch 208/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1138 - acc: 0.9760 - val_loss: 0.1416 - val_acc: 0.9700\n",
            "Epoch 209/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1000 - acc: 0.9820 - val_loss: 0.0818 - val_acc: 0.9880\n",
            "Epoch 210/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0948 - acc: 0.9810 - val_loss: 0.1021 - val_acc: 0.9780\n",
            "Epoch 211/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0964 - acc: 0.9820 - val_loss: 0.0994 - val_acc: 0.9780\n",
            "Epoch 212/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0991 - acc: 0.9840 - val_loss: 0.0792 - val_acc: 0.9880\n",
            "Epoch 213/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0890 - acc: 0.9860 - val_loss: 0.0770 - val_acc: 0.9870\n",
            "Epoch 214/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0925 - acc: 0.9790 - val_loss: 0.0846 - val_acc: 0.9850\n",
            "Epoch 215/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0879 - acc: 0.9830 - val_loss: 0.0839 - val_acc: 0.9850\n",
            "Epoch 216/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0850 - acc: 0.9850 - val_loss: 0.0940 - val_acc: 0.9820\n",
            "Epoch 217/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0864 - acc: 0.9840 - val_loss: 0.0704 - val_acc: 0.9890\n",
            "Epoch 218/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0881 - acc: 0.9820 - val_loss: 0.0844 - val_acc: 0.9860\n",
            "Epoch 219/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0786 - acc: 0.9890 - val_loss: 0.0846 - val_acc: 0.9850\n",
            "Epoch 220/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0797 - acc: 0.9840 - val_loss: 0.0686 - val_acc: 0.9880\n",
            "Epoch 221/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0799 - acc: 0.9850 - val_loss: 0.0715 - val_acc: 0.9860\n",
            "Epoch 222/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0791 - acc: 0.9850 - val_loss: 0.0782 - val_acc: 0.9860\n",
            "Epoch 223/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0755 - acc: 0.9880 - val_loss: 0.0864 - val_acc: 0.9830\n",
            "Epoch 224/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0944 - acc: 0.9780 - val_loss: 0.0629 - val_acc: 0.9910\n",
            "Epoch 225/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0686 - acc: 0.9870 - val_loss: 0.0671 - val_acc: 0.9850\n",
            "Epoch 226/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0764 - acc: 0.9860 - val_loss: 0.0777 - val_acc: 0.9820\n",
            "Epoch 227/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0764 - acc: 0.9810 - val_loss: 0.0674 - val_acc: 0.9910\n",
            "Epoch 228/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0716 - acc: 0.9860 - val_loss: 0.0630 - val_acc: 0.9900\n",
            "Epoch 229/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0691 - acc: 0.9890 - val_loss: 0.0564 - val_acc: 0.9910\n",
            "Epoch 230/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0767 - acc: 0.9800 - val_loss: 0.0681 - val_acc: 0.9860\n",
            "Epoch 231/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0680 - acc: 0.9840 - val_loss: 0.0772 - val_acc: 0.9840\n",
            "Epoch 232/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0620 - acc: 0.9870 - val_loss: 0.0525 - val_acc: 0.9900\n",
            "Epoch 233/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0622 - acc: 0.9850 - val_loss: 0.0963 - val_acc: 0.9810\n",
            "Epoch 234/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0678 - acc: 0.9860 - val_loss: 0.0555 - val_acc: 0.9890\n",
            "Epoch 235/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0565 - acc: 0.9880 - val_loss: 0.0607 - val_acc: 0.9890\n",
            "Epoch 236/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0598 - acc: 0.9900 - val_loss: 0.0577 - val_acc: 0.9920\n",
            "Epoch 237/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0628 - acc: 0.9870 - val_loss: 0.0536 - val_acc: 0.9900\n",
            "Epoch 238/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0595 - acc: 0.9880 - val_loss: 0.0494 - val_acc: 0.9920\n",
            "Epoch 239/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0574 - acc: 0.9890 - val_loss: 0.0549 - val_acc: 0.9900\n",
            "Epoch 240/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0541 - acc: 0.9880 - val_loss: 0.0949 - val_acc: 0.9780\n",
            "Epoch 241/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0556 - acc: 0.9900 - val_loss: 0.0464 - val_acc: 0.9930\n",
            "Epoch 242/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0539 - acc: 0.9890 - val_loss: 0.0537 - val_acc: 0.9880\n",
            "Epoch 243/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0549 - acc: 0.9880 - val_loss: 0.0738 - val_acc: 0.9820\n",
            "Epoch 244/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0524 - acc: 0.9900 - val_loss: 0.0637 - val_acc: 0.9900\n",
            "Epoch 245/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0558 - acc: 0.9870 - val_loss: 0.0456 - val_acc: 0.9920\n",
            "Epoch 246/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0509 - acc: 0.9890 - val_loss: 0.0460 - val_acc: 0.9920\n",
            "Epoch 247/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0497 - acc: 0.9880 - val_loss: 0.0666 - val_acc: 0.9830\n",
            "Epoch 248/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0506 - acc: 0.9900 - val_loss: 0.0480 - val_acc: 0.9920\n",
            "Epoch 249/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0443 - acc: 0.9940 - val_loss: 0.0418 - val_acc: 0.9920\n",
            "Epoch 250/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0574 - acc: 0.9890 - val_loss: 0.0646 - val_acc: 0.9850\n",
            "Epoch 251/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0560 - acc: 0.9860 - val_loss: 0.0397 - val_acc: 0.9930\n",
            "Epoch 252/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0414 - acc: 0.9890 - val_loss: 0.0366 - val_acc: 0.9930\n",
            "Epoch 253/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0503 - acc: 0.9900 - val_loss: 0.0378 - val_acc: 0.9940\n",
            "Epoch 254/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0462 - acc: 0.9890 - val_loss: 0.0415 - val_acc: 0.9920\n",
            "Epoch 255/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0399 - acc: 0.9920 - val_loss: 0.0417 - val_acc: 0.9920\n",
            "Epoch 256/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0450 - acc: 0.9900 - val_loss: 0.0334 - val_acc: 0.9930\n",
            "Epoch 257/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0426 - acc: 0.9910 - val_loss: 0.0341 - val_acc: 0.9940\n",
            "Epoch 258/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0465 - acc: 0.9880 - val_loss: 0.0352 - val_acc: 0.9940\n",
            "Epoch 259/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0474 - acc: 0.9910 - val_loss: 0.0577 - val_acc: 0.9840\n",
            "Epoch 260/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0434 - acc: 0.9890 - val_loss: 0.0361 - val_acc: 0.9910\n",
            "Epoch 261/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0391 - acc: 0.9900 - val_loss: 0.0390 - val_acc: 0.9950\n",
            "Epoch 262/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0387 - acc: 0.9930 - val_loss: 0.0390 - val_acc: 0.9910\n",
            "Epoch 263/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0374 - acc: 0.9910 - val_loss: 0.0406 - val_acc: 0.9920\n",
            "Epoch 264/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0500 - acc: 0.9860 - val_loss: 0.0302 - val_acc: 0.9940\n",
            "Epoch 265/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0352 - acc: 0.9930 - val_loss: 0.0441 - val_acc: 0.9870\n",
            "Epoch 266/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0385 - acc: 0.9920 - val_loss: 0.0317 - val_acc: 0.9930\n",
            "Epoch 267/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0391 - acc: 0.9920 - val_loss: 0.0290 - val_acc: 0.9960\n",
            "Epoch 268/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0356 - acc: 0.9900 - val_loss: 0.0465 - val_acc: 0.9890\n",
            "Epoch 269/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0423 - acc: 0.9910 - val_loss: 0.0303 - val_acc: 0.9960\n",
            "Epoch 270/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0374 - acc: 0.9910 - val_loss: 0.0307 - val_acc: 0.9940\n",
            "Epoch 271/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0316 - acc: 0.9910 - val_loss: 0.0993 - val_acc: 0.9670\n",
            "Epoch 272/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0450 - acc: 0.9920 - val_loss: 0.0371 - val_acc: 0.9920\n",
            "Epoch 273/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0425 - acc: 0.9900 - val_loss: 0.0283 - val_acc: 0.9940\n",
            "Epoch 274/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0311 - acc: 0.9920 - val_loss: 0.0259 - val_acc: 0.9950\n",
            "Epoch 275/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0384 - acc: 0.9890 - val_loss: 0.0378 - val_acc: 0.9930\n",
            "Epoch 276/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0319 - acc: 0.9910 - val_loss: 0.0257 - val_acc: 0.9960\n",
            "Epoch 277/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0365 - acc: 0.9920 - val_loss: 0.0517 - val_acc: 0.9870\n",
            "Epoch 278/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0390 - acc: 0.9880 - val_loss: 0.0255 - val_acc: 0.9980\n",
            "Epoch 279/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0278 - acc: 0.9940 - val_loss: 0.0388 - val_acc: 0.9920\n",
            "Epoch 280/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0406 - acc: 0.9890 - val_loss: 0.0278 - val_acc: 0.9950\n",
            "Epoch 281/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0275 - acc: 0.9950 - val_loss: 0.0263 - val_acc: 0.9960\n",
            "Epoch 282/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0324 - acc: 0.9920 - val_loss: 0.0443 - val_acc: 0.9870\n",
            "Epoch 283/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0304 - acc: 0.9920 - val_loss: 0.0334 - val_acc: 0.9940\n",
            "Epoch 284/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0310 - acc: 0.9950 - val_loss: 0.0224 - val_acc: 0.9960\n",
            "Epoch 285/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0306 - acc: 0.9940 - val_loss: 0.0273 - val_acc: 0.9950\n",
            "Epoch 286/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0297 - acc: 0.9940 - val_loss: 0.0321 - val_acc: 0.9930\n",
            "Epoch 287/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0313 - acc: 0.9920 - val_loss: 0.0295 - val_acc: 0.9960\n",
            "Epoch 288/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0307 - acc: 0.9930 - val_loss: 0.0227 - val_acc: 0.9950\n",
            "Epoch 289/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0254 - acc: 0.9940 - val_loss: 0.0241 - val_acc: 0.9960\n",
            "Epoch 290/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0311 - acc: 0.9920 - val_loss: 0.0208 - val_acc: 0.9970\n",
            "Epoch 291/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0296 - acc: 0.9900 - val_loss: 0.0228 - val_acc: 0.9950\n",
            "Epoch 292/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0256 - acc: 0.9950 - val_loss: 0.0246 - val_acc: 0.9950\n",
            "Epoch 293/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0357 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9910\n",
            "Epoch 294/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0316 - acc: 0.9890 - val_loss: 0.0228 - val_acc: 0.9940\n",
            "Epoch 295/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 0.0199 - val_acc: 0.9960\n",
            "Epoch 296/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0273 - acc: 0.9910 - val_loss: 0.1381 - val_acc: 0.9610\n",
            "Epoch 297/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0401 - acc: 0.9900 - val_loss: 0.0219 - val_acc: 0.9960\n",
            "Epoch 298/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0229 - acc: 0.9940 - val_loss: 0.0313 - val_acc: 0.9930\n",
            "Epoch 299/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0241 - acc: 0.9940 - val_loss: 0.0262 - val_acc: 0.9950\n",
            "Epoch 300/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0327 - acc: 0.9930 - val_loss: 0.0219 - val_acc: 0.9960\n",
            "Epoch 301/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0236 - acc: 0.9950 - val_loss: 0.0237 - val_acc: 0.9940\n",
            "Epoch 302/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 0.0252 - val_acc: 0.9940\n",
            "Epoch 303/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0299 - acc: 0.9920 - val_loss: 0.0193 - val_acc: 0.9980\n",
            "Epoch 304/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0234 - acc: 0.9940 - val_loss: 0.0451 - val_acc: 0.9900\n",
            "Epoch 305/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0239 - acc: 0.9960 - val_loss: 0.0175 - val_acc: 0.9960\n",
            "Epoch 306/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0241 - acc: 0.9930 - val_loss: 0.0299 - val_acc: 0.9940\n",
            "Epoch 307/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0294 - acc: 0.9940 - val_loss: 0.0244 - val_acc: 0.9950\n",
            "Epoch 308/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0205 - acc: 0.9940 - val_loss: 0.0206 - val_acc: 0.9960\n",
            "Epoch 309/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - acc: 0.9930 - val_loss: 0.0202 - val_acc: 0.9970\n",
            "Epoch 310/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0219 - acc: 0.9950 - val_loss: 0.0221 - val_acc: 0.9980\n",
            "Epoch 311/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0306 - acc: 0.9930 - val_loss: 0.0209 - val_acc: 0.9940\n",
            "Epoch 312/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0374 - acc: 0.9860 - val_loss: 0.0215 - val_acc: 0.9970\n",
            "Epoch 313/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0206 - acc: 0.9970 - val_loss: 0.0170 - val_acc: 0.9970\n",
            "Epoch 314/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0201 - acc: 0.9950 - val_loss: 0.0182 - val_acc: 0.9970\n",
            "Epoch 315/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0260 - acc: 0.9950 - val_loss: 0.0324 - val_acc: 0.9930\n",
            "Epoch 316/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0210 - acc: 0.9950 - val_loss: 0.0164 - val_acc: 0.9970\n",
            "Epoch 317/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0209 - acc: 0.9940 - val_loss: 0.0193 - val_acc: 0.9940\n",
            "Epoch 318/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0420 - acc: 0.9910 - val_loss: 0.0173 - val_acc: 0.9970\n",
            "Epoch 319/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0192 - acc: 0.9970 - val_loss: 0.0212 - val_acc: 0.9960\n",
            "Epoch 320/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0249 - acc: 0.9950 - val_loss: 0.0198 - val_acc: 0.9950\n",
            "Epoch 321/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0187 - acc: 0.9970 - val_loss: 0.0161 - val_acc: 0.9960\n",
            "Epoch 322/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0320 - acc: 0.9880 - val_loss: 0.0511 - val_acc: 0.9920\n",
            "Epoch 323/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0298 - acc: 0.9950 - val_loss: 0.0147 - val_acc: 0.9970\n",
            "Epoch 324/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0230 - acc: 0.9940 - val_loss: 0.0451 - val_acc: 0.9900\n",
            "Epoch 325/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0259 - acc: 0.9960 - val_loss: 0.0165 - val_acc: 0.9970\n",
            "Epoch 326/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0261 - val_acc: 0.9940\n",
            "Epoch 327/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0207 - acc: 0.9950 - val_loss: 0.0373 - val_acc: 0.9900\n",
            "Epoch 328/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.0259 - val_acc: 0.9950\n",
            "Epoch 329/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0176 - acc: 0.9950 - val_loss: 0.0224 - val_acc: 0.9950\n",
            "Epoch 330/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0289 - acc: 0.9890 - val_loss: 0.0297 - val_acc: 0.9950\n",
            "Epoch 331/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0245 - acc: 0.9950 - val_loss: 0.0197 - val_acc: 0.9960\n",
            "Epoch 332/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0185 - acc: 0.9970 - val_loss: 0.0198 - val_acc: 0.9950\n",
            "Epoch 333/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0334 - acc: 0.9910 - val_loss: 0.0146 - val_acc: 0.9970\n",
            "Epoch 334/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.0142 - val_acc: 0.9970\n",
            "Epoch 335/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0197 - acc: 0.9950 - val_loss: 0.0237 - val_acc: 0.9930\n",
            "Epoch 336/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0195 - acc: 0.9950 - val_loss: 0.0255 - val_acc: 0.9930\n",
            "Epoch 337/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - acc: 0.9930 - val_loss: 0.0141 - val_acc: 0.9980\n",
            "Epoch 338/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0181 - val_acc: 0.9980\n",
            "Epoch 339/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0263 - acc: 0.9920 - val_loss: 0.0259 - val_acc: 0.9920\n",
            "Epoch 340/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0257 - acc: 0.9930 - val_loss: 0.0277 - val_acc: 0.9930\n",
            "Epoch 341/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0157 - acc: 0.9970 - val_loss: 0.0127 - val_acc: 0.9970\n",
            "Epoch 342/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0177 - acc: 0.9940 - val_loss: 0.0283 - val_acc: 0.9950\n",
            "Epoch 343/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0191 - acc: 0.9970 - val_loss: 0.0139 - val_acc: 0.9980\n",
            "Epoch 344/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0248 - acc: 0.9930 - val_loss: 0.0287 - val_acc: 0.9910\n",
            "Epoch 345/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0319 - acc: 0.9890 - val_loss: 0.0159 - val_acc: 0.9970\n",
            "Epoch 346/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0171 - acc: 0.9960 - val_loss: 0.0127 - val_acc: 0.9980\n",
            "Epoch 347/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0131 - val_acc: 0.9970\n",
            "Epoch 348/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0240 - acc: 0.9920 - val_loss: 0.0419 - val_acc: 0.9880\n",
            "Epoch 349/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.0208 - val_acc: 0.9950\n",
            "Epoch 350/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0176 - acc: 0.9960 - val_loss: 0.0137 - val_acc: 0.9980\n",
            "Epoch 351/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0218 - acc: 0.9950 - val_loss: 0.0121 - val_acc: 0.9970\n",
            "Epoch 352/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0190 - val_acc: 0.9980\n",
            "Epoch 353/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0171 - acc: 0.9960 - val_loss: 0.0146 - val_acc: 0.9970\n",
            "Epoch 354/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0192 - acc: 0.9950 - val_loss: 0.0122 - val_acc: 0.9980\n",
            "Epoch 355/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0150 - acc: 0.9980 - val_loss: 0.0122 - val_acc: 0.9970\n",
            "Epoch 356/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0226 - acc: 0.9910 - val_loss: 0.0131 - val_acc: 0.9980\n",
            "Epoch 357/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0132 - acc: 0.9980 - val_loss: 0.0130 - val_acc: 0.9970\n",
            "Epoch 358/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.0139 - val_acc: 0.9970\n",
            "Epoch 359/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0158 - acc: 0.9970 - val_loss: 0.0253 - val_acc: 0.9950\n",
            "Epoch 360/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0161 - acc: 0.9970 - val_loss: 0.0131 - val_acc: 0.9960\n",
            "Epoch 361/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.0160 - val_acc: 0.9970\n",
            "Epoch 362/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0201 - acc: 0.9960 - val_loss: 0.0111 - val_acc: 0.9970\n",
            "Epoch 363/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0313 - val_acc: 0.9920\n",
            "Epoch 364/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0207 - acc: 0.9940 - val_loss: 0.0138 - val_acc: 0.9980\n",
            "Epoch 365/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0139 - acc: 0.9960 - val_loss: 0.0108 - val_acc: 0.9980\n",
            "Epoch 366/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.0150 - val_acc: 0.9960\n",
            "Epoch 367/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0194 - acc: 0.9930 - val_loss: 0.0126 - val_acc: 0.9960\n",
            "Epoch 368/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0137 - acc: 0.9950 - val_loss: 0.0108 - val_acc: 0.9970\n",
            "Epoch 369/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.0182 - val_acc: 0.9960\n",
            "Epoch 370/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0143 - acc: 0.9960 - val_loss: 0.0129 - val_acc: 0.9980\n",
            "Epoch 371/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0211 - acc: 0.9950 - val_loss: 0.0105 - val_acc: 0.9970\n",
            "Epoch 372/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0144 - acc: 0.9950 - val_loss: 0.0291 - val_acc: 0.9920\n",
            "Epoch 373/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0263 - acc: 0.9920 - val_loss: 0.0172 - val_acc: 0.9950\n",
            "Epoch 374/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0203 - acc: 0.9930 - val_loss: 0.0131 - val_acc: 0.9970\n",
            "Epoch 375/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0143 - acc: 0.9970 - val_loss: 0.0153 - val_acc: 0.9950\n",
            "Epoch 376/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0131 - acc: 0.9970 - val_loss: 0.0145 - val_acc: 0.9970\n",
            "Epoch 377/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0375 - acc: 0.9930 - val_loss: 0.0113 - val_acc: 0.9970\n",
            "Epoch 378/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0121 - acc: 0.9970 - val_loss: 0.0103 - val_acc: 0.9970\n",
            "Epoch 379/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0128 - acc: 0.9950 - val_loss: 0.0121 - val_acc: 0.9960\n",
            "Epoch 380/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0115 - val_acc: 0.9970\n",
            "Epoch 381/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0122 - acc: 0.9970 - val_loss: 0.0098 - val_acc: 0.9970\n",
            "Epoch 382/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.0113 - val_acc: 0.9980\n",
            "Epoch 383/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.0097 - val_acc: 0.9980\n",
            "Epoch 384/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0107 - val_acc: 0.9970\n",
            "Epoch 385/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0179 - acc: 0.9960 - val_loss: 0.0109 - val_acc: 0.9980\n",
            "Epoch 386/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0121 - acc: 0.9980 - val_loss: 0.0097 - val_acc: 0.9970\n",
            "Epoch 387/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0231 - acc: 0.9910 - val_loss: 0.0426 - val_acc: 0.9910\n",
            "Epoch 388/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0200 - acc: 0.9960 - val_loss: 0.0116 - val_acc: 0.9970\n",
            "Epoch 389/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0093 - val_acc: 0.9980\n",
            "Epoch 390/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0211 - acc: 0.9950 - val_loss: 0.0163 - val_acc: 0.9960\n",
            "Epoch 391/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.0110 - val_acc: 0.9970\n",
            "Epoch 392/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0145 - acc: 0.9950 - val_loss: 0.0106 - val_acc: 0.9970\n",
            "Epoch 393/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.0096 - val_acc: 0.9970\n",
            "Epoch 394/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0125 - acc: 0.9950 - val_loss: 0.0102 - val_acc: 0.9970\n",
            "Epoch 395/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0246 - val_acc: 0.9920\n",
            "Epoch 396/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0307 - acc: 0.9910 - val_loss: 0.0102 - val_acc: 0.9980\n",
            "Epoch 397/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0144 - val_acc: 0.9960\n",
            "Epoch 398/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0162 - acc: 0.9950 - val_loss: 0.0140 - val_acc: 0.9970\n",
            "Epoch 399/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0095 - val_acc: 0.9980\n",
            "Epoch 400/400\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0124 - acc: 0.9970 - val_loss: 0.0257 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "puBXpJA71O45",
        "colab_type": "code",
        "outputId": "13797e58-4666-4772-87ca-3d3b41687159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f36f39eac18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEA+X+gzVWdoAAYXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f36f2c71320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yASbEzj3-2iq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1.3 Multi-output models\n",
        "You can also use the functional API to build models with multiple outputs (or multiple heads). \n",
        "\n",
        "####  Example - prediction of Age, Gender and Income from social media posts\n",
        "A simple example is a network that attempts to simultaneously predict different properties of the data, such as a network that takes as input a series of social media posts from a single anonymous person and tries to predict attributes of that person, such as age, gender, and income level (see figure 7.7, below).\n",
        "\n",
        "#### Functional API implementation of a three-ouputs prediction model"
      ]
    },
    {
      "metadata": {
        "id": "LTT9qaX2-2is",
        "colab_type": "code",
        "outputId": "ebdb95c5-f09b-4686-daeb-048205d6f4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input \n",
        "from keras.models import Model \n",
        "\n",
        "vocabulary_size = 50000 \n",
        "num_income_groups = 10 \n",
        "\n",
        "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
        "# embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input) \n",
        "embedded_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n",
        "x = layers.Conv1D(128, 5, activation='relu', padding='same')(embedded_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x) \n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x) \n",
        "\n",
        "# Note that the output layers are given names.\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "income_prediction = layers.Dense(num_income_groups, activation='softmax',name='income')(x)\n",
        "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
        "model = Model(posts_input,[age_prediction, income_prediction, gender_prediction])\n",
        "\n",
        "print(\"Model is ready!\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5fjCj6d-2i0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Why put padding='same'\n",
        "\n",
        "https://stackoverflow.com/questions/50281564/why-i-cant-set-kernel-size-in-1d-convolution\n",
        "\n",
        "When I run it show error like this. InvalidArgumentError: computed output size would be negative\n",
        "\n",
        "If you use padding \"same\" this would just yield an output of one number (the input number multiplied by the middle number of your kernel), but with the default \"valid\" padding, this would make the output size negative."
      ]
    },
    {
      "metadata": {
        "id": "YmWVFMzr-2i3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importantly, training such a model requires the ability to specify different loss functions for different heads of the network: for instance, age prediction is a scalar regression task, but gender prediction is a binary classification task, requiring a different training procedure. But because gradient descent requires you to minimize a scalar, you must combine these losses into a single value in order to train the model. The simplest way to combine different losses is to sum them all. In Keras, you can use either a list or a dictionary of losses in compile to specify different objects for different outputs; the resulting loss values are summed into a global loss, which is minimized during training.\n",
        "\n",
        "#### Compilation options of a multi-output model: multiple losses"
      ]
    },
    {
      "metadata": {
        "id": "V5ByWDIE-2i4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
        "\n",
        "# Equivalent (possible only if you give names to the output layers)\n",
        "model.compile(optimizer='rmsprop',loss={'age': 'mse',\n",
        "                                        'income': 'categorical_crossentropy',\n",
        "                                        'gender': 'binary_crossentropy'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fY838XJU-2i-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem with imbalanced loss contributions\n",
        "\n",
        "Note that very imbalanced loss contributions will cause the model representations to be optimized preferentially for the task with the largest individual loss, at the expense of the other tasks. To remedy this, you can assign different levels of importance to the loss values in their contribution to the final loss. This is useful in particular if the losses’ values use different scales. \n",
        "\n",
        "For instance, the mean squared error (MSE) loss used for the age-regression task typically takes a value around 3–5, whereas the cross-entropy loss used for the gender-classification task can be as low as 0.1. In such a situation, to balance the contribution of the different losses, you can assign a weight of 10 to the crossentropy loss and a weight of 0.25 to the MSE loss.\n",
        "\n",
        "#### Solution to imbalanced loss contributions"
      ]
    },
    {
      "metadata": {
        "id": "XeQ567BP-2jD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
        "              loss_weights=[0.25, 1., 10.]) \n",
        "\n",
        "# Equivalent (possible only if you give names to the output layers)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss={'age': 'mse','income': 'categorical_crossentropy','gender': 'binary_crossentropy'},\n",
        "              loss_weights={'age': 0.25,\n",
        "                            'income': 1.,\n",
        "                            'gender': 10.})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jxadwlu1-2jL",
        "colab_type": "code",
        "outputId": "b0f5f425-0bd7-4af7-949b-e02de7041d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2047
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, None, 128)    163968      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, None, 128)    0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, None, 256)    164096      max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, None, 256)    327936      conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, None, 256)    0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, None, 256)    327936      max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, None, 256)    327936      conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 256)          0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 128)          32896       global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,146,316\n",
            "Trainable params: 14,146,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"968pt\" viewBox=\"0.00 0.00 757.50 968.00\" width=\"758pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 964)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-964 753.5,-964 753.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140402024252808 -->\n<g class=\"node\" id=\"node1\">\n<title>140402024252808</title>\n<polygon fill=\"none\" points=\"229.5,-913.5 229.5,-959.5 500.5,-959.5 500.5,-913.5 229.5,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-932.8\">posts: InputLayer</text>\n<polyline fill=\"none\" points=\"346.5,-913.5 346.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"346.5,-936.5 404.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"404.5,-913.5 404.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"452.5\" y=\"-944.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"404.5,-936.5 500.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"452.5\" y=\"-921.3\">(None, None)</text>\n</g>\n<!-- 140402024252752 -->\n<g class=\"node\" id=\"node2\">\n<title>140402024252752</title>\n<polygon fill=\"none\" points=\"187.5,-830.5 187.5,-876.5 542.5,-876.5 542.5,-830.5 187.5,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-849.8\">embedding_2: Embedding</text>\n<polyline fill=\"none\" points=\"358.5,-830.5 358.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387.5\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"358.5,-853.5 416.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387.5\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"416.5,-830.5 416.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"479.5\" y=\"-861.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"416.5,-853.5 542.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"479.5\" y=\"-838.3\">(None, None, 256)</text>\n</g>\n<!-- 140402024252808&#45;&gt;140402024252752 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140402024252808-&gt;140402024252752</title>\n<path d=\"M365,-913.3799C365,-905.1745 365,-895.7679 365,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-886.784 365,-876.784 361.5001,-886.784 368.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402026208952 -->\n<g class=\"node\" id=\"node3\">\n<title>140402026208952</title>\n<polygon fill=\"none\" points=\"206.5,-747.5 206.5,-793.5 523.5,-793.5 523.5,-747.5 206.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-766.8\">conv1d_6: Conv1D</text>\n<polyline fill=\"none\" points=\"339.5,-747.5 339.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"339.5,-770.5 397.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"397.5,-747.5 397.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-778.3\">(None, None, 256)</text>\n<polyline fill=\"none\" points=\"397.5,-770.5 523.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-755.3\">(None, None, 128)</text>\n</g>\n<!-- 140402024252752&#45;&gt;140402026208952 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140402024252752-&gt;140402026208952</title>\n<path d=\"M365,-830.3799C365,-822.1745 365,-812.7679 365,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-803.784 365,-793.784 361.5001,-803.784 368.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402024251744 -->\n<g class=\"node\" id=\"node4\">\n<title>140402024251744</title>\n<polygon fill=\"none\" points=\"162.5,-664.5 162.5,-710.5 567.5,-710.5 567.5,-664.5 162.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-683.8\">max_pooling1d_3: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"383.5,-664.5 383.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"383.5,-687.5 441.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"441.5,-664.5 441.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-695.3\">(None, None, 128)</text>\n<polyline fill=\"none\" points=\"441.5,-687.5 567.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-672.3\">(None, None, 128)</text>\n</g>\n<!-- 140402026208952&#45;&gt;140402024251744 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140402026208952-&gt;140402024251744</title>\n<path d=\"M365,-747.3799C365,-739.1745 365,-729.7679 365,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-720.784 365,-710.784 361.5001,-720.784 368.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402024251520 -->\n<g class=\"node\" id=\"node5\">\n<title>140402024251520</title>\n<polygon fill=\"none\" points=\"206.5,-581.5 206.5,-627.5 523.5,-627.5 523.5,-581.5 206.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-600.8\">conv1d_7: Conv1D</text>\n<polyline fill=\"none\" points=\"339.5,-581.5 339.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"339.5,-604.5 397.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"397.5,-581.5 397.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-612.3\">(None, None, 128)</text>\n<polyline fill=\"none\" points=\"397.5,-604.5 523.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-589.3\">(None, None, 256)</text>\n</g>\n<!-- 140402024251744&#45;&gt;140402024251520 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140402024251744-&gt;140402024251520</title>\n<path d=\"M365,-664.3799C365,-656.1745 365,-646.7679 365,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-637.784 365,-627.784 361.5001,-637.784 368.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402024251856 -->\n<g class=\"node\" id=\"node6\">\n<title>140402024251856</title>\n<polygon fill=\"none\" points=\"206.5,-498.5 206.5,-544.5 523.5,-544.5 523.5,-498.5 206.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-517.8\">conv1d_8: Conv1D</text>\n<polyline fill=\"none\" points=\"339.5,-498.5 339.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"339.5,-521.5 397.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"397.5,-498.5 397.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-529.3\">(None, None, 256)</text>\n<polyline fill=\"none\" points=\"397.5,-521.5 523.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-506.3\">(None, None, 256)</text>\n</g>\n<!-- 140402024251520&#45;&gt;140402024251856 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140402024251520-&gt;140402024251856</title>\n<path d=\"M365,-581.3799C365,-573.1745 365,-563.7679 365,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-554.784 365,-544.784 361.5001,-554.784 368.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402024244000 -->\n<g class=\"node\" id=\"node7\">\n<title>140402024244000</title>\n<polygon fill=\"none\" points=\"162.5,-415.5 162.5,-461.5 567.5,-461.5 567.5,-415.5 162.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-434.8\">max_pooling1d_4: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"383.5,-415.5 383.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"383.5,-438.5 441.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"441.5,-415.5 441.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-446.3\">(None, None, 256)</text>\n<polyline fill=\"none\" points=\"441.5,-438.5 567.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-423.3\">(None, None, 256)</text>\n</g>\n<!-- 140402024251856&#45;&gt;140402024244000 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140402024251856-&gt;140402024244000</title>\n<path d=\"M365,-498.3799C365,-490.1745 365,-480.7679 365,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-471.784 365,-461.784 361.5001,-471.784 368.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402023796808 -->\n<g class=\"node\" id=\"node8\">\n<title>140402023796808</title>\n<polygon fill=\"none\" points=\"206.5,-332.5 206.5,-378.5 523.5,-378.5 523.5,-332.5 206.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-351.8\">conv1d_9: Conv1D</text>\n<polyline fill=\"none\" points=\"339.5,-332.5 339.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"339.5,-355.5 397.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"397.5,-332.5 397.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-363.3\">(None, None, 256)</text>\n<polyline fill=\"none\" points=\"397.5,-355.5 523.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-340.3\">(None, None, 256)</text>\n</g>\n<!-- 140402024244000&#45;&gt;140402023796808 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140402024244000-&gt;140402023796808</title>\n<path d=\"M365,-415.3799C365,-407.1745 365,-397.7679 365,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-388.784 365,-378.784 361.5001,-388.784 368.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402023799664 -->\n<g class=\"node\" id=\"node9\">\n<title>140402023799664</title>\n<polygon fill=\"none\" points=\"203,-249.5 203,-295.5 527,-295.5 527,-249.5 203,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-268.8\">conv1d_10: Conv1D</text>\n<polyline fill=\"none\" points=\"343,-249.5 343,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"343,-272.5 401,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"401,-249.5 401,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-280.3\">(None, None, 256)</text>\n<polyline fill=\"none\" points=\"401,-272.5 527,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-257.3\">(None, None, 256)</text>\n</g>\n<!-- 140402023796808&#45;&gt;140402023799664 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140402023796808-&gt;140402023799664</title>\n<path d=\"M365,-332.3799C365,-324.1745 365,-314.7679 365,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-305.784 365,-295.784 361.5001,-305.784 368.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402023668816 -->\n<g class=\"node\" id=\"node10\">\n<title>140402023668816</title>\n<polygon fill=\"none\" points=\"121,-166.5 121,-212.5 609,-212.5 609,-166.5 121,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-185.8\">global_max_pooling1d_2: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"425,-166.5 425,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"425,-189.5 483,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"483,-166.5 483,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-197.3\">(None, None, 256)</text>\n<polyline fill=\"none\" points=\"483,-189.5 609,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-174.3\">(None, 256)</text>\n</g>\n<!-- 140402023799664&#45;&gt;140402023668816 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140402023799664-&gt;140402023668816</title>\n<path d=\"M365,-249.3799C365,-241.1745 365,-231.7679 365,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-222.784 365,-212.784 361.5001,-222.784 368.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402023488592 -->\n<g class=\"node\" id=\"node11\">\n<title>140402023488592</title>\n<polygon fill=\"none\" points=\"239,-83.5 239,-129.5 491,-129.5 491,-83.5 239,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-102.8\">dense_9: Dense</text>\n<polyline fill=\"none\" points=\"346,-83.5 346,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"346,-106.5 404,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"404,-83.5 404,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-114.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"404,-106.5 491,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-91.3\">(None, 128)</text>\n</g>\n<!-- 140402023668816&#45;&gt;140402023488592 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140402023668816-&gt;140402023488592</title>\n<path d=\"M365,-166.3799C365,-158.1745 365,-148.7679 365,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-139.784 365,-129.784 361.5001,-139.784 368.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402023193848 -->\n<g class=\"node\" id=\"node12\">\n<title>140402023193848</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 224,-46.5 224,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.5\" y=\"-19.8\">age: Dense</text>\n<polyline fill=\"none\" points=\"79,-.5 79,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"79,-23.5 137,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"137,-.5 137,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"137,-23.5 224,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140402023488592&#45;&gt;140402023193848 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140402023488592-&gt;140402023193848</title>\n<path d=\"M294.8614,-83.4901C262.9174,-73.0105 224.9463,-60.5535 191.9051,-49.7139\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.8679,-46.3463 182.2751,-46.5547 190.6858,-52.9975 192.8679,-46.3463\" stroke=\"#000000\"/>\n</g>\n<!-- 140402022912408 -->\n<g class=\"node\" id=\"node13\">\n<title>140402022912408</title>\n<polygon fill=\"none\" points=\"242,-.5 242,-46.5 488,-46.5 488,-.5 242,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-19.8\">income: Dense</text>\n<polyline fill=\"none\" points=\"343,-.5 343,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"343,-23.5 401,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"401,-.5 401,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"444.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"401,-23.5 488,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"444.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140402023488592&#45;&gt;140402022912408 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140402023488592-&gt;140402022912408</title>\n<path d=\"M365,-83.3799C365,-75.1745 365,-65.7679 365,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"368.5001,-56.784 365,-46.784 361.5001,-56.784 368.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140402022914592 -->\n<g class=\"node\" id=\"node14\">\n<title>140402022914592</title>\n<polygon fill=\"none\" points=\"506.5,-.5 506.5,-46.5 749.5,-46.5 749.5,-.5 506.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555.5\" y=\"-19.8\">gender: Dense</text>\n<polyline fill=\"none\" points=\"604.5,-.5 604.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"633.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"604.5,-23.5 662.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"633.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"662.5,-.5 662.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"706\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"662.5,-23.5 749.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"706\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140402023488592&#45;&gt;140402022914592 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140402023488592-&gt;140402022914592</title>\n<path d=\"M437.9109,-83.4901C471.26,-72.9655 510.9284,-60.4466 545.3785,-49.5745\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"546.4643,-52.902 554.9473,-46.5547 544.3575,-46.2266 546.4643,-52.902\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "utmh5Xufueju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from google.colab import files\n",
        "files.download('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fapYi3at-2jb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Feeding data to a multi-output model\n",
        "\n",
        "Much as in the case of multi-input models, you can pass Numpy data to the model for training either via a list of arrays or via a dictionary of arrays."
      ]
    },
    {
      "metadata": {
        "id": "W70cdSuL-2je",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training a multi-output model"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "pm6uer1q-2ji",
        "colab_type": "code",
        "outputId": "8aaf076a-3045-4887-f66d-3f2c55e565d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "TRACE = False\n",
        "\n",
        "num_samples = 1000 \n",
        "max_length = 100 \n",
        "#產生模擬資料，用於訓練模型\n",
        "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
        "if TRACE:\n",
        "    print(\"*** POSTS ***\")\n",
        "    print(posts.shape)\n",
        "    print(posts[:10])\n",
        "    print()\n",
        "\n",
        "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
        "if TRACE:\n",
        "    print(\"*** AGE ***\")\n",
        "    print(age_targets.shape)\n",
        "    print(age_targets[:10])\n",
        "    print()\n",
        "\n",
        "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
        "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
        "if TRACE:\n",
        "    print(\"*** INCOME ***\")\n",
        "    print(income_targets.shape)\n",
        "    print(income_targets[:10])\n",
        "    print()\n",
        "\n",
        "gender_targets = np.random.randint(0, 2, size=(num_samples,1))\n",
        "if TRACE:\n",
        "    print(\"*** GENDER ***\")\n",
        "    print(gender_targets.shape)\n",
        "    print(gender_targets[:10])\n",
        "    print()\n",
        "\n",
        "print('-'*10, \"First training run with NumPy arrays\", '-'*60)\n",
        "# age_targets, income_targets, and gender_targets are assumed to be Numpy arrays.\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
        "\n",
        "print('-'*10,\"Second training run with dictionary and named outputs\",'-'*60)\n",
        "# Equivalent (possible only if you give names to the output layers)\n",
        "model.fit(posts, {'age': age_targets,\n",
        "                  'income': income_targets,\n",
        "                  'gender': gender_targets},\n",
        "          epochs=10, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- First training run with NumPy arrays ------------------------------------------------------------\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 3411.8500 - age_loss: 13577.6849 - income_loss: 5.7806 - gender_loss: 1.1648\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 149.7953 - age_loss: 554.7659 - income_loss: 3.8756 - gender_loss: 0.7228\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 79.1326 - age_loss: 272.7328 - income_loss: 2.6991 - gender_loss: 0.8250\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 293.9686 - age_loss: 1090.0484 - income_loss: 4.2947 - gender_loss: 1.7162\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 183.9122 - age_loss: 612.1404 - income_loss: 5.3536 - gender_loss: 2.5523\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 194470.8482 - age_loss: 777556.2353 - income_loss: 13.6860 - gender_loss: 6.8101\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 24793.2322 - age_loss: 98804.4178 - income_loss: 14.3290 - gender_loss: 7.7799\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 6296.9211 - age_loss: 24819.1727 - income_loss: 14.3290 - gender_loss: 7.7799\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 617754.6789 - age_loss: 2470649.3766 - income_loss: 14.4958 - gender_loss: 7.7855\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 12892.2840 - age_loss: 51197.3726 - income_loss: 14.3773 - gender_loss: 7.8564\n",
            "---------- Second training run with dictionary and named outputs ------------------------------------------------------------\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 19657.6511 - age_loss: 78256.2701 - income_loss: 14.3773 - gender_loss: 7.9206\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 1702783.9155 - age_loss: 6810748.0868 - income_loss: 14.3615 - gender_loss: 8.2537\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 631241.1053 - age_loss: 2524577.0897 - income_loss: 14.3282 - gender_loss: 8.2525\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 307.4917 - age_loss: 842.3590 - income_loss: 14.3773 - gender_loss: 8.2525\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 2020.8226 - age_loss: 7695.6823 - income_loss: 14.3773 - gender_loss: 8.2525\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 890961.1814 - age_loss: 3563461.8121 - income_loss: 14.2922 - gender_loss: 8.1450\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 5521347.0109 - age_loss: 22085003.4825 - income_loss: 14.2968 - gender_loss: 8.1867\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 216445.6156 - age_loss: 865417.3913 - income_loss: 14.3290 - gender_loss: 7.6946\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 10s 10ms/step - loss: 2941107.6830 - age_loss: 11764055.2545 - income_loss: 14.3290 - gender_loss: 7.9571\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 400.0139 - age_loss: 1231.5445 - income_loss: 14.3290 - gender_loss: 7.7799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1e59cff28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "6cYd-yN4-2jp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1.4 Directed acyclic graphs of layers \n",
        "\n",
        "With the functional API, not only can you build models with multiple inputs and multiple outputs, but you can also implement networks with a complex internal topology. Neural networks in Keras are allowed to be arbitrary directed acyclic graphs of layers. The qualifier acyclic is important: these graphs can’t have cycles. It’s impossible for a tensor <strong>x</strong> to become the input of one of the layers that generated <strong>x</strong>. The only processing loops that are allowed (that is, recurrent connections) are those internal to recurrent layers. \n",
        "\n",
        "Several common neural-network components are implemented as graphs. Two notable ones are <i>Inception modules</i> and <i>residual connections</i>. To better understand how the functional API can be used to build graphs of layers, let’s take a look at how you can implement both of them in Keras."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "vxcHjeSb-2jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Inception modules \n",
        "\n",
        "Inception [3] is a popular type of network architecture for convolutional neural networks. It consists of a stack of modules that themselves look like small independent networks, split into several parallel branches.\n",
        "\n",
        "##### The purpose of 1 × 1 convolutions \n",
        "\n",
        "1 × 1 convolutions (also called pointwise convolutions) are featured in Inception modules, where they contribute to factoring out channel-wise feature learning and space-wise feature learning.\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "JP24bbYo-2jy",
        "colab_type": "code",
        "outputId": "86ac56a5-a146-4e2b-c3e4-a8771704e4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import layers \n",
        "from keras.layers import Input\n",
        "\n",
        "# This example assumes the existence of a 4D input tensor x:\n",
        "# This returns a typical image tensor like those of MNIST dataset \n",
        "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "print(\"x.shape:\",x.shape)\n",
        "\n",
        "# Every branch has the same stride value (2), which is necessary to \n",
        "# keep all branch outputs the same size so you can concatenate them\n",
        "branch_a = layers.Conv2D(128, 1, padding='same', activation='relu', strides=2)(x)\n",
        "\n",
        "# In this branch, the striding occurs in the spatial convolution layer.\n",
        "branch_b = layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
        "branch_b = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_b)\n",
        "\n",
        "# In this branch, the striding occurs in the average pooling layer.\n",
        "branch_c = layers.AveragePooling2D(3,  padding='same', strides=2)(x)\n",
        "branch_c = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_c)\n",
        "\n",
        "branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(x) \n",
        "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
        "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
        "\n",
        "# Concatenates the branch outputs to obtain the module output\n",
        "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
        "\n",
        "# Adding a classifier on top of the convnet\n",
        "output = layers.Flatten()(output)\n",
        "output = layers.Dense(512, activation='relu')(output)\n",
        "predictions = layers.Dense(10, activation='softmax')(output)\n",
        "\n",
        "model = keras.models.Model(inputs=x, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LNV2MTa4-2j6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train the Inception model using the Dataset API and the MNIST data\n",
        "\n",
        "Inspired by: https://github.com/keras-team/keras/blob/master/examples/mnist_dataset_api.py"
      ]
    },
    {
      "metadata": {
        "id": "5eh1g8A_-2j8",
        "colab_type": "code",
        "outputId": "8d9e393c-3ea0-42c6-e21d-82e2fa59f2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "if K.backend() != 'tensorflow':\n",
        "    raise RuntimeError('This example can only run with the TensorFlow backend,'\n",
        "                       ' because it requires the Dataset API, which is not'\n",
        "                       ' supported on other platforms.')\n",
        "\n",
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "steps_per_epoch = int(np.ceil(60000 / float(batch_size)))  # = 469\n",
        "epochs = 5\n",
        "num_classes = 10\n",
        "\n",
        "def cnn_layers(x):\n",
        "    \n",
        "    # This example assumes the existence of a 4D input tensor x:\n",
        "    # This returns a typical image tensor like those of MNIST dataset \n",
        "    print(\"x.shape:\",x.shape)\n",
        "\n",
        "    # Every branch has the same stride value (2), which is necessary to \n",
        "    # keep all branch outputs the same size so you can concatenate them\n",
        "    branch_a = layers.Conv2D(128, 1, padding='same', activation='relu', strides=2)(x)\n",
        "\n",
        "    # In this branch, the striding occurs in the spatial convolution layer.\n",
        "    branch_b = layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
        "    branch_b = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_b)\n",
        "\n",
        "    # In this branch, the striding occurs in the average pooling layer.\n",
        "    branch_c = layers.AveragePooling2D(3,  padding='same', strides=2)(x)\n",
        "    branch_c = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_c)\n",
        "\n",
        "    branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(x) \n",
        "    branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
        "    branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
        "\n",
        "    # Concatenates the branch outputs to obtain the module output\n",
        "    output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
        "\n",
        "    # Adding a classifier on top of the convnet\n",
        "    output = layers.Flatten()(output)\n",
        "    output = layers.Dense(512, activation='relu')(output)\n",
        "    predictions = layers.Dense(num_classes, activation='softmax')(output)\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "  #使用MNIST資料集\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "y_train = tf.one_hot(y_train, num_classes)\n",
        "\n",
        "# Create the dataset and its associated one-shot iterator.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.repeat()\n",
        "dataset = dataset.shuffle(buffer_size)\n",
        "dataset = dataset.batch(batch_size)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "# Model creation using tensors from the get_next() graph node.\n",
        "inputs, targets = iterator.get_next()\n",
        "\n",
        "print(\"inputs.shape:\",inputs.shape)\n",
        "print(\"targets.shape:\",targets.shape)\n",
        "\n",
        "model_input = layers.Input(tensor=inputs)\n",
        "model_output = cnn_layers(model_input)\n",
        "\n",
        "model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        "              target_tensors=[targets])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "inputs.shape: (?, 28, 28, 1)\n",
            "targets.shape: (?, 10)\n",
            "x.shape: (?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_vmcbL4-2j_",
        "colab_type": "code",
        "outputId": "ffbaf25b-7dca-4752-c1fe-dac7998a540a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1626
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 128)  256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 14, 14, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 14, 14, 128)  256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 128)  147584      conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 128)  1280        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 14, 14, 128)  147584      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 512)  0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 100352)       0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          51380736    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 51,830,666\n",
            "Trainable params: 51,830,666\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"636pt\" viewBox=\"0.00 0.00 1193.00 636.00\" width=\"1193pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 632)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-632 1189,-632 1189,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140647098478264 -->\n<g class=\"node\" id=\"node1\">\n<title>140647098478264</title>\n<polygon fill=\"none\" points=\"501.5,-581.5 501.5,-627.5 809.5,-627.5 809.5,-581.5 501.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"568\" y=\"-600.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"634.5,-581.5 634.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"634.5,-604.5 692.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"692.5,-581.5 692.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"751\" y=\"-612.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"692.5,-604.5 809.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"751\" y=\"-589.3\">(None, 28, 28, 1)</text>\n</g>\n<!-- 140647080803856 -->\n<g class=\"node\" id=\"node2\">\n<title>140647080803856</title>\n<polygon fill=\"none\" points=\"86,-498.5 86,-544.5 409,-544.5 409,-498.5 86,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-517.8\">conv2d_5: Conv2D</text>\n<polyline fill=\"none\" points=\"219,-498.5 219,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"219,-521.5 277,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"277,-498.5 277,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343\" y=\"-529.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"277,-521.5 409,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343\" y=\"-506.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140647098478264&#45;&gt;140647080803856 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140647098478264-&gt;140647080803856</title>\n<path d=\"M542.3911,-581.4901C489.108,-570.6506 425.4262,-557.6958 370.8992,-546.6033\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"371.326,-543.1185 360.829,-544.5547 369.9305,-549.978 371.326,-543.1185\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081501528 -->\n<g class=\"node\" id=\"node3\">\n<title>140647081501528</title>\n<polygon fill=\"none\" points=\"341,-415.5 341,-461.5 664,-461.5 664,-415.5 341,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"407.5\" y=\"-434.8\">conv2d_2: Conv2D</text>\n<polyline fill=\"none\" points=\"474,-415.5 474,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"474,-438.5 532,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"532,-415.5 532,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598\" y=\"-446.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"532,-438.5 664,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598\" y=\"-423.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140647098478264&#45;&gt;140647081501528 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140647098478264-&gt;140647081501528</title>\n<path d=\"M591.4726,-581.387C573.3819,-572.3312 554.9757,-560.3523 541.5,-545 523.3646,-524.3392 513.4105,-494.5371 508.108,-471.71\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"511.4968,-470.8196 505.9863,-461.7706 504.651,-472.2809 511.4968,-470.8196\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081091480 -->\n<g class=\"node\" id=\"node4\">\n<title>140647081091480</title>\n<polygon fill=\"none\" points=\"551,-498.5 551,-544.5 986,-544.5 986,-498.5 551,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"681\" y=\"-517.8\">average_pooling2d_1: AveragePooling2D</text>\n<polyline fill=\"none\" points=\"811,-498.5 811,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"840\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"811,-521.5 869,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"840\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"869,-498.5 869,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"927.5\" y=\"-529.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"869,-521.5 986,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"927.5\" y=\"-506.3\">(None, 14, 14, 1)</text>\n</g>\n<!-- 140647098478264&#45;&gt;140647081091480 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140647098478264-&gt;140647081091480</title>\n<path d=\"M686.9768,-581.3799C699.8479,-571.9259 714.8901,-560.8772 728.5246,-550.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"730.8125,-553.5247 736.8001,-544.784 726.6686,-547.883 730.8125,-553.5247\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081501472 -->\n<g class=\"node\" id=\"node6\">\n<title>140647081501472</title>\n<polygon fill=\"none\" points=\"862,-332.5 862,-378.5 1185,-378.5 1185,-332.5 862,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"928.5\" y=\"-351.8\">conv2d_1: Conv2D</text>\n<polyline fill=\"none\" points=\"995,-332.5 995,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1024\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"995,-355.5 1053,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1024\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"1053,-332.5 1053,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1119\" y=\"-363.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"1053,-355.5 1185,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1119\" y=\"-340.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140647098478264&#45;&gt;140647081501472 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140647098478264-&gt;140647081501472</title>\n<path d=\"M809.5727,-593.7888C885.8155,-585.352 967.2774,-570.5669 994.5,-545 1036.8595,-505.2169 1034.9272,-431.5489 1029.4161,-388.7246\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1032.8773,-388.2038 1028.0027,-378.797 1025.9472,-389.1905 1032.8773,-388.2038\" stroke=\"#000000\"/>\n</g>\n<!-- 140647080903344 -->\n<g class=\"node\" id=\"node5\">\n<title>140647080903344</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 323,-461.5 323,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-434.8\">conv2d_6: Conv2D</text>\n<polyline fill=\"none\" points=\"133,-415.5 133,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-438.5 191,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-415.5 191,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-446.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"191,-438.5 323,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-423.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140647080803856&#45;&gt;140647080903344 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140647080803856-&gt;140647080903344</title>\n<path d=\"M223.5442,-498.3799C214.1182,-489.2827 203.1621,-478.7088 193.1029,-469.0005\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.2516,-466.2101 185.6256,-461.784 190.3905,-471.2469 195.2516,-466.2101\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081503320 -->\n<g class=\"node\" id=\"node7\">\n<title>140647081503320</title>\n<polygon fill=\"none\" points=\"454,-332.5 454,-378.5 777,-378.5 777,-332.5 454,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520.5\" y=\"-351.8\">conv2d_3: Conv2D</text>\n<polyline fill=\"none\" points=\"587,-332.5 587,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"587,-355.5 645,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"645,-332.5 645,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"711\" y=\"-363.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"645,-355.5 777,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"711\" y=\"-340.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140647081501528&#45;&gt;140647081503320 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140647081501528-&gt;140647081503320</title>\n<path d=\"M533.9768,-415.3799C546.8479,-405.9259 561.8901,-394.8772 575.5246,-384.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"577.8125,-387.5247 583.8001,-378.784 573.6686,-381.883 577.8125,-387.5247\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081202912 -->\n<g class=\"node\" id=\"node8\">\n<title>140647081202912</title>\n<polygon fill=\"none\" points=\"682,-415.5 682,-461.5 1005,-461.5 1005,-415.5 682,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"748.5\" y=\"-434.8\">conv2d_4: Conv2D</text>\n<polyline fill=\"none\" points=\"815,-415.5 815,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"815,-438.5 873,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"873,-415.5 873,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"939\" y=\"-446.3\">(None, 14, 14, 1)</text>\n<polyline fill=\"none\" points=\"873,-438.5 1005,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"939\" y=\"-423.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140647081091480&#45;&gt;140647081202912 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140647081091480-&gt;140647081202912</title>\n<path d=\"M789.3917,-498.3799C797.5315,-489.3718 806.9795,-478.916 815.6811,-469.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"818.3526,-471.5502 822.4602,-461.784 813.1589,-466.8571 818.3526,-471.5502\" stroke=\"#000000\"/>\n</g>\n<!-- 140647080997608 -->\n<g class=\"node\" id=\"node9\">\n<title>140647080997608</title>\n<polygon fill=\"none\" points=\"75,-332.5 75,-378.5 398,-378.5 398,-332.5 75,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141.5\" y=\"-351.8\">conv2d_7: Conv2D</text>\n<polyline fill=\"none\" points=\"208,-332.5 208,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"208,-355.5 266,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"266,-332.5 266,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332\" y=\"-363.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"266,-355.5 398,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332\" y=\"-340.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140647080903344&#45;&gt;140647080997608 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140647080903344-&gt;140647080997608</title>\n<path d=\"M182.3917,-415.3799C190.5315,-406.3718 199.9795,-395.916 208.6811,-386.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.3526,-388.5502 215.4602,-378.784 206.1589,-383.8571 211.3526,-388.5502\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081347224 -->\n<g class=\"node\" id=\"node10\">\n<title>140647081347224</title>\n<polygon fill=\"none\" points=\"348,-249.5 348,-295.5 1091,-295.5 1091,-249.5 348,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-268.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"523,-249.5 523,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"552\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"523,-272.5 581,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"552\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"581,-249.5 581,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"836\" y=\"-280.3\">[(None, 14, 14, 128), (None, 14, 14, 128), (None, 14, 14, 128), (None, 14, 14, 128)]</text>\n<polyline fill=\"none\" points=\"581,-272.5 1091,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"836\" y=\"-257.3\">(None, 14, 14, 512)</text>\n</g>\n<!-- 140647081501472&#45;&gt;140647081347224 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140647081501472-&gt;140647081347224</title>\n<path d=\"M939.2228,-332.4901C900.263,-321.853 853.8417,-309.1788 813.7274,-298.2266\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"814.51,-294.8122 803.9412,-295.5547 812.6662,-301.565 814.51,-294.8122\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081503320&#45;&gt;140647081347224 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140647081503320-&gt;140647081347224</title>\n<path d=\"M644.4698,-332.3799C656.204,-323.0151 669.8989,-312.0855 682.353,-302.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"684.6921,-304.7574 690.3249,-295.784 680.3256,-299.2862 684.6921,-304.7574\" stroke=\"#000000\"/>\n</g>\n<!-- 140647081202912&#45;&gt;140647081347224 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140647081202912-&gt;140647081347224</title>\n<path d=\"M833.5663,-415.1098C823.3673,-392.5636 806.1026,-358.1167 785.5,-332 777.2821,-321.5826 767.1363,-311.449 757.2858,-302.5844\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"759.3226,-299.7159 749.4915,-295.766 754.7136,-304.9845 759.3226,-299.7159\" stroke=\"#000000\"/>\n</g>\n<!-- 140647080997608&#45;&gt;140647081347224 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140647080997608-&gt;140647081347224</title>\n<path d=\"M370.401,-332.4901C434.1331,-321.5382 510.4321,-308.4268 575.4224,-297.2587\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"576.0758,-300.6978 585.3385,-295.5547 574.8902,-293.7989 576.0758,-300.6978\" stroke=\"#000000\"/>\n</g>\n<!-- 140647080585312 -->\n<g class=\"node\" id=\"node11\">\n<title>140647080585312</title>\n<polygon fill=\"none\" points=\"568,-166.5 568,-212.5 871,-212.5 871,-166.5 568,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624.5\" y=\"-185.8\">flatten_1: Flatten</text>\n<polyline fill=\"none\" points=\"681,-166.5 681,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"681,-189.5 739,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"710\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"739,-166.5 739,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"805\" y=\"-197.3\">(None, 14, 14, 512)</text>\n<polyline fill=\"none\" points=\"739,-189.5 871,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"805\" y=\"-174.3\">(None, 100352)</text>\n</g>\n<!-- 140647081347224&#45;&gt;140647080585312 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140647081347224-&gt;140647080585312</title>\n<path d=\"M719.5,-249.3799C719.5,-241.1745 719.5,-231.7679 719.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"723.0001,-222.784 719.5,-212.784 716.0001,-222.784 723.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140647080585032 -->\n<g class=\"node\" id=\"node12\">\n<title>140647080585032</title>\n<polygon fill=\"none\" points=\"582,-83.5 582,-129.5 857,-129.5 857,-83.5 582,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"635.5\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"689,-83.5 689,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"689,-106.5 747,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"747,-83.5 747,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-114.3\">(None, 100352)</text>\n<polyline fill=\"none\" points=\"747,-106.5 857,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-91.3\">(None, 512)</text>\n</g>\n<!-- 140647080585312&#45;&gt;140647080585032 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140647080585312-&gt;140647080585032</title>\n<path d=\"M719.5,-166.3799C719.5,-158.1745 719.5,-148.7679 719.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"723.0001,-139.784 719.5,-129.784 716.0001,-139.784 723.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140647080758856 -->\n<g class=\"node\" id=\"node13\">\n<title>140647080758856</title>\n<polygon fill=\"none\" points=\"593.5,-.5 593.5,-46.5 845.5,-46.5 845.5,-.5 593.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"647\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"700.5,-.5 700.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"729.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"700.5,-23.5 758.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"729.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"758.5,-.5 758.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-31.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"758.5,-23.5 845.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140647080585032&#45;&gt;140647080758856 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140647080585032-&gt;140647080758856</title>\n<path d=\"M719.5,-83.3799C719.5,-75.1745 719.5,-65.7679 719.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"723.0001,-56.784 719.5,-46.784 716.0001,-56.784 723.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "l64rIKuUwZgB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_Inception.png')\n",
        "from google.colab import files\n",
        "files.download('model_Inception.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scC7bX8b-2kH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Inception model"
      ]
    },
    {
      "metadata": {
        "id": "rXO444Ym-2kK",
        "colab_type": "code",
        "outputId": "c5cbbaea-f939-4e42-8033-3505deb2beed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(epochs=epochs,\n",
        "          steps_per_epoch=steps_per_epoch)\n",
        "\n",
        "# Save the model weights.\n",
        "weight_path = os.path.join(tempfile.gettempdir(), 'saved_Inception_wt.h5')\n",
        "model.save_weights(weight_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 88s 187ms/step - loss: 0.1677 - acc: 0.9547\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 81s 172ms/step - loss: 0.0401 - acc: 0.9877\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 81s 172ms/step - loss: 0.0224 - acc: 0.9932\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 80s 171ms/step - loss: 0.0137 - acc: 0.9960\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 80s 170ms/step - loss: 0.0088 - acc: 0.9974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoXjLLmX-2kP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test the Inception model\n",
        "\n",
        "Second session to test loading trained model without tensors."
      ]
    },
    {
      "metadata": {
        "id": "_KKWU3yt-2kR",
        "colab_type": "code",
        "outputId": "0b1a00f8-a323-4b00-ffa3-9b862470834a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        }
      },
      "cell_type": "code",
      "source": [
        "# Clean up the TF session.\n",
        "K.clear_session()\n",
        "\n",
        "# Second session to test loading trained model without tensors.\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "x_test_inp = layers.Input(shape=x_test.shape[1:])\n",
        "test_out = cnn_layers(x_test_inp)\n",
        "test_model = keras.models.Model(inputs=x_test_inp, outputs=test_out)\n",
        "\n",
        "weight_path = os.path.join(tempfile.gettempdir(), 'saved_Inception_wt.h5')\n",
        "test_model.load_weights(weight_path)\n",
        "\n",
        "test_model.compile(optimizer='rmsprop',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "test_model.summary()\n",
        "\n",
        "SVG(model_to_dot(test_model).create(prog='dot', format='svg'))\n",
        "\n",
        "loss, acc = test_model.evaluate(x_test, y_test, num_classes)\n",
        "print('\\nTest accuracy: {0}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (?, 28, 28, 1)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 128)  256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 14, 14, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 14, 14, 128)  256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 128)  147584      conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 128)  1280        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 14, 14, 128)  147584      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 512)  0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 100352)       0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          51380736    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 51,830,666\n",
            "Trainable params: 51,830,666\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "10000/10000 [==============================] - 10s 1ms/step\n",
            "\n",
            "Test accuracy: 0.9832999967932701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tLoWQDIe-2kY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Residual connections - ResNET\n",
        "\n",
        "Residual connections or ResNET are a common graph-like network component found in many post-2015 network architectures, including Xception. They were introduced by He et al. from Microsoft and are figthing two common problems with large-scale deep-learning model: vanishing gradients and representational bottlenecks. \n",
        "\n",
        "A residual connection consists of making the output of an earlier layer available as input to a later layer, effectively creating a shortcut in a sequential network. Rather than being concatenated to the later activation, the earlier output is summed with the later activation, which assumes that both activations are the same size. If they’re different sizes, you can use a linear transformation to reshape the earlier activation into the target shape (for example, a Dense layer without an activation or, for convolutional feature maps, a 1 × 1 convolution without an activation). \n",
        "\n",
        "###### ResNET implementation when the feature-map sizes are the same\n",
        "\n",
        "Here’s how to implement a residual connection in Keras when the feature-map sizes are the same, using identity residual connections. This example assumes the existence of a 4D input tensor x:"
      ]
    },
    {
      "metadata": {
        "id": "ulHHOdNT-2kZ",
        "colab_type": "code",
        "outputId": "a21aa830-ce43-437e-fb7e-c2720c3ee82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import layers \n",
        "from keras.layers import Input\n",
        "\n",
        "# This example assumes the existence of a 4D input tensor x:\n",
        "# This returns a typical image tensor like those of MNIST dataset \n",
        "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "print(\"x.shape:\",x.shape)\n",
        "\n",
        "# Applies a transformation to x\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "\n",
        "# Adds the original x back to the output features\n",
        "output = layers.add([y, x])\n",
        "\n",
        "# Adding a classifier on top of the convnet\n",
        "output = layers.Flatten()(output)\n",
        "output = layers.Dense(512, activation='relu')(output)\n",
        "predictions = layers.Dense(10, activation='softmax')(output)\n",
        "model = keras.models.Model(inputs=x, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sOfwL02q-2kc",
        "colab_type": "code",
        "outputId": "1a3169d7-9f74-49cf-acc1-e8ffef4e27a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1317
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  1280        images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 128)  0           conv2d_9[0][0]                   \n",
            "                                                                 images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 100352)       0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          51380736    flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           5130        dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 51,682,314\n",
            "Trainable params: 51,682,314\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"636pt\" viewBox=\"0.00 0.00 460.50 636.00\" width=\"461pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 632)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-632 456.5,-632 456.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140300208374224 -->\n<g class=\"node\" id=\"node1\">\n<title>140300208374224</title>\n<polygon fill=\"none\" points=\"105,-581.5 105,-627.5 408,-627.5 408,-581.5 105,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-600.8\">images: InputLayer</text>\n<polyline fill=\"none\" points=\"233,-581.5 233,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"233,-604.5 291,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"291,-581.5 291,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-612.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"291,-604.5 408,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-589.3\">(None, 28, 28, 1)</text>\n</g>\n<!-- 140300208742296 -->\n<g class=\"node\" id=\"node2\">\n<title>140300208742296</title>\n<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 323,-544.5 323,-498.5 0,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-517.8\">conv2d_7: Conv2D</text>\n<polyline fill=\"none\" points=\"133,-498.5 133,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-521.5 191,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-498.5 191,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-529.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"191,-521.5 323,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-506.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140300208374224&#45;&gt;140300208742296 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140300208374224-&gt;140300208742296</title>\n<path d=\"M230.0372,-581.3799C219.4206,-572.1043 207.0468,-561.2936 195.7577,-551.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"197.9839,-548.7277 188.1504,-544.784 193.3783,-553.9992 197.9839,-548.7277\" stroke=\"#000000\"/>\n</g>\n<!-- 140300208060568 -->\n<g class=\"node\" id=\"node5\">\n<title>140300208060568</title>\n<polygon fill=\"none\" points=\"60.5,-249.5 60.5,-295.5 452.5,-295.5 452.5,-249.5 60.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-268.8\">add_3: Add</text>\n<polyline fill=\"none\" points=\"145.5,-249.5 145.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"145.5,-272.5 203.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"203.5,-249.5 203.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328\" y=\"-280.3\">[(None, 28, 28, 128), (None, 28, 28, 1)]</text>\n<polyline fill=\"none\" points=\"203.5,-272.5 452.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328\" y=\"-257.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140300208374224&#45;&gt;140300208060568 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140300208374224-&gt;140300208060568</title>\n<path d=\"M298.8448,-581.2426C311.7625,-571.8231 324.4142,-559.6663 331.5,-545 372.6824,-459.7604 372.6824,-417.2396 331.5,-332 325.9088,-320.4274 316.8523,-310.4172 306.934,-302.0814\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"308.8787,-299.1591 298.8448,-295.7574 304.5674,-304.6739 308.8787,-299.1591\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207958728 -->\n<g class=\"node\" id=\"node3\">\n<title>140300207958728</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 323,-461.5 323,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-434.8\">conv2d_8: Conv2D</text>\n<polyline fill=\"none\" points=\"133,-415.5 133,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-438.5 191,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-415.5 191,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-446.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"191,-438.5 323,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-423.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140300208742296&#45;&gt;140300207958728 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140300208742296-&gt;140300207958728</title>\n<path d=\"M161.5,-498.3799C161.5,-490.1745 161.5,-480.7679 161.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"165.0001,-471.784 161.5,-461.784 158.0001,-471.784 165.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140300208059056 -->\n<g class=\"node\" id=\"node4\">\n<title>140300208059056</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 323,-378.5 323,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-351.8\">conv2d_9: Conv2D</text>\n<polyline fill=\"none\" points=\"133,-332.5 133,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-355.5 191,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-332.5 191,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-363.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"191,-355.5 323,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-340.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140300207958728&#45;&gt;140300208059056 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140300207958728-&gt;140300208059056</title>\n<path d=\"M161.5,-415.3799C161.5,-407.1745 161.5,-397.7679 161.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"165.0001,-388.784 161.5,-378.784 158.0001,-388.784 165.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140300208059056&#45;&gt;140300208060568 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140300208059056-&gt;140300208060568</title>\n<path d=\"M187.9628,-332.3799C198.5794,-323.1043 210.9532,-312.2936 222.2423,-302.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"224.6217,-304.9992 229.8496,-295.784 220.0161,-299.7277 224.6217,-304.9992\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207755616 -->\n<g class=\"node\" id=\"node6\">\n<title>140300207755616</title>\n<polygon fill=\"none\" points=\"105,-166.5 105,-212.5 408,-212.5 408,-166.5 105,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-185.8\">flatten_3: Flatten</text>\n<polyline fill=\"none\" points=\"218,-166.5 218,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"218,-189.5 276,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"276,-166.5 276,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"342\" y=\"-197.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"276,-189.5 408,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"342\" y=\"-174.3\">(None, 100352)</text>\n</g>\n<!-- 140300208060568&#45;&gt;140300207755616 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140300208060568-&gt;140300207755616</title>\n<path d=\"M256.5,-249.3799C256.5,-241.1745 256.5,-231.7679 256.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"260.0001,-222.784 256.5,-212.784 253.0001,-222.784 260.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207756008 -->\n<g class=\"node\" id=\"node7\">\n<title>140300207756008</title>\n<polygon fill=\"none\" points=\"119,-83.5 119,-129.5 394,-129.5 394,-83.5 119,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-102.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"226,-83.5 226,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"226,-106.5 284,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"284,-83.5 284,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-114.3\">(None, 100352)</text>\n<polyline fill=\"none\" points=\"284,-106.5 394,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-91.3\">(None, 512)</text>\n</g>\n<!-- 140300207755616&#45;&gt;140300207756008 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140300207755616-&gt;140300207756008</title>\n<path d=\"M256.5,-166.3799C256.5,-158.1745 256.5,-148.7679 256.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"260.0001,-139.784 256.5,-129.784 253.0001,-139.784 260.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207855152 -->\n<g class=\"node\" id=\"node8\">\n<title>140300207855152</title>\n<polygon fill=\"none\" points=\"130.5,-.5 130.5,-46.5 382.5,-46.5 382.5,-.5 130.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-19.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"237.5,-.5 237.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"237.5,-23.5 295.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"295.5,-.5 295.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-31.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"295.5,-23.5 382.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140300207756008&#45;&gt;140300207855152 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140300207756008-&gt;140300207855152</title>\n<path d=\"M256.5,-83.3799C256.5,-75.1745 256.5,-65.7679 256.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"260.0001,-56.784 256.5,-46.784 253.0001,-56.784 260.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "TVSBtb6N-2km",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### ResNET implementation when the feature-map sizes differ\n",
        "\n",
        "And the following implements a residual connection when the feature-map sizes differ, using a linear residual connection (again, assuming the existence of a 4D input tensor x):"
      ]
    },
    {
      "metadata": {
        "id": "jdm2a7wX-2kn",
        "colab_type": "code",
        "outputId": "56469c4f-af0f-4ec6-8d06-10e852428508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import layers \n",
        "from keras.layers import Input\n",
        "\n",
        "# This example assumes the existence of a 4D input tensor x:\n",
        "# This returns a typical image tensor like those of MNIST dataset \n",
        "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "print(\"x.shape:\",x.shape)\n",
        "\n",
        "# Applies a transformation to x\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.MaxPooling2D(2, strides=2)(y)\n",
        "\n",
        "# Uses a 1 × 1 convolution to linearly downsample the original x tensor to the same shape as y\n",
        "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
        "\n",
        "# Adds the residual tensor back to the output features\n",
        "output = layers.add([y, residual])\n",
        "\n",
        "# Adding a classifier on top of the convnet\n",
        "output = layers.Flatten()(output)\n",
        "output = layers.Dense(512, activation='relu')(output)\n",
        "predictions = layers.Dense(10, activation='softmax')(output)\n",
        "model = keras.models.Model(inputs=x, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mExOZ_Jm-2ku",
        "colab_type": "code",
        "outputId": "70bae303-db38-4143-be23-a7fb56eb235e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1354
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 128)  1280        images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 128)  147584      conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 128)  256         images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 128)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 25088)        0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 512)          12845568    flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 10)           5130        dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 12,999,818\n",
            "Trainable params: 12,999,818\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"636pt\" viewBox=\"0.00 0.00 686.00 636.00\" width=\"686pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 632)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-632 682,-632 682,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140299896323936 -->\n<g class=\"node\" id=\"node1\">\n<title>140299896323936</title>\n<polygon fill=\"none\" points=\"186.5,-581.5 186.5,-627.5 489.5,-627.5 489.5,-581.5 186.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-600.8\">images: InputLayer</text>\n<polyline fill=\"none\" points=\"314.5,-581.5 314.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"314.5,-604.5 372.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"372.5,-581.5 372.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431\" y=\"-612.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"372.5,-604.5 489.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431\" y=\"-589.3\">(None, 28, 28, 1)</text>\n</g>\n<!-- 140300208742240 -->\n<g class=\"node\" id=\"node2\">\n<title>140300208742240</title>\n<polygon fill=\"none\" points=\"77,-498.5 77,-544.5 407,-544.5 407,-498.5 77,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-517.8\">conv2d_10: Conv2D</text>\n<polyline fill=\"none\" points=\"217,-498.5 217,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-521.5 275,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-498.5 275,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341\" y=\"-529.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"275,-521.5 407,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341\" y=\"-506.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140299896323936&#45;&gt;140300208742240 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140299896323936-&gt;140300208742240</title>\n<path d=\"M311.2586,-581.3799C300.5303,-572.1043 288.0263,-561.2936 276.6183,-551.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"278.7847,-548.6767 268.9309,-544.784 274.2065,-553.972 278.7847,-548.6767\" stroke=\"#000000\"/>\n</g>\n<!-- 140299896320408 -->\n<g class=\"node\" id=\"node5\">\n<title>140299896320408</title>\n<polygon fill=\"none\" points=\"348,-415.5 348,-461.5 678,-461.5 678,-415.5 348,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418\" y=\"-434.8\">conv2d_12: Conv2D</text>\n<polyline fill=\"none\" points=\"488,-415.5 488,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"488,-438.5 546,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"546,-415.5 546,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"612\" y=\"-446.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"546,-438.5 678,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"612\" y=\"-423.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140299896323936&#45;&gt;140299896320408 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140299896323936-&gt;140299896320408</title>\n<path d=\"M370.9256,-581.435C385.2495,-570.8883 401.9371,-557.8885 416,-545 441.9447,-521.222 468.6753,-491.4056 487.4887,-469.3738\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"490.2517,-471.5269 494.0455,-461.6346 484.9108,-467.0019 490.2517,-471.5269\" stroke=\"#000000\"/>\n</g>\n<!-- 140299896323544 -->\n<g class=\"node\" id=\"node3\">\n<title>140299896323544</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 330,-461.5 330,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-434.8\">conv2d_11: Conv2D</text>\n<polyline fill=\"none\" points=\"140,-415.5 140,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"140,-438.5 198,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"198,-415.5 198,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-446.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"198,-438.5 330,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-423.3\">(None, 28, 28, 128)</text>\n</g>\n<!-- 140300208742240&#45;&gt;140299896323544 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140300208742240-&gt;140299896323544</title>\n<path d=\"M220.5512,-498.3799C212.1944,-489.3718 202.4943,-478.916 193.5608,-469.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.9679,-466.7347 186.6008,-461.784 190.8361,-471.4955 195.9679,-466.7347\" stroke=\"#000000\"/>\n</g>\n<!-- 140299896323040 -->\n<g class=\"node\" id=\"node4\">\n<title>140299896323040</title>\n<polygon fill=\"none\" points=\"16.5,-332.5 16.5,-378.5 427.5,-378.5 427.5,-332.5 16.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-351.8\">max_pooling2d_2: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"237.5,-332.5 237.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"237.5,-355.5 295.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"295.5,-332.5 295.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-363.3\">(None, 28, 28, 128)</text>\n<polyline fill=\"none\" points=\"295.5,-355.5 427.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-340.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140299896323544&#45;&gt;140299896323040 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140299896323544-&gt;140299896323040</title>\n<path d=\"M180.8777,-415.3799C186.8802,-406.6394 193.8188,-396.5358 200.2669,-387.1465\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"203.2338,-389.0087 206.0098,-378.784 197.4635,-385.0459 203.2338,-389.0087\" stroke=\"#000000\"/>\n</g>\n<!-- 140299896320240 -->\n<g class=\"node\" id=\"node6\">\n<title>140299896320240</title>\n<polygon fill=\"none\" points=\"135.5,-249.5 135.5,-295.5 542.5,-295.5 542.5,-249.5 135.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-268.8\">add_4: Add</text>\n<polyline fill=\"none\" points=\"220.5,-249.5 220.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"220.5,-272.5 278.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"278.5,-249.5 278.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"410.5\" y=\"-280.3\">[(None, 14, 14, 128), (None, 14, 14, 128)]</text>\n<polyline fill=\"none\" points=\"278.5,-272.5 542.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"410.5\" y=\"-257.3\">(None, 14, 14, 128)</text>\n</g>\n<!-- 140299896323040&#45;&gt;140299896320240 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140299896323040-&gt;140299896320240</title>\n<path d=\"M254.591,-332.3799C268.0434,-322.8367 283.7865,-311.6686 298.0087,-301.5793\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"300.0469,-304.4247 306.178,-295.784 295.9967,-298.7154 300.0469,-304.4247\" stroke=\"#000000\"/>\n</g>\n<!-- 140299896320408&#45;&gt;140299896320240 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140299896320408-&gt;140299896320240</title>\n<path d=\"M499.9315,-415.2724C486.1576,-392.2143 462.7727,-356.8169 436,-332 423.5215,-320.4331 408.4605,-309.9146 393.967,-301.0484\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"395.429,-297.8459 385.0442,-295.7468 391.8534,-303.8638 395.429,-297.8459\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207280480 -->\n<g class=\"node\" id=\"node7\">\n<title>140300207280480</title>\n<polygon fill=\"none\" points=\"187.5,-166.5 187.5,-212.5 490.5,-212.5 490.5,-166.5 187.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-185.8\">flatten_4: Flatten</text>\n<polyline fill=\"none\" points=\"300.5,-166.5 300.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"300.5,-189.5 358.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"358.5,-166.5 358.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-197.3\">(None, 14, 14, 128)</text>\n<polyline fill=\"none\" points=\"358.5,-189.5 490.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-174.3\">(None, 25088)</text>\n</g>\n<!-- 140299896320240&#45;&gt;140300207280480 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140299896320240-&gt;140300207280480</title>\n<path d=\"M339,-249.3799C339,-241.1745 339,-231.7679 339,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"342.5001,-222.784 339,-212.784 335.5001,-222.784 342.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207280200 -->\n<g class=\"node\" id=\"node8\">\n<title>140300207280200</title>\n<polygon fill=\"none\" points=\"205.5,-83.5 205.5,-129.5 472.5,-129.5 472.5,-83.5 205.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-102.8\">dense_7: Dense</text>\n<polyline fill=\"none\" points=\"312.5,-83.5 312.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"312.5,-106.5 370.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"370.5,-83.5 370.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-114.3\">(None, 25088)</text>\n<polyline fill=\"none\" points=\"370.5,-106.5 472.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-91.3\">(None, 512)</text>\n</g>\n<!-- 140300207280480&#45;&gt;140300207280200 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140300207280480-&gt;140300207280200</title>\n<path d=\"M339,-166.3799C339,-158.1745 339,-148.7679 339,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"342.5001,-139.784 339,-129.784 335.5001,-139.784 342.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140300207274584 -->\n<g class=\"node\" id=\"node9\">\n<title>140300207274584</title>\n<polygon fill=\"none\" points=\"213,-.5 213,-46.5 465,-46.5 465,-.5 213,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-19.8\">dense_8: Dense</text>\n<polyline fill=\"none\" points=\"320,-.5 320,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"320,-23.5 378,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"378,-.5 378,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-31.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"378,-23.5 465,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140300207280200&#45;&gt;140300207274584 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140300207280200-&gt;140300207274584</title>\n<path d=\"M339,-83.3799C339,-75.1745 339,-65.7679 339,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"342.5001,-56.784 339,-46.784 335.5001,-56.784 342.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "C7uwDATrVfQD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train and Save the ResNet model using  the CIFAR10 data"
      ]
    },
    {
      "metadata": {
        "id": "5MvFWgjBqCtd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#法1\n",
        "import keras\n",
        "import tempfile\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Add, Concatenate, Lambda\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import os\n",
        "\n",
        "def zeropad(x):\n",
        "    y = K.zeros_like(x)\n",
        "    return Concatenate()([x,y])\n",
        "\n",
        "def residualConvolution(x, num_filter, size, num_layer, reg, padding=False):\n",
        "    c = x\n",
        "    #ASSUME THE SIZE OF AXIS -1 DOUBLE\n",
        "    if padding:\n",
        "        x = Lambda(zeropad)(x)\n",
        "\n",
        "    for i in range(num_layer-1):\n",
        "        c = Conv2D(num_filter, (size, size), padding='same')(c)\n",
        "        c = Dropout(0.1)(c)\n",
        "        c = BatchNormalization()(c)\n",
        "        c = Activation('relu')(c)\n",
        "\n",
        "    c = Conv2D(num_filter, (size, size), padding='same')(c)\n",
        "    c = Dropout(0.1)(c)\n",
        "    c = BatchNormalization()(c)\n",
        "\n",
        "    # add back residual before non-linearity\n",
        "    y = Add()([c, x])\n",
        "    return Activation('relu')(c)\n",
        "\n",
        "\n",
        "# 19 layers network based on VGG architecture with residual connection\n",
        "def generateModel(reg, dropout_p, input_shape, num_classes):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # First Block: 1 128 3x3 convolutional filters (strides 2)\n",
        "    y = Conv2D(128, (3, 3), padding='same' )(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    # Second Block: 2 128 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=128, size=3, num_layer=2, reg=reg)\n",
        "\n",
        "    y = MaxPooling2D()(y)\n",
        "    y = Dropout(0.25)(y)\n",
        "\n",
        "    # Third Block: 2 256 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=256, size=3, num_layer=2, reg=reg, padding=True)\n",
        "\n",
        "    # Fourth Block: 2 256 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=256, size=3, num_layer=2, reg=reg)\n",
        "\n",
        "    y = MaxPooling2D()(y)\n",
        "    y = Dropout(0.25)(y)\n",
        "\n",
        "    # Fifth Block: 2 512 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=512, size=3, num_layer=2, reg=reg, padding=True)\n",
        "\n",
        "    # Sixth Block: 2 512 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=512, size=3, num_layer=2, reg=reg)\n",
        "\n",
        "\n",
        "    y = Flatten()(y)\n",
        "\n",
        "    for i in range(1):\n",
        "        y = Dense(512)(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Dropout(dropout_p)(y)\n",
        "\n",
        "    y = Dense(num_classes, activation='softmax')(y)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtO740Q8ebad",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 法2\n",
        "import keras\n",
        "import tempfile\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Add, Concatenate, Lambda\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import os\n",
        "\n",
        "def zeropad(x):\n",
        "    y = K.zeros_like(x)\n",
        "    return Concatenate()([x,y])\n",
        "\n",
        "def residualConvolution(x, num_filter, size, num_layer, reg, padding=False):\n",
        "    c = x\n",
        "    #ASSUME THE SIZE OF AXIS -1 DOUBLE\n",
        "    if padding:\n",
        "        x = Lambda(zeropad)(x)\n",
        "\n",
        "    for i in range(num_layer-1):\n",
        "        c = Conv2D(num_filter, (size, size), padding='same')(c)\n",
        "        c = Dropout(0.1)(c)\n",
        "        c = BatchNormalization()(c)\n",
        "        c = Activation('relu')(c)\n",
        "\n",
        "    c = Conv2D(num_filter, (size, size), padding='same')(c)\n",
        "    c = Dropout(0.1)(c)\n",
        "    c = BatchNormalization()(c)\n",
        "\n",
        "    # add back residual before non-linearity\n",
        "    c = Add()([c, x])\n",
        "    return Activation('relu')(c)\n",
        "\n",
        "\n",
        "# 19 layers network based on VGG architecture with residual connection\n",
        "def generateModel(reg, dropout_p, input_shape, num_classes):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # First Block: 1 128 3x3 convolutional filters (strides 2)\n",
        "    y = Conv2D(128, (3, 3), padding='same' )(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    # Second Block: 2 128 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=128, size=3, num_layer=2, reg=reg)\n",
        "\n",
        "    y = MaxPooling2D()(y)\n",
        "    y = Dropout(0.25)(y)\n",
        "\n",
        "    # Third Block: 2 256 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=256, size=3, num_layer=2, reg=reg, padding=True)\n",
        "\n",
        "    # Fourth Block: 2 256 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=256, size=3, num_layer=2, reg=reg)\n",
        "\n",
        "    y = MaxPooling2D()(y)\n",
        "    y = Dropout(0.25)(y)\n",
        "\n",
        "    # Fifth Block: 2 512 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=512, size=3, num_layer=2, reg=reg, padding=True)\n",
        "\n",
        "    # Sixth Block: 2 512 3x3 convolutional filters with residual connection\n",
        "    y = residualConvolution(y, num_filter=512, size=3, num_layer=2, reg=reg)\n",
        "\n",
        "\n",
        "    y = Flatten()(y)\n",
        "\n",
        "    for i in range(1):\n",
        "        y = Dense(512)(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Dropout(dropout_p)(y)\n",
        "\n",
        "    y = Dense(num_classes, activation='softmax')(y)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MuB7AxKdrJyL",
        "colab_type": "code",
        "outputId": "79b34a74-ba46-4cc7-8fa2-4f2d9610b5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "reg = 0.001\n",
        "dropout_p = 0.5\n",
        "lr = 0.00025\n",
        "num_classes = 10\n",
        "epochs = 40\n",
        "\n",
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "\n",
        "steps_per_epoch = int(np.ceil(50000 / float(batch_size)))  \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "print(x_train.shape)\n",
        "input_shape = x_train.shape[1:]\n",
        "print (input_shape)\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "#print(\"inputs.shape:\",inputs.shape)\n",
        "#print(\"targets.shape:\",targets.shape)\n",
        "\n",
        "#model_input = layers.Input(tensor=inputs)\n",
        "x = Input(shape = input_shape, dtype  = 'float32', name = 'images')\n",
        "model_output = generateModel(reg, dropout_p, input_shape, num_classes)\n",
        "\n",
        "\n",
        "model = keras.models.Model(inputs = x, outputs = model_output)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr = lr),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_c8bd2HeoCM",
        "colab_type": "code",
        "outputId": "dec2fea2-561d-4f44-cac5-b122998e90ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8791
        }
      },
      "cell_type": "code",
      "source": [
        "#法2\n",
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "\n",
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_ResNet.png')\n",
        "from google.colab import files\n",
        "files.download('model_ResNet.png')\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 128)  3584        images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 128)  147584      activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 128)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  147584      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 16, 128)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 256)  295168      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 256)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 256)  590080      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 16, 256)  0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 256)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 256)  1024        dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16, 16, 256)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 8, 8, 256)    0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 512)    1180160     dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 8, 8, 512)    0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 512)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 512)    2359808     activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8, 8, 512)    0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 512)    2048        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 8, 8, 512)    0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 512)    0           batch_normalization_9[0][0]      \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 512)    2359808     activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 8, 8, 512)    0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 512)    2048        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 512)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 512)    2359808     activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 8, 8, 512)    0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 512)    2048        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 512)    0           batch_normalization_11[0][0]     \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32768)        0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          16777728    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 512)          2048        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 512)          0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 512)          0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           5130        dropout_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 27,422,474\n",
            "Trainable params: 27,414,538\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"4869pt\" viewBox=\"0.00 0.00 700.00 4869.00\" width=\"700pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 4865)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-4865 696,-4865 696,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140178357568680 -->\n<g class=\"node\" id=\"node1\">\n<title>140178357568680</title>\n<polygon fill=\"none\" points=\"243,-4814.5 243,-4860.5 546,-4860.5 546,-4814.5 243,-4814.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-4833.8\">images: InputLayer</text>\n<polyline fill=\"none\" points=\"371,-4814.5 371,-4860.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-4845.3\">input:</text>\n<polyline fill=\"none\" points=\"371,-4837.5 429,-4837.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-4822.3\">output:</text>\n<polyline fill=\"none\" points=\"429,-4814.5 429,-4860.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-4845.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"429,-4837.5 546,-4837.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-4822.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 140178278478232 -->\n<g class=\"node\" id=\"node2\">\n<title>140178278478232</title>\n<polygon fill=\"none\" points=\"233,-4731.5 233,-4777.5 556,-4777.5 556,-4731.5 233,-4731.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-4750.8\">conv2d_1: Conv2D</text>\n<polyline fill=\"none\" points=\"366,-4731.5 366,-4777.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4762.3\">input:</text>\n<polyline fill=\"none\" points=\"366,-4754.5 424,-4754.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4739.3\">output:</text>\n<polyline fill=\"none\" points=\"424,-4731.5 424,-4777.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-4762.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"424,-4754.5 556,-4754.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-4739.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178357568680&#45;&gt;140178278478232 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140178357568680-&gt;140178278478232</title>\n<path d=\"M394.5,-4814.3799C394.5,-4806.1745 394.5,-4796.7679 394.5,-4787.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-4787.784 394.5,-4777.784 391.0001,-4787.784 398.0001,-4787.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178278477896 -->\n<g class=\"node\" id=\"node3\">\n<title>140178278477896</title>\n<polygon fill=\"none\" points=\"164,-4648.5 164,-4694.5 625,-4694.5 625,-4648.5 164,-4648.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-4667.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"435,-4648.5 435,-4694.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-4679.3\">input:</text>\n<polyline fill=\"none\" points=\"435,-4671.5 493,-4671.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-4656.3\">output:</text>\n<polyline fill=\"none\" points=\"493,-4648.5 493,-4694.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559\" y=\"-4679.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"493,-4671.5 625,-4671.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559\" y=\"-4656.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278478232&#45;&gt;140178278477896 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140178278478232-&gt;140178278477896</title>\n<path d=\"M394.5,-4731.3799C394.5,-4723.1745 394.5,-4713.7679 394.5,-4704.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-4704.784 394.5,-4694.784 391.0001,-4704.784 398.0001,-4704.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178278480808 -->\n<g class=\"node\" id=\"node4\">\n<title>140178278480808</title>\n<polygon fill=\"none\" points=\"222.5,-4565.5 222.5,-4611.5 566.5,-4611.5 566.5,-4565.5 222.5,-4565.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-4584.8\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"376.5,-4565.5 376.5,-4611.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-4596.3\">input:</text>\n<polyline fill=\"none\" points=\"376.5,-4588.5 434.5,-4588.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-4573.3\">output:</text>\n<polyline fill=\"none\" points=\"434.5,-4565.5 434.5,-4611.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500.5\" y=\"-4596.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"434.5,-4588.5 566.5,-4588.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500.5\" y=\"-4573.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278477896&#45;&gt;140178278480808 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140178278477896-&gt;140178278480808</title>\n<path d=\"M394.5,-4648.3799C394.5,-4640.1745 394.5,-4630.7679 394.5,-4621.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-4621.784 394.5,-4611.784 391.0001,-4621.784 398.0001,-4621.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178278479576 -->\n<g class=\"node\" id=\"node5\">\n<title>140178278479576</title>\n<polygon fill=\"none\" points=\"138,-4482.5 138,-4528.5 461,-4528.5 461,-4482.5 138,-4482.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204.5\" y=\"-4501.8\">conv2d_2: Conv2D</text>\n<polyline fill=\"none\" points=\"271,-4482.5 271,-4528.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-4513.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-4505.5 329,-4505.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-4490.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-4482.5 329,-4528.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4513.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"329,-4505.5 461,-4505.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4490.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278480808&#45;&gt;140178278479576 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140178278480808-&gt;140178278479576</title>\n<path d=\"M368.0372,-4565.3799C357.4206,-4556.1043 345.0468,-4545.2936 333.7577,-4535.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"335.9839,-4532.7277 326.1504,-4528.784 331.3783,-4537.9992 335.9839,-4532.7277\" stroke=\"#000000\"/>\n</g>\n<!-- 140178279348824 -->\n<g class=\"node\" id=\"node12\">\n<title>140178279348824</title>\n<polygon fill=\"none\" points=\"156,-3901.5 156,-3947.5 563,-3947.5 563,-3901.5 156,-3901.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-3920.8\">add_1: Add</text>\n<polyline fill=\"none\" points=\"241,-3901.5 241,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270\" y=\"-3932.3\">input:</text>\n<polyline fill=\"none\" points=\"241,-3924.5 299,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270\" y=\"-3909.3\">output:</text>\n<polyline fill=\"none\" points=\"299,-3901.5 299,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431\" y=\"-3932.3\">[(None, 32, 32, 128), (None, 32, 32, 128)]</text>\n<polyline fill=\"none\" points=\"299,-3924.5 563,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431\" y=\"-3909.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278480808&#45;&gt;140178279348824 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140178278480808-&gt;140178279348824</title>\n<path d=\"M434.1517,-4565.284C447.3244,-4555.6667 460.8278,-4543.3733 469.5,-4529 494.3801,-4487.7637 489.5,-4470.6607 489.5,-4422.5 489.5,-4422.5 489.5,-4422.5 489.5,-4090.5 489.5,-4042.3393 497.8851,-4022.9068 469.5,-3984 460.2099,-3971.2663 447.3426,-3960.9698 433.6742,-3952.7521\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"435.037,-3949.5029 424.6059,-3947.6475 431.6032,-3955.6029 435.037,-3949.5029\" stroke=\"#000000\"/>\n</g>\n<!-- 140178278570024 -->\n<g class=\"node\" id=\"node6\">\n<title>140178278570024</title>\n<polygon fill=\"none\" points=\"103.5,-4399.5 103.5,-4445.5 427.5,-4445.5 427.5,-4399.5 103.5,-4399.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-4418.8\">dropout_1: Dropout</text>\n<polyline fill=\"none\" points=\"237.5,-4399.5 237.5,-4445.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-4430.3\">input:</text>\n<polyline fill=\"none\" points=\"237.5,-4422.5 295.5,-4422.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-4407.3\">output:</text>\n<polyline fill=\"none\" points=\"295.5,-4399.5 295.5,-4445.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-4430.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"295.5,-4422.5 427.5,-4422.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-4407.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278479576&#45;&gt;140178278570024 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140178278479576-&gt;140178278570024</title>\n<path d=\"M290.0291,-4482.3799C286.5948,-4473.9962 282.6468,-4464.3584 278.936,-4455.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"282.0676,-4453.7109 275.038,-4445.784 275.59,-4456.3645 282.0676,-4453.7109\" stroke=\"#000000\"/>\n</g>\n<!-- 140178280197592 -->\n<g class=\"node\" id=\"node7\">\n<title>140178280197592</title>\n<polygon fill=\"none\" points=\"0,-4316.5 0,-4362.5 461,-4362.5 461,-4316.5 0,-4316.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-4335.8\">batch_normalization_2: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-4316.5 271,-4362.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-4347.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-4339.5 329,-4339.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-4324.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-4316.5 329,-4362.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4347.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"329,-4339.5 461,-4339.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4324.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278570024&#45;&gt;140178280197592 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140178278570024-&gt;140178280197592</title>\n<path d=\"M255.7505,-4399.3799C252.1776,-4390.907 248.0646,-4381.1531 244.2093,-4372.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"247.4291,-4370.6383 240.3186,-4362.784 240.9792,-4373.3582 247.4291,-4370.6383\" stroke=\"#000000\"/>\n</g>\n<!-- 140178280195016 -->\n<g class=\"node\" id=\"node8\">\n<title>140178280195016</title>\n<polygon fill=\"none\" points=\"58.5,-4233.5 58.5,-4279.5 402.5,-4279.5 402.5,-4233.5 58.5,-4233.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-4252.8\">activation_2: Activation</text>\n<polyline fill=\"none\" points=\"212.5,-4233.5 212.5,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-4264.3\">input:</text>\n<polyline fill=\"none\" points=\"212.5,-4256.5 270.5,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-4241.3\">output:</text>\n<polyline fill=\"none\" points=\"270.5,-4233.5 270.5,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-4264.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"270.5,-4256.5 402.5,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-4241.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178280197592&#45;&gt;140178280195016 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140178280197592-&gt;140178280195016</title>\n<path d=\"M230.5,-4316.3799C230.5,-4308.1745 230.5,-4298.7679 230.5,-4289.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"234.0001,-4289.784 230.5,-4279.784 227.0001,-4289.784 234.0001,-4289.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178278000400 -->\n<g class=\"node\" id=\"node9\">\n<title>140178278000400</title>\n<polygon fill=\"none\" points=\"69,-4150.5 69,-4196.5 392,-4196.5 392,-4150.5 69,-4150.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-4169.8\">conv2d_3: Conv2D</text>\n<polyline fill=\"none\" points=\"202,-4150.5 202,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-4181.3\">input:</text>\n<polyline fill=\"none\" points=\"202,-4173.5 260,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-4158.3\">output:</text>\n<polyline fill=\"none\" points=\"260,-4150.5 260,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326\" y=\"-4181.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"260,-4173.5 392,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326\" y=\"-4158.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178280195016&#45;&gt;140178278000400 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140178280195016-&gt;140178278000400</title>\n<path d=\"M230.5,-4233.3799C230.5,-4225.1745 230.5,-4215.7679 230.5,-4206.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"234.0001,-4206.784 230.5,-4196.784 227.0001,-4206.784 234.0001,-4206.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178279421432 -->\n<g class=\"node\" id=\"node10\">\n<title>140178279421432</title>\n<polygon fill=\"none\" points=\"68.5,-4067.5 68.5,-4113.5 392.5,-4113.5 392.5,-4067.5 68.5,-4067.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-4086.8\">dropout_2: Dropout</text>\n<polyline fill=\"none\" points=\"202.5,-4067.5 202.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231.5\" y=\"-4098.3\">input:</text>\n<polyline fill=\"none\" points=\"202.5,-4090.5 260.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231.5\" y=\"-4075.3\">output:</text>\n<polyline fill=\"none\" points=\"260.5,-4067.5 260.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.5\" y=\"-4098.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"260.5,-4090.5 392.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.5\" y=\"-4075.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178278000400&#45;&gt;140178279421432 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140178278000400-&gt;140178279421432</title>\n<path d=\"M230.5,-4150.3799C230.5,-4142.1745 230.5,-4132.7679 230.5,-4123.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"234.0001,-4123.784 230.5,-4113.784 227.0001,-4123.784 234.0001,-4123.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178280911592 -->\n<g class=\"node\" id=\"node11\">\n<title>140178280911592</title>\n<polygon fill=\"none\" points=\"0,-3984.5 0,-4030.5 461,-4030.5 461,-3984.5 0,-3984.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-4003.8\">batch_normalization_3: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-3984.5 271,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-4015.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-4007.5 329,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-3992.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-3984.5 329,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-4015.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"329,-4007.5 461,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-3992.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178279421432&#45;&gt;140178280911592 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140178279421432-&gt;140178280911592</title>\n<path d=\"M230.5,-4067.3799C230.5,-4059.1745 230.5,-4049.7679 230.5,-4040.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"234.0001,-4040.784 230.5,-4030.784 227.0001,-4040.784 234.0001,-4040.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178280911592&#45;&gt;140178279348824 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140178280911592-&gt;140178279348824</title>\n<path d=\"M266.4337,-3984.3799C281.4044,-3974.7475 298.9482,-3963.4597 314.7437,-3953.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"316.7957,-3956.1383 323.3116,-3947.784 313.0081,-3950.2515 316.7957,-3956.1383\" stroke=\"#000000\"/>\n</g>\n<!-- 140178281927904 -->\n<g class=\"node\" id=\"node13\">\n<title>140178281927904</title>\n<polygon fill=\"none\" points=\"187.5,-3818.5 187.5,-3864.5 531.5,-3864.5 531.5,-3818.5 187.5,-3818.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-3837.8\">activation_3: Activation</text>\n<polyline fill=\"none\" points=\"341.5,-3818.5 341.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.5\" y=\"-3849.3\">input:</text>\n<polyline fill=\"none\" points=\"341.5,-3841.5 399.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.5\" y=\"-3826.3\">output:</text>\n<polyline fill=\"none\" points=\"399.5,-3818.5 399.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"465.5\" y=\"-3849.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"399.5,-3841.5 531.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"465.5\" y=\"-3826.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140178279348824&#45;&gt;140178281927904 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140178279348824-&gt;140178281927904</title>\n<path d=\"M359.5,-3901.3799C359.5,-3893.1745 359.5,-3883.7679 359.5,-3874.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"363.0001,-3874.784 359.5,-3864.784 356.0001,-3874.784 363.0001,-3874.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178281927512 -->\n<g class=\"node\" id=\"node14\">\n<title>140178281927512</title>\n<polygon fill=\"none\" points=\"154,-3735.5 154,-3781.5 565,-3781.5 565,-3735.5 154,-3735.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-3754.8\">max_pooling2d_1: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"375,-3735.5 375,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"404\" y=\"-3766.3\">input:</text>\n<polyline fill=\"none\" points=\"375,-3758.5 433,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"404\" y=\"-3743.3\">output:</text>\n<polyline fill=\"none\" points=\"433,-3735.5 433,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499\" y=\"-3766.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"433,-3758.5 565,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499\" y=\"-3743.3\">(None, 16, 16, 128)</text>\n</g>\n<!-- 140178281927904&#45;&gt;140178281927512 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140178281927904-&gt;140178281927512</title>\n<path d=\"M359.5,-3818.3799C359.5,-3810.1745 359.5,-3800.7679 359.5,-3791.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"363.0001,-3791.784 359.5,-3781.784 356.0001,-3791.784 363.0001,-3791.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178277813384 -->\n<g class=\"node\" id=\"node15\">\n<title>140178277813384</title>\n<polygon fill=\"none\" points=\"197.5,-3652.5 197.5,-3698.5 521.5,-3698.5 521.5,-3652.5 197.5,-3652.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-3671.8\">dropout_3: Dropout</text>\n<polyline fill=\"none\" points=\"331.5,-3652.5 331.5,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.5\" y=\"-3683.3\">input:</text>\n<polyline fill=\"none\" points=\"331.5,-3675.5 389.5,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.5\" y=\"-3660.3\">output:</text>\n<polyline fill=\"none\" points=\"389.5,-3652.5 389.5,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"455.5\" y=\"-3683.3\">(None, 16, 16, 128)</text>\n<polyline fill=\"none\" points=\"389.5,-3675.5 521.5,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"455.5\" y=\"-3660.3\">(None, 16, 16, 128)</text>\n</g>\n<!-- 140178281927512&#45;&gt;140178277813384 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140178281927512-&gt;140178277813384</title>\n<path d=\"M359.5,-3735.3799C359.5,-3727.1745 359.5,-3717.7679 359.5,-3708.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"363.0001,-3708.784 359.5,-3698.784 356.0001,-3708.784 363.0001,-3708.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178281502424 -->\n<g class=\"node\" id=\"node16\">\n<title>140178281502424</title>\n<polygon fill=\"none\" points=\"103,-3569.5 103,-3615.5 426,-3615.5 426,-3569.5 103,-3569.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-3588.8\">conv2d_4: Conv2D</text>\n<polyline fill=\"none\" points=\"236,-3569.5 236,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265\" y=\"-3600.3\">input:</text>\n<polyline fill=\"none\" points=\"236,-3592.5 294,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265\" y=\"-3577.3\">output:</text>\n<polyline fill=\"none\" points=\"294,-3569.5 294,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-3600.3\">(None, 16, 16, 128)</text>\n<polyline fill=\"none\" points=\"294,-3592.5 426,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-3577.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140178277813384&#45;&gt;140178281502424 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140178277813384-&gt;140178281502424</title>\n<path d=\"M333.0372,-3652.3799C322.4206,-3643.1043 310.0468,-3632.2936 298.7577,-3622.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"300.9839,-3619.7277 291.1504,-3615.784 296.3783,-3624.9992 300.9839,-3619.7277\" stroke=\"#000000\"/>\n</g>\n<!-- 140178277811424 -->\n<g class=\"node\" id=\"node23\">\n<title>140178277811424</title>\n<polygon fill=\"none\" points=\"370.5,-3486.5 370.5,-3532.5 688.5,-3532.5 688.5,-3486.5 370.5,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-3505.8\">lambda_1: Lambda</text>\n<polyline fill=\"none\" points=\"498.5,-3486.5 498.5,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"527.5\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"498.5,-3509.5 556.5,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"527.5\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"556.5,-3486.5 556.5,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622.5\" y=\"-3517.3\">(None, 16, 16, 128)</text>\n<polyline fill=\"none\" points=\"556.5,-3509.5 688.5,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622.5\" y=\"-3494.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140178277813384&#45;&gt;140178277811424 -->\n<g class=\"edge\" id=\"edge23\">\n<title>140178277813384-&gt;140178277811424</title>\n<path d=\"M391.1448,-3652.3297C404.9151,-3641.7635 420.9627,-3628.7776 434.5,-3616 459.8548,-3592.0681 486.0398,-3562.267 504.4813,-3540.2802\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"507.2012,-3542.4834 510.9093,-3532.5587 501.8213,-3538.0048 507.2012,-3542.4834\" stroke=\"#000000\"/>\n</g>\n<!-- 140180013803896 -->\n<g class=\"node\" id=\"node17\">\n<title>140180013803896</title>\n<polygon fill=\"none\" points=\"28.5,-3486.5 28.5,-3532.5 352.5,-3532.5 352.5,-3486.5 28.5,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95.5\" y=\"-3505.8\">dropout_4: Dropout</text>\n<polyline fill=\"none\" points=\"162.5,-3486.5 162.5,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.5\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"162.5,-3509.5 220.5,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.5\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"220.5,-3486.5 220.5,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-3517.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"220.5,-3509.5 352.5,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-3494.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140178281502424&#45;&gt;140180013803896 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140178281502424-&gt;140180013803896</title>\n<path d=\"M243.8869,-3569.3799C235.8556,-3560.3718 226.5335,-3549.916 217.948,-3540.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"220.5265,-3537.919 211.2592,-3532.784 215.3016,-3542.5774 220.5265,-3537.919\" stroke=\"#000000\"/>\n</g>\n<!-- 140180013414104 -->\n<g class=\"node\" id=\"node18\">\n<title>140180013414104</title>\n<polygon fill=\"none\" points=\"0,-3403.5 0,-3449.5 461,-3449.5 461,-3403.5 0,-3403.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-3422.8\">batch_normalization_4: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-3403.5 271,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-3434.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-3426.5 329,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-3411.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-3403.5 329,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-3434.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"329,-3426.5 461,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-3411.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180013803896&#45;&gt;140180013414104 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140180013803896-&gt;140180013414104</title>\n<path d=\"M201.6422,-3486.3799C205.7256,-3477.907 210.4262,-3468.1531 214.8322,-3459.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"218.0903,-3460.312 219.2788,-3449.784 211.7844,-3457.2729 218.0903,-3460.312\" stroke=\"#000000\"/>\n</g>\n<!-- 140180013416176 -->\n<g class=\"node\" id=\"node19\">\n<title>140180013416176</title>\n<polygon fill=\"none\" points=\"78.5,-3320.5 78.5,-3366.5 422.5,-3366.5 422.5,-3320.5 78.5,-3320.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-3339.8\">activation_4: Activation</text>\n<polyline fill=\"none\" points=\"232.5,-3320.5 232.5,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.5\" y=\"-3351.3\">input:</text>\n<polyline fill=\"none\" points=\"232.5,-3343.5 290.5,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.5\" y=\"-3328.3\">output:</text>\n<polyline fill=\"none\" points=\"290.5,-3320.5 290.5,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356.5\" y=\"-3351.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"290.5,-3343.5 422.5,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356.5\" y=\"-3328.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180013414104&#45;&gt;140180013416176 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140180013414104-&gt;140180013416176</title>\n<path d=\"M236.0711,-3403.3799C238.0698,-3395.0854 240.3643,-3385.5633 242.5268,-3376.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"245.9493,-3377.3257 244.8894,-3366.784 239.1441,-3375.6858 245.9493,-3377.3257\" stroke=\"#000000\"/>\n</g>\n<!-- 140180013539224 -->\n<g class=\"node\" id=\"node20\">\n<title>140180013539224</title>\n<polygon fill=\"none\" points=\"99,-3237.5 99,-3283.5 422,-3283.5 422,-3237.5 99,-3237.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165.5\" y=\"-3256.8\">conv2d_5: Conv2D</text>\n<polyline fill=\"none\" points=\"232,-3237.5 232,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261\" y=\"-3268.3\">input:</text>\n<polyline fill=\"none\" points=\"232,-3260.5 290,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261\" y=\"-3245.3\">output:</text>\n<polyline fill=\"none\" points=\"290,-3237.5 290,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356\" y=\"-3268.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"290,-3260.5 422,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356\" y=\"-3245.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180013416176&#45;&gt;140180013539224 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140180013416176-&gt;140180013539224</title>\n<path d=\"M253.2856,-3320.3799C254.2742,-3312.1745 255.4075,-3302.7679 256.4785,-3293.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"259.9733,-3294.1309 257.6947,-3283.784 253.0236,-3293.2935 259.9733,-3294.1309\" stroke=\"#000000\"/>\n</g>\n<!-- 140180013348792 -->\n<g class=\"node\" id=\"node21\">\n<title>140180013348792</title>\n<polygon fill=\"none\" points=\"103.5,-3154.5 103.5,-3200.5 427.5,-3200.5 427.5,-3154.5 103.5,-3154.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-3173.8\">dropout_5: Dropout</text>\n<polyline fill=\"none\" points=\"237.5,-3154.5 237.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-3185.3\">input:</text>\n<polyline fill=\"none\" points=\"237.5,-3177.5 295.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-3162.3\">output:</text>\n<polyline fill=\"none\" points=\"295.5,-3154.5 295.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-3185.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"295.5,-3177.5 427.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-3162.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180013539224&#45;&gt;140180013348792 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140180013539224-&gt;140180013348792</title>\n<path d=\"M261.8928,-3237.3799C262.3871,-3229.1745 262.9537,-3219.7679 263.4892,-3210.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"266.9896,-3210.9764 264.0973,-3200.784 260.0023,-3210.5554 266.9896,-3210.9764\" stroke=\"#000000\"/>\n</g>\n<!-- 140180012955464 -->\n<g class=\"node\" id=\"node22\">\n<title>140180012955464</title>\n<polygon fill=\"none\" points=\"37,-3071.5 37,-3117.5 498,-3117.5 498,-3071.5 37,-3071.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-3090.8\">batch_normalization_5: BatchNormalization</text>\n<polyline fill=\"none\" points=\"308,-3071.5 308,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"337\" y=\"-3102.3\">input:</text>\n<polyline fill=\"none\" points=\"308,-3094.5 366,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"337\" y=\"-3079.3\">output:</text>\n<polyline fill=\"none\" points=\"366,-3071.5 366,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432\" y=\"-3102.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"366,-3094.5 498,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432\" y=\"-3079.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180013348792&#45;&gt;140180012955464 -->\n<g class=\"edge\" id=\"edge22\">\n<title>140180013348792-&gt;140180012955464</title>\n<path d=\"M266.0571,-3154.3799C266.2548,-3146.1745 266.4815,-3136.7679 266.6957,-3127.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"270.1969,-3127.8655 266.9389,-3117.784 263.199,-3127.6968 270.1969,-3127.8655\" stroke=\"#000000\"/>\n</g>\n<!-- 140180013085752 -->\n<g class=\"node\" id=\"node24\">\n<title>140180013085752</title>\n<polygon fill=\"none\" points=\"193,-2988.5 193,-3034.5 600,-3034.5 600,-2988.5 193,-2988.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-3007.8\">add_2: Add</text>\n<polyline fill=\"none\" points=\"278,-2988.5 278,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3019.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-3011.5 336,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2996.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-2988.5 336,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468\" y=\"-3019.3\">[(None, 16, 16, 256), (None, 16, 16, 256)]</text>\n<polyline fill=\"none\" points=\"336,-3011.5 600,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468\" y=\"-2996.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180012955464&#45;&gt;140180013085752 -->\n<g class=\"edge\" id=\"edge24\">\n<title>140180012955464-&gt;140180013085752</title>\n<path d=\"M303.4337,-3071.3799C318.4044,-3061.7475 335.9482,-3050.4597 351.7437,-3040.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"353.7957,-3043.1383 360.3116,-3034.784 350.0081,-3037.2515 353.7957,-3043.1383\" stroke=\"#000000\"/>\n</g>\n<!-- 140178277811424&#45;&gt;140180013085752 -->\n<g class=\"edge\" id=\"edge25\">\n<title>140178277811424-&gt;140180013085752</title>\n<path d=\"M529.0462,-3486.4063C528.4561,-3454.3403 527.5,-3394.5141 527.5,-3343.5 527.5,-3343.5 527.5,-3343.5 527.5,-3177.5 527.5,-3129.3393 535.9586,-3109.8531 507.5,-3071 498.031,-3058.0724 484.8861,-3047.6702 470.9463,-3039.4069\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"472.6299,-3036.3384 462.1897,-3034.5348 469.2265,-3042.4554 472.6299,-3036.3384\" stroke=\"#000000\"/>\n</g>\n<!-- 140180012488520 -->\n<g class=\"node\" id=\"node25\">\n<title>140180012488520</title>\n<polygon fill=\"none\" points=\"224.5,-2905.5 224.5,-2951.5 568.5,-2951.5 568.5,-2905.5 224.5,-2905.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-2924.8\">activation_5: Activation</text>\n<polyline fill=\"none\" points=\"378.5,-2905.5 378.5,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"407.5\" y=\"-2936.3\">input:</text>\n<polyline fill=\"none\" points=\"378.5,-2928.5 436.5,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"407.5\" y=\"-2913.3\">output:</text>\n<polyline fill=\"none\" points=\"436.5,-2905.5 436.5,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"502.5\" y=\"-2936.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"436.5,-2928.5 568.5,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"502.5\" y=\"-2913.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180013085752&#45;&gt;140180012488520 -->\n<g class=\"edge\" id=\"edge26\">\n<title>140180013085752-&gt;140180012488520</title>\n<path d=\"M396.5,-2988.3799C396.5,-2980.1745 396.5,-2970.7679 396.5,-2961.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"400.0001,-2961.784 396.5,-2951.784 393.0001,-2961.784 400.0001,-2961.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180012490312 -->\n<g class=\"node\" id=\"node26\">\n<title>140180012490312</title>\n<polygon fill=\"none\" points=\"140,-2822.5 140,-2868.5 463,-2868.5 463,-2822.5 140,-2822.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-2841.8\">conv2d_6: Conv2D</text>\n<polyline fill=\"none\" points=\"273,-2822.5 273,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302\" y=\"-2853.3\">input:</text>\n<polyline fill=\"none\" points=\"273,-2845.5 331,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302\" y=\"-2830.3\">output:</text>\n<polyline fill=\"none\" points=\"331,-2822.5 331,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397\" y=\"-2853.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"331,-2845.5 463,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397\" y=\"-2830.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180012488520&#45;&gt;140180012490312 -->\n<g class=\"edge\" id=\"edge27\">\n<title>140180012488520-&gt;140180012490312</title>\n<path d=\"M370.0372,-2905.3799C359.4206,-2896.1043 347.0468,-2885.2936 335.7577,-2875.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"337.9839,-2872.7277 328.1504,-2868.784 333.3783,-2877.9992 337.9839,-2872.7277\" stroke=\"#000000\"/>\n</g>\n<!-- 140180010962448 -->\n<g class=\"node\" id=\"node33\">\n<title>140180010962448</title>\n<polygon fill=\"none\" points=\"175,-2241.5 175,-2287.5 582,-2287.5 582,-2241.5 175,-2241.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-2260.8\">add_3: Add</text>\n<polyline fill=\"none\" points=\"260,-2241.5 260,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-2272.3\">input:</text>\n<polyline fill=\"none\" points=\"260,-2264.5 318,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-2249.3\">output:</text>\n<polyline fill=\"none\" points=\"318,-2241.5 318,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450\" y=\"-2272.3\">[(None, 16, 16, 256), (None, 16, 16, 256)]</text>\n<polyline fill=\"none\" points=\"318,-2264.5 582,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450\" y=\"-2249.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180012488520&#45;&gt;140180010962448 -->\n<g class=\"edge\" id=\"edge35\">\n<title>140180012488520-&gt;140180010962448</title>\n<path d=\"M433.842,-2905.3889C447.2413,-2895.5587 461.4952,-2883.0959 471.5,-2869 500.5027,-2828.1379 508.5,-2812.6085 508.5,-2762.5 508.5,-2762.5 508.5,-2762.5 508.5,-2430.5 508.5,-2382.4193 517.7348,-2362.9172 489.5,-2324 480.2312,-2311.2245 467.3637,-2300.9228 453.6639,-2292.7156\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"455.0051,-2289.4552 444.5705,-2287.6199 451.5831,-2295.5618 455.0051,-2289.4552\" stroke=\"#000000\"/>\n</g>\n<!-- 140180011951048 -->\n<g class=\"node\" id=\"node27\">\n<title>140180011951048</title>\n<polygon fill=\"none\" points=\"122.5,-2739.5 122.5,-2785.5 446.5,-2785.5 446.5,-2739.5 122.5,-2739.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189.5\" y=\"-2758.8\">dropout_6: Dropout</text>\n<polyline fill=\"none\" points=\"256.5,-2739.5 256.5,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-2770.3\">input:</text>\n<polyline fill=\"none\" points=\"256.5,-2762.5 314.5,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-2747.3\">output:</text>\n<polyline fill=\"none\" points=\"314.5,-2739.5 314.5,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380.5\" y=\"-2770.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"314.5,-2762.5 446.5,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380.5\" y=\"-2747.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180012490312&#45;&gt;140180011951048 -->\n<g class=\"edge\" id=\"edge28\">\n<title>140180012490312-&gt;140180011951048</title>\n<path d=\"M296.7646,-2822.3799C295.0657,-2814.0854 293.1154,-2804.5633 291.2773,-2795.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"294.7044,-2794.8783 289.269,-2785.784 287.8468,-2796.2829 294.7044,-2794.8783\" stroke=\"#000000\"/>\n</g>\n<!-- 140180011952616 -->\n<g class=\"node\" id=\"node28\">\n<title>140180011952616</title>\n<polygon fill=\"none\" points=\"19,-2656.5 19,-2702.5 480,-2702.5 480,-2656.5 19,-2656.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-2675.8\">batch_normalization_6: BatchNormalization</text>\n<polyline fill=\"none\" points=\"290,-2656.5 290,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-2687.3\">input:</text>\n<polyline fill=\"none\" points=\"290,-2679.5 348,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-2664.3\">output:</text>\n<polyline fill=\"none\" points=\"348,-2656.5 348,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-2687.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"348,-2679.5 480,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-2664.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180011951048&#45;&gt;140180011952616 -->\n<g class=\"edge\" id=\"edge29\">\n<title>140180011951048-&gt;140180011952616</title>\n<path d=\"M274.7505,-2739.3799C271.1776,-2730.907 267.0646,-2721.1531 263.2093,-2712.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"266.4291,-2710.6383 259.3186,-2702.784 259.9792,-2713.3582 266.4291,-2710.6383\" stroke=\"#000000\"/>\n</g>\n<!-- 140180011773232 -->\n<g class=\"node\" id=\"node29\">\n<title>140180011773232</title>\n<polygon fill=\"none\" points=\"77.5,-2573.5 77.5,-2619.5 421.5,-2619.5 421.5,-2573.5 77.5,-2573.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-2592.8\">activation_6: Activation</text>\n<polyline fill=\"none\" points=\"231.5,-2573.5 231.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.5\" y=\"-2604.3\">input:</text>\n<polyline fill=\"none\" points=\"231.5,-2596.5 289.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.5\" y=\"-2581.3\">output:</text>\n<polyline fill=\"none\" points=\"289.5,-2573.5 289.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-2604.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"289.5,-2596.5 421.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-2581.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180011952616&#45;&gt;140180011773232 -->\n<g class=\"edge\" id=\"edge30\">\n<title>140180011952616-&gt;140180011773232</title>\n<path d=\"M249.5,-2656.3799C249.5,-2648.1745 249.5,-2638.7679 249.5,-2629.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"253.0001,-2629.784 249.5,-2619.784 246.0001,-2629.784 253.0001,-2629.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180011514568 -->\n<g class=\"node\" id=\"node30\">\n<title>140180011514568</title>\n<polygon fill=\"none\" points=\"88,-2490.5 88,-2536.5 411,-2536.5 411,-2490.5 88,-2490.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-2509.8\">conv2d_7: Conv2D</text>\n<polyline fill=\"none\" points=\"221,-2490.5 221,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-2521.3\">input:</text>\n<polyline fill=\"none\" points=\"221,-2513.5 279,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-2498.3\">output:</text>\n<polyline fill=\"none\" points=\"279,-2490.5 279,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-2521.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"279,-2513.5 411,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-2498.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180011773232&#45;&gt;140180011514568 -->\n<g class=\"edge\" id=\"edge31\">\n<title>140180011773232-&gt;140180011514568</title>\n<path d=\"M249.5,-2573.3799C249.5,-2565.1745 249.5,-2555.7679 249.5,-2546.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"253.0001,-2546.784 249.5,-2536.784 246.0001,-2546.784 253.0001,-2546.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180011216736 -->\n<g class=\"node\" id=\"node31\">\n<title>140180011216736</title>\n<polygon fill=\"none\" points=\"87.5,-2407.5 87.5,-2453.5 411.5,-2453.5 411.5,-2407.5 87.5,-2407.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-2426.8\">dropout_7: Dropout</text>\n<polyline fill=\"none\" points=\"221.5,-2407.5 221.5,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-2438.3\">input:</text>\n<polyline fill=\"none\" points=\"221.5,-2430.5 279.5,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-2415.3\">output:</text>\n<polyline fill=\"none\" points=\"279.5,-2407.5 279.5,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-2438.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"279.5,-2430.5 411.5,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-2415.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180011514568&#45;&gt;140180011216736 -->\n<g class=\"edge\" id=\"edge32\">\n<title>140180011514568-&gt;140180011216736</title>\n<path d=\"M249.5,-2490.3799C249.5,-2482.1745 249.5,-2472.7679 249.5,-2463.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"253.0001,-2463.784 249.5,-2453.784 246.0001,-2463.784 253.0001,-2463.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180010962056 -->\n<g class=\"node\" id=\"node32\">\n<title>140180010962056</title>\n<polygon fill=\"none\" points=\"19,-2324.5 19,-2370.5 480,-2370.5 480,-2324.5 19,-2324.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-2343.8\">batch_normalization_7: BatchNormalization</text>\n<polyline fill=\"none\" points=\"290,-2324.5 290,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-2355.3\">input:</text>\n<polyline fill=\"none\" points=\"290,-2347.5 348,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-2332.3\">output:</text>\n<polyline fill=\"none\" points=\"348,-2324.5 348,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-2355.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"348,-2347.5 480,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-2332.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180011216736&#45;&gt;140180010962056 -->\n<g class=\"edge\" id=\"edge33\">\n<title>140180011216736-&gt;140180010962056</title>\n<path d=\"M249.5,-2407.3799C249.5,-2399.1745 249.5,-2389.7679 249.5,-2380.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"253.0001,-2380.784 249.5,-2370.784 246.0001,-2380.784 253.0001,-2380.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180010962056&#45;&gt;140180010962448 -->\n<g class=\"edge\" id=\"edge34\">\n<title>140180010962056-&gt;140180010962448</title>\n<path d=\"M285.4337,-2324.3799C300.4044,-2314.7475 317.9482,-2303.4597 333.7437,-2293.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"335.7957,-2296.1383 342.3116,-2287.784 332.0081,-2290.2515 335.7957,-2296.1383\" stroke=\"#000000\"/>\n</g>\n<!-- 140180010010608 -->\n<g class=\"node\" id=\"node34\">\n<title>140180010010608</title>\n<polygon fill=\"none\" points=\"206.5,-2158.5 206.5,-2204.5 550.5,-2204.5 550.5,-2158.5 206.5,-2158.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-2177.8\">activation_7: Activation</text>\n<polyline fill=\"none\" points=\"360.5,-2158.5 360.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"389.5\" y=\"-2189.3\">input:</text>\n<polyline fill=\"none\" points=\"360.5,-2181.5 418.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"389.5\" y=\"-2166.3\">output:</text>\n<polyline fill=\"none\" points=\"418.5,-2158.5 418.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"484.5\" y=\"-2189.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"418.5,-2181.5 550.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"484.5\" y=\"-2166.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140180010962448&#45;&gt;140180010010608 -->\n<g class=\"edge\" id=\"edge36\">\n<title>140180010962448-&gt;140180010010608</title>\n<path d=\"M378.5,-2241.3799C378.5,-2233.1745 378.5,-2223.7679 378.5,-2214.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"382.0001,-2214.784 378.5,-2204.784 375.0001,-2214.784 382.0001,-2214.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180010010216 -->\n<g class=\"node\" id=\"node35\">\n<title>140180010010216</title>\n<polygon fill=\"none\" points=\"173,-2075.5 173,-2121.5 584,-2121.5 584,-2075.5 173,-2075.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-2094.8\">max_pooling2d_2: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"394,-2075.5 394,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423\" y=\"-2106.3\">input:</text>\n<polyline fill=\"none\" points=\"394,-2098.5 452,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423\" y=\"-2083.3\">output:</text>\n<polyline fill=\"none\" points=\"452,-2075.5 452,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-2106.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"452,-2098.5 584,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-2083.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140180010010608&#45;&gt;140180010010216 -->\n<g class=\"edge\" id=\"edge37\">\n<title>140180010010608-&gt;140180010010216</title>\n<path d=\"M378.5,-2158.3799C378.5,-2150.1745 378.5,-2140.7679 378.5,-2131.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"382.0001,-2131.784 378.5,-2121.784 375.0001,-2131.784 382.0001,-2131.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009718168 -->\n<g class=\"node\" id=\"node36\">\n<title>140180009718168</title>\n<polygon fill=\"none\" points=\"224,-1992.5 224,-2038.5 533,-2038.5 533,-1992.5 224,-1992.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291\" y=\"-2011.8\">dropout_8: Dropout</text>\n<polyline fill=\"none\" points=\"358,-1992.5 358,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387\" y=\"-2023.3\">input:</text>\n<polyline fill=\"none\" points=\"358,-2015.5 416,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387\" y=\"-2000.3\">output:</text>\n<polyline fill=\"none\" points=\"416,-1992.5 416,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"474.5\" y=\"-2023.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"416,-2015.5 533,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"474.5\" y=\"-2000.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140180010010216&#45;&gt;140180009718168 -->\n<g class=\"edge\" id=\"edge38\">\n<title>140180010010216-&gt;140180009718168</title>\n<path d=\"M378.5,-2075.3799C378.5,-2067.1745 378.5,-2057.7679 378.5,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"382.0001,-2048.784 378.5,-2038.784 375.0001,-2048.784 382.0001,-2048.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009233488 -->\n<g class=\"node\" id=\"node37\">\n<title>140180009233488</title>\n<polygon fill=\"none\" points=\"133.5,-1909.5 133.5,-1955.5 441.5,-1955.5 441.5,-1909.5 133.5,-1909.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-1928.8\">conv2d_8: Conv2D</text>\n<polyline fill=\"none\" points=\"266.5,-1909.5 266.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-1940.3\">input:</text>\n<polyline fill=\"none\" points=\"266.5,-1932.5 324.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-1917.3\">output:</text>\n<polyline fill=\"none\" points=\"324.5,-1909.5 324.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383\" y=\"-1940.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"324.5,-1932.5 441.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383\" y=\"-1917.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180009718168&#45;&gt;140180009233488 -->\n<g class=\"edge\" id=\"edge39\">\n<title>140180009718168-&gt;140180009233488</title>\n<path d=\"M353.1514,-1992.3799C343.0796,-1983.1935 331.3569,-1972.5013 320.6275,-1962.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"322.7752,-1959.9369 313.0282,-1955.784 318.058,-1965.1088 322.7752,-1959.9369\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009721416 -->\n<g class=\"node\" id=\"node44\">\n<title>140180009721416</title>\n<polygon fill=\"none\" points=\"389,-1826.5 389,-1872.5 692,-1872.5 692,-1826.5 389,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-1845.8\">lambda_2: Lambda</text>\n<polyline fill=\"none\" points=\"517,-1826.5 517,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"517,-1849.5 575,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"575,-1826.5 575,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"633.5\" y=\"-1857.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"575,-1849.5 692,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"633.5\" y=\"-1834.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180009718168&#45;&gt;140180009721416 -->\n<g class=\"edge\" id=\"edge46\">\n<title>140180009718168-&gt;140180009721416</title>\n<path d=\"M408.9578,-1992.3239C422.1919,-1981.7566 437.5872,-1968.7715 450.5,-1956 474.6132,-1932.1506 499.289,-1902.508 516.6896,-1880.5561\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"519.5568,-1882.5721 522.986,-1872.5475 514.0539,-1878.2456 519.5568,-1882.5721\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009412088 -->\n<g class=\"node\" id=\"node38\">\n<title>140180009412088</title>\n<polygon fill=\"none\" points=\"62,-1826.5 62,-1872.5 371,-1872.5 371,-1826.5 62,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129\" y=\"-1845.8\">dropout_9: Dropout</text>\n<polyline fill=\"none\" points=\"196,-1826.5 196,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-1849.5 254,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-1826.5 254,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-1857.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"254,-1849.5 371,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-1834.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180009233488&#45;&gt;140180009412088 -->\n<g class=\"edge\" id=\"edge40\">\n<title>140180009233488-&gt;140180009412088</title>\n<path d=\"M267.7225,-1909.3799C260.0932,-1900.461 251.2497,-1890.1229 243.0801,-1880.5725\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"245.5777,-1878.1079 236.4176,-1872.784 240.2584,-1882.6582 245.5777,-1878.1079\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009413600 -->\n<g class=\"node\" id=\"node39\">\n<title>140180009413600</title>\n<polygon fill=\"none\" points=\"29.5,-1743.5 29.5,-1789.5 475.5,-1789.5 475.5,-1743.5 29.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-1762.8\">batch_normalization_8: BatchNormalization</text>\n<polyline fill=\"none\" points=\"300.5,-1743.5 300.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"300.5,-1766.5 358.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"358.5,-1743.5 358.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-1774.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"358.5,-1766.5 475.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-1751.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180009412088&#45;&gt;140180009413600 -->\n<g class=\"edge\" id=\"edge41\">\n<title>140180009412088-&gt;140180009413600</title>\n<path d=\"M226.528,-1826.3799C230.203,-1817.907 234.4336,-1808.1531 238.399,-1799.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"241.6327,-1800.351 242.4009,-1789.784 235.2107,-1797.5655 241.6327,-1800.351\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009142144 -->\n<g class=\"node\" id=\"node40\">\n<title>140180009142144</title>\n<polygon fill=\"none\" points=\"106,-1660.5 106,-1706.5 435,-1706.5 435,-1660.5 106,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-1679.8\">activation_8: Activation</text>\n<polyline fill=\"none\" points=\"260,-1660.5 260,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"260,-1683.5 318,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"318,-1660.5 318,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-1691.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"318,-1683.5 435,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-1668.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180009413600&#45;&gt;140180009142144 -->\n<g class=\"edge\" id=\"edge42\">\n<title>140180009413600-&gt;140180009142144</title>\n<path d=\"M257.514,-1743.3799C259.3128,-1735.0854 261.3778,-1725.5633 263.3241,-1716.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"266.7515,-1717.2987 265.4505,-1706.784 259.9105,-1715.815 266.7515,-1717.2987\" stroke=\"#000000\"/>\n</g>\n<!-- 140180008718968 -->\n<g class=\"node\" id=\"node41\">\n<title>140180008718968</title>\n<polygon fill=\"none\" points=\"125.5,-1577.5 125.5,-1623.5 433.5,-1623.5 433.5,-1577.5 125.5,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-1596.8\">conv2d_9: Conv2D</text>\n<polyline fill=\"none\" points=\"258.5,-1577.5 258.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"258.5,-1600.5 316.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"316.5,-1577.5 316.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-1608.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"316.5,-1600.5 433.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-1585.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180009142144&#45;&gt;140180008718968 -->\n<g class=\"edge\" id=\"edge43\">\n<title>140180009142144-&gt;140180008718968</title>\n<path d=\"M273.007,-1660.3799C273.8967,-1652.1745 274.9167,-1642.7679 275.8806,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"279.3767,-1634.1031 276.9752,-1623.784 272.4175,-1633.3484 279.3767,-1634.1031\" stroke=\"#000000\"/>\n</g>\n<!-- 140180008440104 -->\n<g class=\"node\" id=\"node42\">\n<title>140180008440104</title>\n<polygon fill=\"none\" points=\"126.5,-1494.5 126.5,-1540.5 442.5,-1540.5 442.5,-1494.5 126.5,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197\" y=\"-1513.8\">dropout_10: Dropout</text>\n<polyline fill=\"none\" points=\"267.5,-1494.5 267.5,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"267.5,-1517.5 325.5,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"325.5,-1494.5 325.5,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384\" y=\"-1525.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"325.5,-1517.5 442.5,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384\" y=\"-1502.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180008718968&#45;&gt;140180008440104 -->\n<g class=\"edge\" id=\"edge44\">\n<title>140180008718968-&gt;140180008440104</title>\n<path d=\"M280.8928,-1577.3799C281.3871,-1569.1745 281.9537,-1559.7679 282.4892,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"285.9896,-1550.9764 283.0973,-1540.784 279.0023,-1550.5554 285.9896,-1550.9764\" stroke=\"#000000\"/>\n</g>\n<!-- 140180008550128 -->\n<g class=\"node\" id=\"node43\">\n<title>140180008550128</title>\n<polygon fill=\"none\" points=\"63.5,-1411.5 63.5,-1457.5 509.5,-1457.5 509.5,-1411.5 63.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199\" y=\"-1430.8\">batch_normalization_9: BatchNormalization</text>\n<polyline fill=\"none\" points=\"334.5,-1411.5 334.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"334.5,-1434.5 392.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"392.5,-1411.5 392.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-1442.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"392.5,-1434.5 509.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-1419.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180008440104&#45;&gt;140180008550128 -->\n<g class=\"edge\" id=\"edge45\">\n<title>140180008440104-&gt;140180008550128</title>\n<path d=\"M285.0571,-1494.3799C285.2548,-1486.1745 285.4815,-1476.7679 285.6957,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"289.1969,-1467.8655 285.9389,-1457.784 282.199,-1467.6968 289.1969,-1467.8655\" stroke=\"#000000\"/>\n</g>\n<!-- 140180008171896 -->\n<g class=\"node\" id=\"node45\">\n<title>140180008171896</title>\n<polygon fill=\"none\" points=\"223,-1328.5 223,-1374.5 600,-1374.5 600,-1328.5 223,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-1347.8\">add_4: Add</text>\n<polyline fill=\"none\" points=\"308,-1328.5 308,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"337\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"308,-1351.5 366,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"337\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"366,-1328.5 366,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"483\" y=\"-1359.3\">[(None, 8, 8, 512), (None, 8, 8, 512)]</text>\n<polyline fill=\"none\" points=\"366,-1351.5 600,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"483\" y=\"-1336.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180008550128&#45;&gt;140180008171896 -->\n<g class=\"edge\" id=\"edge47\">\n<title>140180008550128-&gt;140180008171896</title>\n<path d=\"M321.3195,-1411.3799C335.6917,-1401.8367 352.5112,-1390.6686 367.7059,-1380.5793\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"370.039,-1383.2314 376.4337,-1374.784 366.1669,-1377.3999 370.039,-1383.2314\" stroke=\"#000000\"/>\n</g>\n<!-- 140180009721416&#45;&gt;140180008171896 -->\n<g class=\"edge\" id=\"edge48\">\n<title>140180009721416-&gt;140180008171896</title>\n<path d=\"M540.0462,-1826.4063C539.4561,-1794.3403 538.5,-1734.5141 538.5,-1683.5 538.5,-1683.5 538.5,-1683.5 538.5,-1517.5 538.5,-1469.3393 546.6579,-1450.0716 518.5,-1411 509.3252,-1398.2691 496.5432,-1387.9326 482.9975,-1379.6683\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"484.4344,-1376.4581 474.016,-1374.5323 480.9595,-1382.5348 484.4344,-1376.4581\" stroke=\"#000000\"/>\n</g>\n<!-- 140180008102264 -->\n<g class=\"node\" id=\"node46\">\n<title>140180008102264</title>\n<polygon fill=\"none\" points=\"247,-1245.5 247,-1291.5 576,-1291.5 576,-1245.5 247,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324\" y=\"-1264.8\">activation_9: Activation</text>\n<polyline fill=\"none\" points=\"401,-1245.5 401,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"430\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"401,-1268.5 459,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"430\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"459,-1245.5 459,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517.5\" y=\"-1276.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"459,-1268.5 576,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517.5\" y=\"-1253.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180008171896&#45;&gt;140180008102264 -->\n<g class=\"edge\" id=\"edge49\">\n<title>140180008171896-&gt;140180008102264</title>\n<path d=\"M411.5,-1328.3799C411.5,-1320.1745 411.5,-1310.7679 411.5,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"415.0001,-1301.784 411.5,-1291.784 408.0001,-1301.784 415.0001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180007418736 -->\n<g class=\"node\" id=\"node47\">\n<title>140180007418736</title>\n<polygon fill=\"none\" points=\"161,-1162.5 161,-1208.5 476,-1208.5 476,-1162.5 161,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-1181.8\">conv2d_10: Conv2D</text>\n<polyline fill=\"none\" points=\"301,-1162.5 301,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"301,-1185.5 359,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"359,-1162.5 359,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-1193.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"359,-1185.5 476,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-1170.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180008102264&#45;&gt;140180007418736 -->\n<g class=\"edge\" id=\"edge50\">\n<title>140180008102264-&gt;140180007418736</title>\n<path d=\"M385.5943,-1245.3799C375.3011,-1236.1935 363.3208,-1225.5013 352.3556,-1215.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"354.3806,-1212.8313 344.5893,-1208.784 349.7196,-1218.0539 354.3806,-1212.8313\" stroke=\"#000000\"/>\n</g>\n<!-- 140180006551168 -->\n<g class=\"node\" id=\"node54\">\n<title>140180006551168</title>\n<polygon fill=\"none\" points=\"206,-581.5 206,-627.5 583,-627.5 583,-581.5 206,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-600.8\">add_5: Add</text>\n<polyline fill=\"none\" points=\"291,-581.5 291,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"291,-604.5 349,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"349,-581.5 349,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466\" y=\"-612.3\">[(None, 8, 8, 512), (None, 8, 8, 512)]</text>\n<polyline fill=\"none\" points=\"349,-604.5 583,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466\" y=\"-589.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180008102264&#45;&gt;140180006551168 -->\n<g class=\"edge\" id=\"edge58\">\n<title>140180008102264-&gt;140180006551168</title>\n<path d=\"M447.4574,-1245.498C460.6065,-1235.6019 474.656,-1223.065 484.5,-1209 513.2324,-1167.9474 521.5,-1152.6085 521.5,-1102.5 521.5,-1102.5 521.5,-1102.5 521.5,-770.5 521.5,-722.4193 530.5107,-703.0788 502.5,-664 493.3438,-651.2258 480.5566,-640.8849 466.9742,-632.6322\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"468.3865,-629.4089 457.9639,-627.5059 464.9249,-635.4931 468.3865,-629.4089\" stroke=\"#000000\"/>\n</g>\n<!-- 140180007149864 -->\n<g class=\"node\" id=\"node48\">\n<title>140180007149864</title>\n<polygon fill=\"none\" points=\"144,-1079.5 144,-1125.5 459,-1125.5 459,-1079.5 144,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-1098.8\">dropout_11: Dropout</text>\n<polyline fill=\"none\" points=\"284,-1079.5 284,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"284,-1102.5 342,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"342,-1079.5 342,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400.5\" y=\"-1110.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"342,-1102.5 459,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400.5\" y=\"-1087.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180007418736&#45;&gt;140180007149864 -->\n<g class=\"edge\" id=\"edge51\">\n<title>140180007418736-&gt;140180007149864</title>\n<path d=\"M313.7646,-1162.3799C312.0657,-1154.0854 310.1154,-1144.5633 308.2773,-1135.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"311.7044,-1134.8783 306.269,-1125.784 304.8468,-1136.2829 311.7044,-1134.8783\" stroke=\"#000000\"/>\n</g>\n<!-- 140180007150032 -->\n<g class=\"node\" id=\"node49\">\n<title>140180007150032</title>\n<polygon fill=\"none\" points=\"41,-996.5 41,-1042.5 494,-1042.5 494,-996.5 41,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-1015.8\">batch_normalization_10: BatchNormalization</text>\n<polyline fill=\"none\" points=\"319,-996.5 319,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"319,-1019.5 377,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"377,-996.5 377,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-1027.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"377,-1019.5 494,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-1004.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180007149864&#45;&gt;140180007150032 -->\n<g class=\"edge\" id=\"edge52\">\n<title>140180007149864-&gt;140180007150032</title>\n<path d=\"M292.0291,-1079.3799C288.5948,-1070.9962 284.6468,-1061.3584 280.936,-1052.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"284.0676,-1050.7109 277.038,-1042.784 277.59,-1053.3645 284.0676,-1050.7109\" stroke=\"#000000\"/>\n</g>\n<!-- 140180006979288 -->\n<g class=\"node\" id=\"node50\">\n<title>140180006979288</title>\n<polygon fill=\"none\" points=\"99.5,-913.5 99.5,-959.5 435.5,-959.5 435.5,-913.5 99.5,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-932.8\">activation_10: Activation</text>\n<polyline fill=\"none\" points=\"260.5,-913.5 260.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"260.5,-936.5 318.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"318.5,-913.5 318.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"377\" y=\"-944.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"318.5,-936.5 435.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"377\" y=\"-921.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180007150032&#45;&gt;140180006979288 -->\n<g class=\"edge\" id=\"edge53\">\n<title>140180007150032-&gt;140180006979288</title>\n<path d=\"M267.5,-996.3799C267.5,-988.1745 267.5,-978.7679 267.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.0001,-969.784 267.5,-959.784 264.0001,-969.784 271.0001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180006407752 -->\n<g class=\"node\" id=\"node51\">\n<title>140180006407752</title>\n<polygon fill=\"none\" points=\"110,-830.5 110,-876.5 425,-876.5 425,-830.5 110,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-849.8\">conv2d_11: Conv2D</text>\n<polyline fill=\"none\" points=\"250,-830.5 250,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"250,-853.5 308,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"308,-830.5 308,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366.5\" y=\"-861.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"308,-853.5 425,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366.5\" y=\"-838.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180006979288&#45;&gt;140180006407752 -->\n<g class=\"edge\" id=\"edge54\">\n<title>140180006979288-&gt;140180006407752</title>\n<path d=\"M267.5,-913.3799C267.5,-905.1745 267.5,-895.7679 267.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.0001,-886.784 267.5,-876.784 264.0001,-886.784 271.0001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180006800800 -->\n<g class=\"node\" id=\"node52\">\n<title>140180006800800</title>\n<polygon fill=\"none\" points=\"109.5,-747.5 109.5,-793.5 425.5,-793.5 425.5,-747.5 109.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-766.8\">dropout_12: Dropout</text>\n<polyline fill=\"none\" points=\"250.5,-747.5 250.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"250.5,-770.5 308.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"308.5,-747.5 308.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367\" y=\"-778.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"308.5,-770.5 425.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367\" y=\"-755.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180006407752&#45;&gt;140180006800800 -->\n<g class=\"edge\" id=\"edge55\">\n<title>140180006407752-&gt;140180006800800</title>\n<path d=\"M267.5,-830.3799C267.5,-822.1745 267.5,-812.7679 267.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.0001,-803.784 267.5,-793.784 264.0001,-803.784 271.0001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180006548536 -->\n<g class=\"node\" id=\"node53\">\n<title>140180006548536</title>\n<polygon fill=\"none\" points=\"41,-664.5 41,-710.5 494,-710.5 494,-664.5 41,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-683.8\">batch_normalization_11: BatchNormalization</text>\n<polyline fill=\"none\" points=\"319,-664.5 319,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"319,-687.5 377,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"377,-664.5 377,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-695.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"377,-687.5 494,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-672.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180006800800&#45;&gt;140180006548536 -->\n<g class=\"edge\" id=\"edge56\">\n<title>140180006800800-&gt;140180006548536</title>\n<path d=\"M267.5,-747.3799C267.5,-739.1745 267.5,-729.7679 267.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.0001,-720.784 267.5,-710.784 264.0001,-720.784 271.0001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180006548536&#45;&gt;140180006551168 -->\n<g class=\"edge\" id=\"edge57\">\n<title>140180006548536-&gt;140180006551168</title>\n<path d=\"M302.8766,-664.3799C317.6152,-654.7475 334.887,-643.4597 350.4375,-633.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"352.4166,-636.1846 358.8727,-627.784 348.587,-630.325 352.4166,-636.1846\" stroke=\"#000000\"/>\n</g>\n<!-- 140180005585976 -->\n<g class=\"node\" id=\"node55\">\n<title>140180005585976</title>\n<polygon fill=\"none\" points=\"226.5,-498.5 226.5,-544.5 562.5,-544.5 562.5,-498.5 226.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-517.8\">activation_11: Activation</text>\n<polyline fill=\"none\" points=\"387.5,-498.5 387.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"387.5,-521.5 445.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"445.5,-498.5 445.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-529.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"445.5,-521.5 562.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-506.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140180006551168&#45;&gt;140180005585976 -->\n<g class=\"edge\" id=\"edge59\">\n<title>140180006551168-&gt;140180005585976</title>\n<path d=\"M394.5,-581.3799C394.5,-573.1745 394.5,-563.7679 394.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-554.784 394.5,-544.784 391.0001,-554.784 398.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140180005588384 -->\n<g class=\"node\" id=\"node56\">\n<title>140180005588384</title>\n<polygon fill=\"none\" points=\"250.5,-415.5 250.5,-461.5 538.5,-461.5 538.5,-415.5 250.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-434.8\">flatten_1: Flatten</text>\n<polyline fill=\"none\" points=\"363.5,-415.5 363.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"363.5,-438.5 421.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"421.5,-415.5 421.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-446.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"421.5,-438.5 538.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-423.3\">(None, 32768)</text>\n</g>\n<!-- 140180005585976&#45;&gt;140180005588384 -->\n<g class=\"edge\" id=\"edge60\">\n<title>140180005585976-&gt;140180005588384</title>\n<path d=\"M394.5,-498.3799C394.5,-490.1745 394.5,-480.7679 394.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-471.784 394.5,-461.784 391.0001,-471.784 398.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178260577808 -->\n<g class=\"node\" id=\"node57\">\n<title>140178260577808</title>\n<polygon fill=\"none\" points=\"261,-332.5 261,-378.5 528,-378.5 528,-332.5 261,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-351.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"368,-332.5 368,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"368,-355.5 426,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"426,-332.5 426,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477\" y=\"-363.3\">(None, 32768)</text>\n<polyline fill=\"none\" points=\"426,-355.5 528,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477\" y=\"-340.3\">(None, 512)</text>\n</g>\n<!-- 140180005588384&#45;&gt;140178260577808 -->\n<g class=\"edge\" id=\"edge61\">\n<title>140180005588384-&gt;140178260577808</title>\n<path d=\"M394.5,-415.3799C394.5,-407.1745 394.5,-397.7679 394.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-388.784 394.5,-378.784 391.0001,-388.784 398.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178260242160 -->\n<g class=\"node\" id=\"node58\">\n<title>140178260242160</title>\n<polygon fill=\"none\" points=\"183,-249.5 183,-295.5 606,-295.5 606,-249.5 183,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-268.8\">batch_normalization_12: BatchNormalization</text>\n<polyline fill=\"none\" points=\"461,-249.5 461,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"461,-272.5 519,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"519,-249.5 519,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-280.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"519,-272.5 606,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-257.3\">(None, 512)</text>\n</g>\n<!-- 140178260577808&#45;&gt;140178260242160 -->\n<g class=\"edge\" id=\"edge62\">\n<title>140178260577808-&gt;140178260242160</title>\n<path d=\"M394.5,-332.3799C394.5,-324.1745 394.5,-314.7679 394.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-305.784 394.5,-295.784 391.0001,-305.784 398.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178260242384 -->\n<g class=\"node\" id=\"node59\">\n<title>140178260242384</title>\n<polygon fill=\"none\" points=\"241.5,-166.5 241.5,-212.5 547.5,-212.5 547.5,-166.5 241.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-185.8\">activation_12: Activation</text>\n<polyline fill=\"none\" points=\"402.5,-166.5 402.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"402.5,-189.5 460.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"460.5,-166.5 460.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-197.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"460.5,-189.5 547.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-174.3\">(None, 512)</text>\n</g>\n<!-- 140178260242160&#45;&gt;140178260242384 -->\n<g class=\"edge\" id=\"edge63\">\n<title>140178260242160-&gt;140178260242384</title>\n<path d=\"M394.5,-249.3799C394.5,-241.1745 394.5,-231.7679 394.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-222.784 394.5,-212.784 391.0001,-222.784 398.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140181529658088 -->\n<g class=\"node\" id=\"node60\">\n<title>140181529658088</title>\n<polygon fill=\"none\" points=\"251.5,-83.5 251.5,-129.5 537.5,-129.5 537.5,-83.5 251.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-102.8\">dropout_13: Dropout</text>\n<polyline fill=\"none\" points=\"392.5,-83.5 392.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"392.5,-106.5 450.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"450.5,-83.5 450.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-114.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"450.5,-106.5 537.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-91.3\">(None, 512)</text>\n</g>\n<!-- 140178260242384&#45;&gt;140181529658088 -->\n<g class=\"edge\" id=\"edge64\">\n<title>140178260242384-&gt;140181529658088</title>\n<path d=\"M394.5,-166.3799C394.5,-158.1745 394.5,-148.7679 394.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-139.784 394.5,-129.784 391.0001,-139.784 398.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140178259974408 -->\n<g class=\"node\" id=\"node61\">\n<title>140178259974408</title>\n<polygon fill=\"none\" points=\"268.5,-.5 268.5,-46.5 520.5,-46.5 520.5,-.5 268.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-19.8\">dense_3: Dense</text>\n<polyline fill=\"none\" points=\"375.5,-.5 375.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"404.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"375.5,-23.5 433.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"404.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"433.5,-.5 433.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477\" y=\"-31.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"433.5,-23.5 520.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140181529658088&#45;&gt;140178259974408 -->\n<g class=\"edge\" id=\"edge65\">\n<title>140181529658088-&gt;140178259974408</title>\n<path d=\"M394.5,-83.3799C394.5,-75.1745 394.5,-65.7679 394.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.0001,-56.784 394.5,-46.784 391.0001,-56.784 398.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYsY7PPlgWrE",
        "colab_type": "code",
        "outputId": "efa38a59-2bca-40a7-d32e-794343c9462c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "#法2\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=5,\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath= os.path.join(tempfile.gettempdir(), 'saved_ResNet_wt.h5'),\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 128, validation_split = 0.2, epochs = 40, callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "40000/40000 [==============================] - 149s 4ms/step - loss: 1.5710 - acc: 0.4673 - val_loss: 2.0727 - val_acc: 0.3919\n",
            "Epoch 2/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 1.0149 - acc: 0.6454 - val_loss: 1.2430 - val_acc: 0.5974\n",
            "Epoch 3/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.7908 - acc: 0.7215 - val_loss: 1.0706 - val_acc: 0.6603\n",
            "Epoch 4/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.6508 - acc: 0.7734 - val_loss: 0.8369 - val_acc: 0.7202\n",
            "Epoch 5/40\n",
            "40000/40000 [==============================] - 140s 4ms/step - loss: 0.5568 - acc: 0.8051 - val_loss: 0.6720 - val_acc: 0.7792\n",
            "Epoch 6/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.4853 - acc: 0.8324 - val_loss: 0.7054 - val_acc: 0.7758\n",
            "Epoch 7/40\n",
            "40000/40000 [==============================] - 140s 4ms/step - loss: 0.4197 - acc: 0.8555 - val_loss: 0.8076 - val_acc: 0.7490\n",
            "Epoch 8/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.3592 - acc: 0.8758 - val_loss: 0.6205 - val_acc: 0.8078\n",
            "Epoch 9/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.3097 - acc: 0.8917 - val_loss: 0.8575 - val_acc: 0.7585\n",
            "Epoch 10/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.2672 - acc: 0.9075 - val_loss: 0.6156 - val_acc: 0.8107\n",
            "Epoch 11/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.2325 - acc: 0.9202 - val_loss: 0.5547 - val_acc: 0.8334\n",
            "Epoch 12/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.1957 - acc: 0.9331 - val_loss: 0.8439 - val_acc: 0.7722\n",
            "Epoch 13/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.1690 - acc: 0.9435 - val_loss: 0.9183 - val_acc: 0.7647\n",
            "Epoch 14/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.1503 - acc: 0.9494 - val_loss: 0.6090 - val_acc: 0.8268\n",
            "Epoch 15/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.1319 - acc: 0.9574 - val_loss: 0.5780 - val_acc: 0.8437\n",
            "Epoch 16/40\n",
            "40000/40000 [==============================] - 140s 4ms/step - loss: 0.1162 - acc: 0.9615 - val_loss: 0.5733 - val_acc: 0.8349\n",
            "Epoch 17/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.0972 - acc: 0.9680 - val_loss: 0.6994 - val_acc: 0.8262\n",
            "Epoch 18/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.0948 - acc: 0.9680 - val_loss: 0.5909 - val_acc: 0.8383\n",
            "Epoch 19/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.0848 - acc: 0.9718 - val_loss: 0.9019 - val_acc: 0.7720\n",
            "Epoch 20/40\n",
            "40000/40000 [==============================] - 139s 3ms/step - loss: 0.0779 - acc: 0.9748 - val_loss: 0.7742 - val_acc: 0.8166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QjbpLoshsK-t",
        "colab_type": "code",
        "outputId": "744026e9-aaa4-4114-f51f-561df586d799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "cell_type": "code",
      "source": [
        "#法2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVk01vn7VAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7dc93b10b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7dc93729e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eGq4v2ZIsl84",
        "colab_type": "code",
        "outputId": "d77c597c-61fa-4cbb-80ae-7396dbb762f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#法2\n",
        "# 載入weights\n",
        "weight_path = os.path.join(tempfile.gettempdir(), 'saved_ResNet_wt.h5')\n",
        "model.load_weights(weight_path)\n",
        "\n",
        "# Evaluate \n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 12s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tQWe-kwLsr7_",
        "colab_type": "code",
        "outputId": "6824afa4-a13b-4fbd-cb42-2b165423bc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#法2\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5754121539831162\n",
            "Test accuracy: 0.8257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hPYY48GItsOS",
        "colab_type": "code",
        "outputId": "2e5a11e4-3476-44a7-8562-b2e868c98ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "! ls -al \"/tmp/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 321512\n",
            "drwxrwxrwt 1 root root      4096 Nov 15 08:37 .\n",
            "drwxr-xr-x 1 root root      4096 Nov 15 04:31 ..\n",
            "-rw-r--r-- 1 root root 329217080 Nov 15 09:01 saved_ResNet_wt.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BIf4lJEWt-8A",
        "colab_type": "code",
        "outputId": "0f6f7254-f0f6-4ec2-e63e-a0ae70ff5d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "weight_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/saved_ResNet_wt.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "e4UzAMkjuLu-",
        "colab_type": "code",
        "outputId": "375dad34-65fd-47ba-f4c4-af32d5ef5ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! date '+%A %d %m %Y %X'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thursday 15 11 2018 09:37:36 AM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ik-nYylStU0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "2WmFrFFXr0_N",
        "colab_type": "code",
        "outputId": "9aab96c2-b80f-4c1f-8c5c-63e22f80eec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8106
        }
      },
      "cell_type": "code",
      "source": [
        "#法1\n",
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "\n",
        "#下載模型的視覺化圖檔\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_ResNet.png')\n",
        "from google.colab import files\n",
        "files.download('model_ResNet.png')\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "images (InputLayer)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               16777728  \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 27,422,474\n",
            "Trainable params: 27,414,538\n",
            "Non-trainable params: 7,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"4454pt\" viewBox=\"0.00 0.00 476.00 4454.00\" width=\"476pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 4450)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-4450 472,-4450 472,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140282755681584 -->\n<g class=\"node\" id=\"node1\">\n<title>140282755681584</title>\n<polygon fill=\"none\" points=\"82.5,-4399.5 82.5,-4445.5 385.5,-4445.5 385.5,-4399.5 82.5,-4399.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-4418.8\">images: InputLayer</text>\n<polyline fill=\"none\" points=\"210.5,-4399.5 210.5,-4445.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-4430.3\">input:</text>\n<polyline fill=\"none\" points=\"210.5,-4422.5 268.5,-4422.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-4407.3\">output:</text>\n<polyline fill=\"none\" points=\"268.5,-4399.5 268.5,-4445.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327\" y=\"-4430.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"268.5,-4422.5 385.5,-4422.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327\" y=\"-4407.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 140284940926648 -->\n<g class=\"node\" id=\"node2\">\n<title>140284940926648</title>\n<polygon fill=\"none\" points=\"69,-4316.5 69,-4362.5 399,-4362.5 399,-4316.5 69,-4316.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-4335.8\">conv2d_15: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-4316.5 209,-4362.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-4347.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-4339.5 267,-4339.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-4324.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-4316.5 267,-4362.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-4347.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"267,-4339.5 399,-4339.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-4324.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282755681584&#45;&gt;140284940926648 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140282755681584-&gt;140284940926648</title>\n<path d=\"M234,-4399.3799C234,-4391.1745 234,-4381.7679 234,-4372.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-4372.784 234,-4362.784 230.5001,-4372.784 237.5001,-4372.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282755681920 -->\n<g class=\"node\" id=\"node3\">\n<title>140282755681920</title>\n<polygon fill=\"none\" points=\"0,-4233.5 0,-4279.5 468,-4279.5 468,-4233.5 0,-4233.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-4252.8\">batch_normalization_18: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-4233.5 278,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-4264.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-4256.5 336,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-4241.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-4233.5 336,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-4264.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"336,-4256.5 468,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-4241.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140284940926648&#45;&gt;140282755681920 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140284940926648-&gt;140282755681920</title>\n<path d=\"M234,-4316.3799C234,-4308.1745 234,-4298.7679 234,-4289.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-4289.784 234,-4279.784 230.5001,-4289.784 237.5001,-4289.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282755681416 -->\n<g class=\"node\" id=\"node4\">\n<title>140282755681416</title>\n<polygon fill=\"none\" points=\"58.5,-4150.5 58.5,-4196.5 409.5,-4196.5 409.5,-4150.5 58.5,-4150.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-4169.8\">activation_18: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-4150.5 219.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-4181.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-4173.5 277.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-4158.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-4150.5 277.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-4181.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"277.5,-4173.5 409.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-4158.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282755681920&#45;&gt;140282755681416 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140282755681920-&gt;140282755681416</title>\n<path d=\"M234,-4233.3799C234,-4225.1745 234,-4215.7679 234,-4206.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-4206.784 234,-4196.784 230.5001,-4206.784 237.5001,-4206.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282755337576 -->\n<g class=\"node\" id=\"node5\">\n<title>140282755337576</title>\n<polygon fill=\"none\" points=\"69,-4067.5 69,-4113.5 399,-4113.5 399,-4067.5 69,-4067.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-4086.8\">conv2d_16: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-4067.5 209,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-4098.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-4090.5 267,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-4075.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-4067.5 267,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-4098.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"267,-4090.5 399,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-4075.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282755681416&#45;&gt;140282755337576 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140282755681416-&gt;140282755337576</title>\n<path d=\"M234,-4150.3799C234,-4142.1745 234,-4132.7679 234,-4123.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-4123.784 234,-4113.784 230.5001,-4123.784 237.5001,-4123.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282755230632 -->\n<g class=\"node\" id=\"node6\">\n<title>140282755230632</title>\n<polygon fill=\"none\" points=\"68.5,-3984.5 68.5,-4030.5 399.5,-4030.5 399.5,-3984.5 68.5,-3984.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-4003.8\">dropout_21: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-3984.5 209.5,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-4015.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-4007.5 267.5,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3992.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-3984.5 267.5,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-4015.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"267.5,-4007.5 399.5,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3992.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282755337576&#45;&gt;140282755230632 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140282755337576-&gt;140282755230632</title>\n<path d=\"M234,-4067.3799C234,-4059.1745 234,-4049.7679 234,-4040.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-4040.784 234,-4030.784 230.5001,-4040.784 237.5001,-4040.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282754936504 -->\n<g class=\"node\" id=\"node7\">\n<title>140282754936504</title>\n<polygon fill=\"none\" points=\"0,-3901.5 0,-3947.5 468,-3947.5 468,-3901.5 0,-3901.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3920.8\">batch_normalization_19: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-3901.5 278,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3932.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-3924.5 336,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3909.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-3901.5 336,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3932.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"336,-3924.5 468,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3909.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282755230632&#45;&gt;140282754936504 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140282755230632-&gt;140282754936504</title>\n<path d=\"M234,-3984.3799C234,-3976.1745 234,-3966.7679 234,-3957.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3957.784 234,-3947.784 230.5001,-3957.784 237.5001,-3957.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282754933592 -->\n<g class=\"node\" id=\"node8\">\n<title>140282754933592</title>\n<polygon fill=\"none\" points=\"58.5,-3818.5 58.5,-3864.5 409.5,-3864.5 409.5,-3818.5 58.5,-3818.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3837.8\">activation_19: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-3818.5 219.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-3849.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-3841.5 277.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-3826.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-3818.5 277.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-3849.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"277.5,-3841.5 409.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-3826.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282754936504&#45;&gt;140282754933592 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140282754936504-&gt;140282754933592</title>\n<path d=\"M234,-3901.3799C234,-3893.1745 234,-3883.7679 234,-3874.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3874.784 234,-3864.784 230.5001,-3874.784 237.5001,-3874.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282754508560 -->\n<g class=\"node\" id=\"node9\">\n<title>140282754508560</title>\n<polygon fill=\"none\" points=\"69,-3735.5 69,-3781.5 399,-3781.5 399,-3735.5 69,-3735.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3754.8\">conv2d_17: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-3735.5 209,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-3766.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-3758.5 267,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-3743.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-3735.5 267,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3766.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"267,-3758.5 399,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3743.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282754933592&#45;&gt;140282754508560 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140282754933592-&gt;140282754508560</title>\n<path d=\"M234,-3818.3799C234,-3810.1745 234,-3800.7679 234,-3791.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3791.784 234,-3781.784 230.5001,-3791.784 237.5001,-3791.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282754229976 -->\n<g class=\"node\" id=\"node10\">\n<title>140282754229976</title>\n<polygon fill=\"none\" points=\"68.5,-3652.5 68.5,-3698.5 399.5,-3698.5 399.5,-3652.5 68.5,-3652.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3671.8\">dropout_22: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-3652.5 209.5,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3683.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-3675.5 267.5,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3660.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-3652.5 267.5,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3683.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"267.5,-3675.5 399.5,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3660.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282754508560&#45;&gt;140282754229976 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140282754508560-&gt;140282754229976</title>\n<path d=\"M234,-3735.3799C234,-3727.1745 234,-3717.7679 234,-3708.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3708.784 234,-3698.784 230.5001,-3708.784 237.5001,-3708.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282753418184 -->\n<g class=\"node\" id=\"node11\">\n<title>140282753418184</title>\n<polygon fill=\"none\" points=\"0,-3569.5 0,-3615.5 468,-3615.5 468,-3569.5 0,-3569.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3588.8\">batch_normalization_20: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-3569.5 278,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3600.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-3592.5 336,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3577.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-3569.5 336,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3600.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"336,-3592.5 468,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3577.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282754229976&#45;&gt;140282753418184 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140282754229976-&gt;140282753418184</title>\n<path d=\"M234,-3652.3799C234,-3644.1745 234,-3634.7679 234,-3625.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3625.784 234,-3615.784 230.5001,-3625.784 237.5001,-3625.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282753578432 -->\n<g class=\"node\" id=\"node12\">\n<title>140282753578432</title>\n<polygon fill=\"none\" points=\"58.5,-3486.5 58.5,-3532.5 409.5,-3532.5 409.5,-3486.5 58.5,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3505.8\">activation_20: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-3486.5 219.5,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-3509.5 277.5,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-3486.5 277.5,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-3517.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"277.5,-3509.5 409.5,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-3494.3\">(None, 32, 32, 128)</text>\n</g>\n<!-- 140282753418184&#45;&gt;140282753578432 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140282753418184-&gt;140282753578432</title>\n<path d=\"M234,-3569.3799C234,-3561.1745 234,-3551.7679 234,-3542.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3542.784 234,-3532.784 230.5001,-3542.784 237.5001,-3542.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282753578040 -->\n<g class=\"node\" id=\"node13\">\n<title>140282753578040</title>\n<polygon fill=\"none\" points=\"28.5,-3403.5 28.5,-3449.5 439.5,-3449.5 439.5,-3403.5 28.5,-3403.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3422.8\">max_pooling2d_7: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"249.5,-3403.5 249.5,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-3434.3\">input:</text>\n<polyline fill=\"none\" points=\"249.5,-3426.5 307.5,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-3411.3\">output:</text>\n<polyline fill=\"none\" points=\"307.5,-3403.5 307.5,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-3434.3\">(None, 32, 32, 128)</text>\n<polyline fill=\"none\" points=\"307.5,-3426.5 439.5,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-3411.3\">(None, 16, 16, 128)</text>\n</g>\n<!-- 140282753578432&#45;&gt;140282753578040 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140282753578432-&gt;140282753578040</title>\n<path d=\"M234,-3486.3799C234,-3478.1745 234,-3468.7679 234,-3459.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3459.784 234,-3449.784 230.5001,-3459.784 237.5001,-3459.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282753316960 -->\n<g class=\"node\" id=\"node14\">\n<title>140282753316960</title>\n<polygon fill=\"none\" points=\"68.5,-3320.5 68.5,-3366.5 399.5,-3366.5 399.5,-3320.5 68.5,-3320.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3339.8\">dropout_23: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-3320.5 209.5,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3351.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-3343.5 267.5,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3328.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-3320.5 267.5,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3351.3\">(None, 16, 16, 128)</text>\n<polyline fill=\"none\" points=\"267.5,-3343.5 399.5,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3328.3\">(None, 16, 16, 128)</text>\n</g>\n<!-- 140282753578040&#45;&gt;140282753316960 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140282753578040-&gt;140282753316960</title>\n<path d=\"M234,-3403.3799C234,-3395.1745 234,-3385.7679 234,-3376.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3376.784 234,-3366.784 230.5001,-3376.784 237.5001,-3376.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282752337568 -->\n<g class=\"node\" id=\"node15\">\n<title>140282752337568</title>\n<polygon fill=\"none\" points=\"69,-3237.5 69,-3283.5 399,-3283.5 399,-3237.5 69,-3237.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3256.8\">conv2d_18: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-3237.5 209,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-3268.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-3260.5 267,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-3245.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-3237.5 267,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3268.3\">(None, 16, 16, 128)</text>\n<polyline fill=\"none\" points=\"267,-3260.5 399,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3245.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282753316960&#45;&gt;140282752337568 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140282753316960-&gt;140282752337568</title>\n<path d=\"M234,-3320.3799C234,-3312.1745 234,-3302.7679 234,-3293.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3293.784 234,-3283.784 230.5001,-3293.784 237.5001,-3293.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282752514480 -->\n<g class=\"node\" id=\"node16\">\n<title>140282752514480</title>\n<polygon fill=\"none\" points=\"68.5,-3154.5 68.5,-3200.5 399.5,-3200.5 399.5,-3154.5 68.5,-3154.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3173.8\">dropout_24: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-3154.5 209.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3185.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-3177.5 267.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-3162.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-3154.5 267.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3185.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267.5,-3177.5 399.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-3162.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282752337568&#45;&gt;140282752514480 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140282752337568-&gt;140282752514480</title>\n<path d=\"M234,-3237.3799C234,-3229.1745 234,-3219.7679 234,-3210.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3210.784 234,-3200.784 230.5001,-3210.784 237.5001,-3210.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282752111560 -->\n<g class=\"node\" id=\"node17\">\n<title>140282752111560</title>\n<polygon fill=\"none\" points=\"0,-3071.5 0,-3117.5 468,-3117.5 468,-3071.5 0,-3071.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3090.8\">batch_normalization_21: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-3071.5 278,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3102.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-3094.5 336,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-3079.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-3071.5 336,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3102.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"336,-3094.5 468,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3079.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282752514480&#45;&gt;140282752111560 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140282752514480-&gt;140282752111560</title>\n<path d=\"M234,-3154.3799C234,-3146.1745 234,-3136.7679 234,-3127.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3127.784 234,-3117.784 230.5001,-3127.784 237.5001,-3127.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282752249808 -->\n<g class=\"node\" id=\"node18\">\n<title>140282752249808</title>\n<polygon fill=\"none\" points=\"58.5,-2988.5 58.5,-3034.5 409.5,-3034.5 409.5,-2988.5 58.5,-2988.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-3007.8\">activation_21: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-2988.5 219.5,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-3019.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-3011.5 277.5,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2996.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-2988.5 277.5,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-3019.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"277.5,-3011.5 409.5,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2996.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282752111560&#45;&gt;140282752249808 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140282752111560-&gt;140282752249808</title>\n<path d=\"M234,-3071.3799C234,-3063.1745 234,-3053.7679 234,-3044.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-3044.784 234,-3034.784 230.5001,-3044.784 237.5001,-3044.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282751829496 -->\n<g class=\"node\" id=\"node19\">\n<title>140282751829496</title>\n<polygon fill=\"none\" points=\"69,-2905.5 69,-2951.5 399,-2951.5 399,-2905.5 69,-2905.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2924.8\">conv2d_19: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-2905.5 209,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-2936.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-2928.5 267,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-2913.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-2905.5 267,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-2936.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267,-2928.5 399,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-2913.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282752249808&#45;&gt;140282751829496 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140282752249808-&gt;140282751829496</title>\n<path d=\"M234,-2988.3799C234,-2980.1745 234,-2970.7679 234,-2961.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2961.784 234,-2951.784 230.5001,-2961.784 237.5001,-2961.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282751571952 -->\n<g class=\"node\" id=\"node20\">\n<title>140282751571952</title>\n<polygon fill=\"none\" points=\"68.5,-2822.5 68.5,-2868.5 399.5,-2868.5 399.5,-2822.5 68.5,-2822.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2841.8\">dropout_25: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-2822.5 209.5,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2853.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-2845.5 267.5,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2830.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-2822.5 267.5,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-2853.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267.5,-2845.5 399.5,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-2830.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282751829496&#45;&gt;140282751571952 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140282751829496-&gt;140282751571952</title>\n<path d=\"M234,-2905.3799C234,-2897.1745 234,-2887.7679 234,-2878.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2878.784 234,-2868.784 230.5001,-2878.784 237.5001,-2878.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282751686528 -->\n<g class=\"node\" id=\"node21\">\n<title>140282751686528</title>\n<polygon fill=\"none\" points=\"0,-2739.5 0,-2785.5 468,-2785.5 468,-2739.5 0,-2739.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2758.8\">batch_normalization_22: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-2739.5 278,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2770.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-2762.5 336,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2747.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-2739.5 336,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-2770.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"336,-2762.5 468,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-2747.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282751571952&#45;&gt;140282751686528 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140282751571952-&gt;140282751686528</title>\n<path d=\"M234,-2822.3799C234,-2814.1745 234,-2804.7679 234,-2795.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2795.784 234,-2785.784 230.5001,-2795.784 237.5001,-2795.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282750764928 -->\n<g class=\"node\" id=\"node22\">\n<title>140282750764928</title>\n<polygon fill=\"none\" points=\"58.5,-2656.5 58.5,-2702.5 409.5,-2702.5 409.5,-2656.5 58.5,-2656.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2675.8\">activation_22: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-2656.5 219.5,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2687.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-2679.5 277.5,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2664.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-2656.5 277.5,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2687.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"277.5,-2679.5 409.5,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2664.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282751686528&#45;&gt;140282750764928 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140282751686528-&gt;140282750764928</title>\n<path d=\"M234,-2739.3799C234,-2731.1745 234,-2721.7679 234,-2712.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2712.784 234,-2702.784 230.5001,-2712.784 237.5001,-2712.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282750766720 -->\n<g class=\"node\" id=\"node23\">\n<title>140282750766720</title>\n<polygon fill=\"none\" points=\"69,-2573.5 69,-2619.5 399,-2619.5 399,-2573.5 69,-2573.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2592.8\">conv2d_20: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-2573.5 209,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-2604.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-2596.5 267,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-2581.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-2573.5 267,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-2604.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267,-2596.5 399,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-2581.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282750764928&#45;&gt;140282750766720 -->\n<g class=\"edge\" id=\"edge22\">\n<title>140282750764928-&gt;140282750766720</title>\n<path d=\"M234,-2656.3799C234,-2648.1745 234,-2638.7679 234,-2629.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2629.784 234,-2619.784 230.5001,-2629.784 237.5001,-2629.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282750247880 -->\n<g class=\"node\" id=\"node24\">\n<title>140282750247880</title>\n<polygon fill=\"none\" points=\"68.5,-2490.5 68.5,-2536.5 399.5,-2536.5 399.5,-2490.5 68.5,-2490.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2509.8\">dropout_26: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-2490.5 209.5,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2521.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-2513.5 267.5,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2498.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-2490.5 267.5,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-2521.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267.5,-2513.5 399.5,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-2498.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282750766720&#45;&gt;140282750247880 -->\n<g class=\"edge\" id=\"edge23\">\n<title>140282750766720-&gt;140282750247880</title>\n<path d=\"M234,-2573.3799C234,-2565.1745 234,-2555.7679 234,-2546.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2546.784 234,-2536.784 230.5001,-2546.784 237.5001,-2546.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282750249448 -->\n<g class=\"node\" id=\"node25\">\n<title>140282750249448</title>\n<polygon fill=\"none\" points=\"0,-2407.5 0,-2453.5 468,-2453.5 468,-2407.5 0,-2407.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2426.8\">batch_normalization_23: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-2407.5 278,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2438.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-2430.5 336,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2415.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-2407.5 336,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-2438.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"336,-2430.5 468,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-2415.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282750247880&#45;&gt;140282750249448 -->\n<g class=\"edge\" id=\"edge24\">\n<title>140282750247880-&gt;140282750249448</title>\n<path d=\"M234,-2490.3799C234,-2482.1745 234,-2472.7679 234,-2463.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2463.784 234,-2453.784 230.5001,-2463.784 237.5001,-2463.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282750086448 -->\n<g class=\"node\" id=\"node26\">\n<title>140282750086448</title>\n<polygon fill=\"none\" points=\"58.5,-2324.5 58.5,-2370.5 409.5,-2370.5 409.5,-2324.5 58.5,-2324.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2343.8\">activation_23: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-2324.5 219.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2355.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-2347.5 277.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2332.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-2324.5 277.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2355.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"277.5,-2347.5 409.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2332.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282750249448&#45;&gt;140282750086448 -->\n<g class=\"edge\" id=\"edge25\">\n<title>140282750249448-&gt;140282750086448</title>\n<path d=\"M234,-2407.3799C234,-2399.1745 234,-2389.7679 234,-2380.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2380.784 234,-2370.784 230.5001,-2380.784 237.5001,-2380.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282749823688 -->\n<g class=\"node\" id=\"node27\">\n<title>140282749823688</title>\n<polygon fill=\"none\" points=\"69,-2241.5 69,-2287.5 399,-2287.5 399,-2241.5 69,-2241.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2260.8\">conv2d_21: Conv2D</text>\n<polyline fill=\"none\" points=\"209,-2241.5 209,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-2272.3\">input:</text>\n<polyline fill=\"none\" points=\"209,-2264.5 267,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-2249.3\">output:</text>\n<polyline fill=\"none\" points=\"267,-2241.5 267,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-2272.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267,-2264.5 399,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-2249.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282750086448&#45;&gt;140282749823688 -->\n<g class=\"edge\" id=\"edge26\">\n<title>140282750086448-&gt;140282749823688</title>\n<path d=\"M234,-2324.3799C234,-2316.1745 234,-2306.7679 234,-2297.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2297.784 234,-2287.784 230.5001,-2297.784 237.5001,-2297.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282749558624 -->\n<g class=\"node\" id=\"node28\">\n<title>140282749558624</title>\n<polygon fill=\"none\" points=\"68.5,-2158.5 68.5,-2204.5 399.5,-2204.5 399.5,-2158.5 68.5,-2158.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2177.8\">dropout_27: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-2158.5 209.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2189.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-2181.5 267.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2166.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-2158.5 267.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-2189.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"267.5,-2181.5 399.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-2166.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282749823688&#45;&gt;140282749558624 -->\n<g class=\"edge\" id=\"edge27\">\n<title>140282749823688-&gt;140282749558624</title>\n<path d=\"M234,-2241.3799C234,-2233.1745 234,-2223.7679 234,-2214.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2214.784 234,-2204.784 230.5001,-2214.784 237.5001,-2214.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282749312136 -->\n<g class=\"node\" id=\"node29\">\n<title>140282749312136</title>\n<polygon fill=\"none\" points=\"0,-2075.5 0,-2121.5 468,-2121.5 468,-2075.5 0,-2075.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2094.8\">batch_normalization_24: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-2075.5 278,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2106.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-2098.5 336,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-2083.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-2075.5 336,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-2106.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"336,-2098.5 468,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-2083.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282749558624&#45;&gt;140282749312136 -->\n<g class=\"edge\" id=\"edge28\">\n<title>140282749558624-&gt;140282749312136</title>\n<path d=\"M234,-2158.3799C234,-2150.1745 234,-2140.7679 234,-2131.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2131.784 234,-2121.784 230.5001,-2131.784 237.5001,-2131.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282748393456 -->\n<g class=\"node\" id=\"node30\">\n<title>140282748393456</title>\n<polygon fill=\"none\" points=\"58.5,-1992.5 58.5,-2038.5 409.5,-2038.5 409.5,-1992.5 58.5,-1992.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-2011.8\">activation_24: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-1992.5 219.5,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2023.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-2015.5 277.5,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-2000.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-1992.5 277.5,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2023.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"277.5,-2015.5 409.5,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-2000.3\">(None, 16, 16, 256)</text>\n</g>\n<!-- 140282749312136&#45;&gt;140282748393456 -->\n<g class=\"edge\" id=\"edge29\">\n<title>140282749312136-&gt;140282748393456</title>\n<path d=\"M234,-2075.3799C234,-2067.1745 234,-2057.7679 234,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-2048.784 234,-2038.784 230.5001,-2048.784 237.5001,-2048.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282748393064 -->\n<g class=\"node\" id=\"node31\">\n<title>140282748393064</title>\n<polygon fill=\"none\" points=\"28.5,-1909.5 28.5,-1955.5 439.5,-1955.5 439.5,-1909.5 28.5,-1909.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1928.8\">max_pooling2d_8: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"249.5,-1909.5 249.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-1940.3\">input:</text>\n<polyline fill=\"none\" points=\"249.5,-1932.5 307.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-1917.3\">output:</text>\n<polyline fill=\"none\" points=\"307.5,-1909.5 307.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-1940.3\">(None, 16, 16, 256)</text>\n<polyline fill=\"none\" points=\"307.5,-1932.5 439.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-1917.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140282748393456&#45;&gt;140282748393064 -->\n<g class=\"edge\" id=\"edge30\">\n<title>140282748393456-&gt;140282748393064</title>\n<path d=\"M234,-1992.3799C234,-1984.1745 234,-1974.7679 234,-1965.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1965.784 234,-1955.784 230.5001,-1965.784 237.5001,-1965.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282757548632 -->\n<g class=\"node\" id=\"node32\">\n<title>140282757548632</title>\n<polygon fill=\"none\" points=\"76,-1826.5 76,-1872.5 392,-1872.5 392,-1826.5 76,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1845.8\">dropout_28: Dropout</text>\n<polyline fill=\"none\" points=\"217,-1826.5 217,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-1849.5 275,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-1826.5 275,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1857.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"275,-1849.5 392,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1834.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140282748393064&#45;&gt;140282757548632 -->\n<g class=\"edge\" id=\"edge31\">\n<title>140282748393064-&gt;140282757548632</title>\n<path d=\"M234,-1909.3799C234,-1901.1745 234,-1891.7679 234,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1882.784 234,-1872.784 230.5001,-1882.784 237.5001,-1882.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282748124744 -->\n<g class=\"node\" id=\"node33\">\n<title>140282748124744</title>\n<polygon fill=\"none\" points=\"76.5,-1743.5 76.5,-1789.5 391.5,-1789.5 391.5,-1743.5 76.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1762.8\">conv2d_22: Conv2D</text>\n<polyline fill=\"none\" points=\"216.5,-1743.5 216.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"216.5,-1766.5 274.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"274.5,-1743.5 274.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-1774.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"274.5,-1766.5 391.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-1751.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282757548632&#45;&gt;140282748124744 -->\n<g class=\"edge\" id=\"edge32\">\n<title>140282757548632-&gt;140282748124744</title>\n<path d=\"M234,-1826.3799C234,-1818.1745 234,-1808.7679 234,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1799.784 234,-1789.784 230.5001,-1799.784 237.5001,-1799.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282756763776 -->\n<g class=\"node\" id=\"node34\">\n<title>140282756763776</title>\n<polygon fill=\"none\" points=\"76,-1660.5 76,-1706.5 392,-1706.5 392,-1660.5 76,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1679.8\">dropout_29: Dropout</text>\n<polyline fill=\"none\" points=\"217,-1660.5 217,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-1683.5 275,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-1660.5 275,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1691.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"275,-1683.5 392,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1668.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282748124744&#45;&gt;140282756763776 -->\n<g class=\"edge\" id=\"edge33\">\n<title>140282748124744-&gt;140282756763776</title>\n<path d=\"M234,-1743.3799C234,-1735.1745 234,-1725.7679 234,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1716.784 234,-1706.784 230.5001,-1716.784 237.5001,-1716.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282756765568 -->\n<g class=\"node\" id=\"node35\">\n<title>140282756765568</title>\n<polygon fill=\"none\" points=\"7.5,-1577.5 7.5,-1623.5 460.5,-1623.5 460.5,-1577.5 7.5,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1596.8\">batch_normalization_25: BatchNormalization</text>\n<polyline fill=\"none\" points=\"285.5,-1577.5 285.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"285.5,-1600.5 343.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"343.5,-1577.5 343.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-1608.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"343.5,-1600.5 460.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-1585.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282756763776&#45;&gt;140282756765568 -->\n<g class=\"edge\" id=\"edge34\">\n<title>140282756763776-&gt;140282756765568</title>\n<path d=\"M234,-1660.3799C234,-1652.1745 234,-1642.7679 234,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1633.784 234,-1623.784 230.5001,-1633.784 237.5001,-1633.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282757000328 -->\n<g class=\"node\" id=\"node36\">\n<title>140282757000328</title>\n<polygon fill=\"none\" points=\"66,-1494.5 66,-1540.5 402,-1540.5 402,-1494.5 66,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1513.8\">activation_25: Activation</text>\n<polyline fill=\"none\" points=\"227,-1494.5 227,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"227,-1517.5 285,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"285,-1494.5 285,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-1525.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"285,-1517.5 402,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-1502.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282756765568&#45;&gt;140282757000328 -->\n<g class=\"edge\" id=\"edge35\">\n<title>140282756765568-&gt;140282757000328</title>\n<path d=\"M234,-1577.3799C234,-1569.1745 234,-1559.7679 234,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1550.784 234,-1540.784 230.5001,-1550.784 237.5001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282757331488 -->\n<g class=\"node\" id=\"node37\">\n<title>140282757331488</title>\n<polygon fill=\"none\" points=\"76.5,-1411.5 76.5,-1457.5 391.5,-1457.5 391.5,-1411.5 76.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1430.8\">conv2d_23: Conv2D</text>\n<polyline fill=\"none\" points=\"216.5,-1411.5 216.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"216.5,-1434.5 274.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"274.5,-1411.5 274.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-1442.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"274.5,-1434.5 391.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-1419.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282757000328&#45;&gt;140282757331488 -->\n<g class=\"edge\" id=\"edge36\">\n<title>140282757000328-&gt;140282757331488</title>\n<path d=\"M234,-1494.3799C234,-1486.1745 234,-1476.7679 234,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1467.784 234,-1457.784 230.5001,-1467.784 237.5001,-1467.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282756151840 -->\n<g class=\"node\" id=\"node38\">\n<title>140282756151840</title>\n<polygon fill=\"none\" points=\"76,-1328.5 76,-1374.5 392,-1374.5 392,-1328.5 76,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1347.8\">dropout_30: Dropout</text>\n<polyline fill=\"none\" points=\"217,-1328.5 217,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-1351.5 275,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-1328.5 275,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1359.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"275,-1351.5 392,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1336.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282757331488&#45;&gt;140282756151840 -->\n<g class=\"edge\" id=\"edge37\">\n<title>140282757331488-&gt;140282756151840</title>\n<path d=\"M234,-1411.3799C234,-1403.1745 234,-1393.7679 234,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1384.784 234,-1374.784 230.5001,-1384.784 237.5001,-1384.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282748239488 -->\n<g class=\"node\" id=\"node39\">\n<title>140282748239488</title>\n<polygon fill=\"none\" points=\"7.5,-1245.5 7.5,-1291.5 460.5,-1291.5 460.5,-1245.5 7.5,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1264.8\">batch_normalization_26: BatchNormalization</text>\n<polyline fill=\"none\" points=\"285.5,-1245.5 285.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"285.5,-1268.5 343.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"343.5,-1245.5 343.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-1276.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"343.5,-1268.5 460.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-1253.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282756151840&#45;&gt;140282748239488 -->\n<g class=\"edge\" id=\"edge38\">\n<title>140282756151840-&gt;140282748239488</title>\n<path d=\"M234,-1328.3799C234,-1320.1745 234,-1310.7679 234,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1301.784 234,-1291.784 230.5001,-1301.784 237.5001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282746456328 -->\n<g class=\"node\" id=\"node40\">\n<title>140282746456328</title>\n<polygon fill=\"none\" points=\"66,-1162.5 66,-1208.5 402,-1208.5 402,-1162.5 66,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1181.8\">activation_26: Activation</text>\n<polyline fill=\"none\" points=\"227,-1162.5 227,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"227,-1185.5 285,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"285,-1162.5 285,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-1193.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"285,-1185.5 402,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-1170.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282748239488&#45;&gt;140282746456328 -->\n<g class=\"edge\" id=\"edge39\">\n<title>140282748239488-&gt;140282746456328</title>\n<path d=\"M234,-1245.3799C234,-1237.1745 234,-1227.7679 234,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1218.784 234,-1208.784 230.5001,-1218.784 237.5001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282745785928 -->\n<g class=\"node\" id=\"node41\">\n<title>140282745785928</title>\n<polygon fill=\"none\" points=\"76.5,-1079.5 76.5,-1125.5 391.5,-1125.5 391.5,-1079.5 76.5,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1098.8\">conv2d_24: Conv2D</text>\n<polyline fill=\"none\" points=\"216.5,-1079.5 216.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"216.5,-1102.5 274.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"274.5,-1079.5 274.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-1110.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"274.5,-1102.5 391.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-1087.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282746456328&#45;&gt;140282745785928 -->\n<g class=\"edge\" id=\"edge40\">\n<title>140282746456328-&gt;140282745785928</title>\n<path d=\"M234,-1162.3799C234,-1154.1745 234,-1144.7679 234,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1135.784 234,-1125.784 230.5001,-1135.784 237.5001,-1135.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282745532992 -->\n<g class=\"node\" id=\"node42\">\n<title>140282745532992</title>\n<polygon fill=\"none\" points=\"76,-996.5 76,-1042.5 392,-1042.5 392,-996.5 76,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-1015.8\">dropout_31: Dropout</text>\n<polyline fill=\"none\" points=\"217,-996.5 217,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-1019.5 275,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-996.5 275,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1027.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"275,-1019.5 392,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1004.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282745785928&#45;&gt;140282745532992 -->\n<g class=\"edge\" id=\"edge41\">\n<title>140282745785928-&gt;140282745532992</title>\n<path d=\"M234,-1079.3799C234,-1071.1745 234,-1061.7679 234,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-1052.784 234,-1042.784 230.5001,-1052.784 237.5001,-1052.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282745533272 -->\n<g class=\"node\" id=\"node43\">\n<title>140282745533272</title>\n<polygon fill=\"none\" points=\"7.5,-913.5 7.5,-959.5 460.5,-959.5 460.5,-913.5 7.5,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-932.8\">batch_normalization_27: BatchNormalization</text>\n<polyline fill=\"none\" points=\"285.5,-913.5 285.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"285.5,-936.5 343.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"343.5,-913.5 343.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-944.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"343.5,-936.5 460.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-921.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282745532992&#45;&gt;140282745533272 -->\n<g class=\"edge\" id=\"edge42\">\n<title>140282745532992-&gt;140282745533272</title>\n<path d=\"M234,-996.3799C234,-988.1745 234,-978.7679 234,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-969.784 234,-959.784 230.5001,-969.784 237.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282745385872 -->\n<g class=\"node\" id=\"node44\">\n<title>140282745385872</title>\n<polygon fill=\"none\" points=\"66,-830.5 66,-876.5 402,-876.5 402,-830.5 66,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-849.8\">activation_27: Activation</text>\n<polyline fill=\"none\" points=\"227,-830.5 227,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"227,-853.5 285,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"285,-830.5 285,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-861.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"285,-853.5 402,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-838.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282745533272&#45;&gt;140282745385872 -->\n<g class=\"edge\" id=\"edge43\">\n<title>140282745533272-&gt;140282745385872</title>\n<path d=\"M234,-913.3799C234,-905.1745 234,-895.7679 234,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-886.784 234,-876.784 230.5001,-886.784 237.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282744851872 -->\n<g class=\"node\" id=\"node45\">\n<title>140282744851872</title>\n<polygon fill=\"none\" points=\"76.5,-747.5 76.5,-793.5 391.5,-793.5 391.5,-747.5 76.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-766.8\">conv2d_25: Conv2D</text>\n<polyline fill=\"none\" points=\"216.5,-747.5 216.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"216.5,-770.5 274.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"274.5,-747.5 274.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-778.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"274.5,-770.5 391.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-755.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282745385872&#45;&gt;140282744851872 -->\n<g class=\"edge\" id=\"edge44\">\n<title>140282745385872-&gt;140282744851872</title>\n<path d=\"M234,-830.3799C234,-822.1745 234,-812.7679 234,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-803.784 234,-793.784 230.5001,-803.784 237.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282745233024 -->\n<g class=\"node\" id=\"node46\">\n<title>140282745233024</title>\n<polygon fill=\"none\" points=\"76,-664.5 76,-710.5 392,-710.5 392,-664.5 76,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-683.8\">dropout_32: Dropout</text>\n<polyline fill=\"none\" points=\"217,-664.5 217,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-687.5 275,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-664.5 275,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-695.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"275,-687.5 392,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-672.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282744851872&#45;&gt;140282745233024 -->\n<g class=\"edge\" id=\"edge45\">\n<title>140282744851872-&gt;140282745233024</title>\n<path d=\"M234,-747.3799C234,-739.1745 234,-729.7679 234,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-720.784 234,-710.784 230.5001,-720.784 237.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282744468984 -->\n<g class=\"node\" id=\"node47\">\n<title>140282744468984</title>\n<polygon fill=\"none\" points=\"7.5,-581.5 7.5,-627.5 460.5,-627.5 460.5,-581.5 7.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-600.8\">batch_normalization_28: BatchNormalization</text>\n<polyline fill=\"none\" points=\"285.5,-581.5 285.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"285.5,-604.5 343.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"343.5,-581.5 343.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-612.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"343.5,-604.5 460.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-589.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282745233024&#45;&gt;140282744468984 -->\n<g class=\"edge\" id=\"edge46\">\n<title>140282745233024-&gt;140282744468984</title>\n<path d=\"M234,-664.3799C234,-656.1745 234,-646.7679 234,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-637.784 234,-627.784 230.5001,-637.784 237.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282744034808 -->\n<g class=\"node\" id=\"node48\">\n<title>140282744034808</title>\n<polygon fill=\"none\" points=\"66,-498.5 66,-544.5 402,-544.5 402,-498.5 66,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-517.8\">activation_28: Activation</text>\n<polyline fill=\"none\" points=\"227,-498.5 227,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"227,-521.5 285,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"285,-498.5 285,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-529.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"285,-521.5 402,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-506.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140282744468984&#45;&gt;140282744034808 -->\n<g class=\"edge\" id=\"edge47\">\n<title>140282744468984-&gt;140282744034808</title>\n<path d=\"M234,-581.3799C234,-573.1745 234,-563.7679 234,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-554.784 234,-544.784 230.5001,-554.784 237.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282744035816 -->\n<g class=\"node\" id=\"node49\">\n<title>140282744035816</title>\n<polygon fill=\"none\" points=\"90,-415.5 90,-461.5 378,-461.5 378,-415.5 90,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-434.8\">flatten_4: Flatten</text>\n<polyline fill=\"none\" points=\"203,-415.5 203,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"203,-438.5 261,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"261,-415.5 261,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319.5\" y=\"-446.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"261,-438.5 378,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319.5\" y=\"-423.3\">(None, 32768)</text>\n</g>\n<!-- 140282744034808&#45;&gt;140282744035816 -->\n<g class=\"edge\" id=\"edge48\">\n<title>140282744034808-&gt;140282744035816</title>\n<path d=\"M234,-498.3799C234,-490.1745 234,-480.7679 234,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-471.784 234,-461.784 230.5001,-471.784 237.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282743909792 -->\n<g class=\"node\" id=\"node50\">\n<title>140282743909792</title>\n<polygon fill=\"none\" points=\"100.5,-332.5 100.5,-378.5 367.5,-378.5 367.5,-332.5 100.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154\" y=\"-351.8\">dense_7: Dense</text>\n<polyline fill=\"none\" points=\"207.5,-332.5 207.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"207.5,-355.5 265.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"265.5,-332.5 265.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-363.3\">(None, 32768)</text>\n<polyline fill=\"none\" points=\"265.5,-355.5 367.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-340.3\">(None, 512)</text>\n</g>\n<!-- 140282744035816&#45;&gt;140282743909792 -->\n<g class=\"edge\" id=\"edge49\">\n<title>140282744035816-&gt;140282743909792</title>\n<path d=\"M234,-415.3799C234,-407.1745 234,-397.7679 234,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-388.784 234,-378.784 230.5001,-388.784 237.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282743088352 -->\n<g class=\"node\" id=\"node51\">\n<title>140282743088352</title>\n<polygon fill=\"none\" points=\"22.5,-249.5 22.5,-295.5 445.5,-295.5 445.5,-249.5 22.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-268.8\">batch_normalization_29: BatchNormalization</text>\n<polyline fill=\"none\" points=\"300.5,-249.5 300.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"300.5,-272.5 358.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"358.5,-249.5 358.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-280.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"358.5,-272.5 445.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-257.3\">(None, 512)</text>\n</g>\n<!-- 140282743909792&#45;&gt;140282743088352 -->\n<g class=\"edge\" id=\"edge50\">\n<title>140282743909792-&gt;140282743088352</title>\n<path d=\"M234,-332.3799C234,-324.1745 234,-314.7679 234,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-305.784 234,-295.784 230.5001,-305.784 237.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282743090984 -->\n<g class=\"node\" id=\"node52\">\n<title>140282743090984</title>\n<polygon fill=\"none\" points=\"81,-166.5 81,-212.5 387,-212.5 387,-166.5 81,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-185.8\">activation_29: Activation</text>\n<polyline fill=\"none\" points=\"242,-166.5 242,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"242,-189.5 300,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"300,-166.5 300,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-197.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"300,-189.5 387,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-174.3\">(None, 512)</text>\n</g>\n<!-- 140282743088352&#45;&gt;140282743090984 -->\n<g class=\"edge\" id=\"edge51\">\n<title>140282743088352-&gt;140282743090984</title>\n<path d=\"M234,-249.3799C234,-241.1745 234,-231.7679 234,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-222.784 234,-212.784 230.5001,-222.784 237.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282743090144 -->\n<g class=\"node\" id=\"node53\">\n<title>140282743090144</title>\n<polygon fill=\"none\" points=\"91,-83.5 91,-129.5 377,-129.5 377,-83.5 91,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-102.8\">dropout_33: Dropout</text>\n<polyline fill=\"none\" points=\"232,-83.5 232,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"232,-106.5 290,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"290,-83.5 290,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-114.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"290,-106.5 377,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-91.3\">(None, 512)</text>\n</g>\n<!-- 140282743090984&#45;&gt;140282743090144 -->\n<g class=\"edge\" id=\"edge52\">\n<title>140282743090984-&gt;140282743090144</title>\n<path d=\"M234,-166.3799C234,-158.1745 234,-148.7679 234,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-139.784 234,-129.784 230.5001,-139.784 237.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140282743090424 -->\n<g class=\"node\" id=\"node54\">\n<title>140282743090424</title>\n<polygon fill=\"none\" points=\"108,-.5 108,-46.5 360,-46.5 360,-.5 108,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-19.8\">dense_8: Dense</text>\n<polyline fill=\"none\" points=\"215,-.5 215,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"215,-23.5 273,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"273,-.5 273,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-31.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"273,-23.5 360,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140282743090144&#45;&gt;140282743090424 -->\n<g class=\"edge\" id=\"edge53\">\n<title>140282743090144-&gt;140282743090424</title>\n<path d=\"M234,-83.3799C234,-75.1745 234,-65.7679 234,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"237.5001,-56.784 234,-46.784 230.5001,-56.784 237.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "af33HEm3gO_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOqDcmmmszJz",
        "colab_type": "code",
        "outputId": "b9ca7bac-3e09-4db4-989c-8305d29056aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "cell_type": "code",
      "source": [
        "#法1\n",
        "callbacks_list = [\n",
        "    # Interrupts training when improvement stops\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Monitors the model’s validation accuracy\n",
        "        monitor='val_acc',\n",
        "        # Interrupts training when accuracy has stopped \n",
        "        # improving for more than one epoch (that is, two epochs)\n",
        "        patience=5,\n",
        "    ),\n",
        "    # Saves the current weights after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        # Path to the destination model file\n",
        "        filepath= os.path.join(tempfile.gettempdir(), 'saved_ResNet_wt.h5'),\n",
        "        # These two arguments mean you won’t overwrite the model file \n",
        "        # unless val_loss has improved, \n",
        "        monitor='val_loss',\n",
        "        # which allows you to keep the best model seen during training\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 128, validation_split = 0.2, epochs = 40, callbacks = callbacks_list)\n",
        "          \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "40000/40000 [==============================] - 145s 4ms/step - loss: 1.7281 - acc: 0.4000 - val_loss: 2.3659 - val_acc: 0.3231\n",
            "Epoch 2/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 1.1927 - acc: 0.5826 - val_loss: 1.2764 - val_acc: 0.5719\n",
            "Epoch 3/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.9021 - acc: 0.6867 - val_loss: 1.1411 - val_acc: 0.6293\n",
            "Epoch 4/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.7311 - acc: 0.7449 - val_loss: 0.8386 - val_acc: 0.7321\n",
            "Epoch 5/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.6148 - acc: 0.7828 - val_loss: 0.7884 - val_acc: 0.7549\n",
            "Epoch 6/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.5264 - acc: 0.8166 - val_loss: 0.7058 - val_acc: 0.7854\n",
            "Epoch 7/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.4577 - acc: 0.8405 - val_loss: 0.7346 - val_acc: 0.7726\n",
            "Epoch 8/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.3974 - acc: 0.8620 - val_loss: 1.0365 - val_acc: 0.7171\n",
            "Epoch 9/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.3523 - acc: 0.8754 - val_loss: 0.6872 - val_acc: 0.7942\n",
            "Epoch 10/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.3045 - acc: 0.8945 - val_loss: 0.7818 - val_acc: 0.7895\n",
            "Epoch 11/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.2701 - acc: 0.9041 - val_loss: 0.6858 - val_acc: 0.8086\n",
            "Epoch 12/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.2354 - acc: 0.9183 - val_loss: 0.7061 - val_acc: 0.8106\n",
            "Epoch 13/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.2046 - acc: 0.9292 - val_loss: 0.6286 - val_acc: 0.8275\n",
            "Epoch 14/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.1885 - acc: 0.9350 - val_loss: 0.5817 - val_acc: 0.8390\n",
            "Epoch 15/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.1637 - acc: 0.9427 - val_loss: 0.7174 - val_acc: 0.8237\n",
            "Epoch 16/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.1511 - acc: 0.9477 - val_loss: 0.7486 - val_acc: 0.8185\n",
            "Epoch 17/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.1331 - acc: 0.9535 - val_loss: 0.6976 - val_acc: 0.8251\n",
            "Epoch 18/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.1209 - acc: 0.9579 - val_loss: 0.7877 - val_acc: 0.8234\n",
            "Epoch 19/40\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.1029 - acc: 0.9649 - val_loss: 0.8268 - val_acc: 0.8156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9kBoSiwRsfJ",
        "colab_type": "code",
        "outputId": "3fe3b0bf-a774-42e4-c57e-50397a707916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "cell_type": "code",
      "source": [
        "#法1\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwdx6PDcSQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f961cd15240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f961ccabb38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y8gOu3DoSQa8",
        "colab_type": "code",
        "outputId": "a427b786-4708-4f5a-acd2-fb6c16145be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "#法1\n",
        "# 載入weights\n",
        "weight_path = os.path.join(tempfile.gettempdir(), 'saved_ResNet_wt.h5')\n",
        "model.load_weights(weight_path)\n",
        "\n",
        "# Evaluate \n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 11s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OyVob51uTjti",
        "colab_type": "code",
        "outputId": "ad797160-ed73-4bcb-fce7-30e307b38306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#法1\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.617426807975769\n",
            "Test accuracy: 0.8281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bW_C0MW2-2lV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1.5. *Layer weights sharing*\n",
        "\n",
        "One more important feature of the functional API is the ability to reuse a layer instance several times where instead of instantiating a new layer for each call, you reuse the same weights with every call. This allows you to build models that have shared branches—several branches that all share the same knowledge and perform the same operations.  \n",
        "\n",
        "####  Example - semantic similarity between two sentences\n",
        "\n",
        "For example, consider a model that attempts to assess the semantic similarity between two sentences. The model has two inputs (the two sentences to compare) and outputs a score between 0 and 1, where 0 means unrelated sentences and 1 means sentences that are either identical or reformulations of each other. Such a model could be useful in many applications, including deduplicating natural-language queries in a dialog system. \n",
        "\n",
        "In this setup, the two input sentences are interchangeable, because semantic similarity is a symmetrical relationship: the similarity of A to B is identical to the similarity of B to A. For this reason, it wouldn’t make sense to learn two independent models for processing each input sentence. Rather, you want to process both with a single LSTM layer. The representations of this LSTM layer (its weights) are learned based on both inputs simultaneously. This is what we call a Siamese LSTM model or a shared LSTM.\n",
        "\n",
        "    Note: Siamese network is a special type of neural network architecture. Instead of learning to classify its\n",
        "    inputs, the Siamese neural network learns to differentiate between two inputs. It learns the similarity.\n",
        "\n",
        "Here’s how to implement such a model using layer sharing (layer reuse) in the Keras functional API:"
      ]
    },
    {
      "metadata": {
        "id": "8_eud_Pszu2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "在這裡, 我們將使用真實文本資料來訓練Siamese network\n",
        "\n",
        "文本資料來自Quora這個問答網站\n",
        "\n",
        "[https://www.kaggle.com/quora/question-pairs-dataset](https://www.kaggle.com/quora/question-pairs-dataset)\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1000/1*8inl5NyNsmEcqKOPMewgjA.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "ovSXfKZ5TTfT",
        "colab_type": "code",
        "outputId": "5f2b0bbf-6725-40ea-c512-7c499d8c844b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "#下載資料集\n",
        "\n",
        "!wget --no-check-certificate -r 'https://docs.google.com/uc?export=download&id=1Ey3PnfSV2SnBHFFiAwjUh2M49WEa9-Al' -O questions.csv.zip\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(open('questions.csv.zip', 'rb')) as f:\n",
        "    f.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2018-11-04 10:11:52--  https://docs.google.com/uc?export=download&id=1Ey3PnfSV2SnBHFFiAwjUh2M49WEa9-Al\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.139, 108.177.111.101, 108.177.111.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-ac-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2jk9jikrj7fv65v030uitsne2khsqn9e/1541325600000/05881448651423052326/*/1Ey3PnfSV2SnBHFFiAwjUh2M49WEa9-Al?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2018-11-04 10:11:54--  https://doc-00-ac-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2jk9jikrj7fv65v030uitsne2khsqn9e/1541325600000/05881448651423052326/*/1Ey3PnfSV2SnBHFFiAwjUh2M49WEa9-Al?e=download\n",
            "Resolving doc-00-ac-docs.googleusercontent.com (doc-00-ac-docs.googleusercontent.com)... 173.194.198.132, 2607:f8b0:4001:c1c::84\n",
            "Connecting to doc-00-ac-docs.googleusercontent.com (doc-00-ac-docs.googleusercontent.com)|173.194.198.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘questions.csv.zip’\n",
            "\n",
            "questions.csv.zip       [  <=>               ]  21.38M  63.7MB/s    in 0.3s    \n",
            "\n",
            "2018-11-04 10:11:55 (63.7 MB/s) - ‘questions.csv.zip’ saved [22418615]\n",
            "\n",
            "FINISHED --2018-11-04 10:11:55--\n",
            "Total wall clock time: 2.9s\n",
            "Downloaded: 1 files, 21M in 0.3s (63.7 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y3c7ku9NCx5y",
        "colab_type": "code",
        "outputId": "94d31d83-a22e-4fee-9c79-ea9a5b21852b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "cell_type": "code",
      "source": [
        "#下載Ｇoogle word embeedings\n",
        "!wget --no-check-certificate -r 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz' -O GoogleNews-vectors-negative300.bin.gz\n",
        "\n",
        "\n",
        "#https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2018-11-04 10:12:09--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.229.141\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.229.141|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  82.9MB/s    in 19s     \n",
            "\n",
            "2018-11-04 10:12:29 (82.0 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n",
            "FINISHED --2018-11-04 10:12:29--\n",
            "Total wall clock time: 19s\n",
            "Downloaded: 1 files, 1.5G in 19s (82.0 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NVG7wa5LVbJz",
        "colab_type": "code",
        "outputId": "70330377-40b3-4e31-8e11-fcf800af078a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "cell_type": "code",
      "source": [
        "# 安裝word2vec所需的套件\n",
        "\n",
        "! pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.37)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.37 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.37)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.37->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.37->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iVcvnKJ6VUlF",
        "colab_type": "code",
        "outputId": "60cf1703-c641-4c36-9f20-db57ea16cb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "import gensim\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import itertools\n",
        "\n",
        "#安裝nltk所需的停用詞集\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#以下為資料前處理的functions,請大家課後再細看\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    # Pre process and convert texts to a list of words\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n",
        "\n",
        "#建立word2vec embeedings \n",
        "\n",
        "vocabs = {}\n",
        "\n",
        "def make_w2v_embeddings(df, embedding_dim=300, empty_w2v=False):\n",
        "    #vocabs = {}\n",
        "    vocabs_cnt = 0\n",
        "\n",
        "    vocabs_not_w2v = {}\n",
        "    vocabs_not_w2v_cnt = 0\n",
        "\n",
        "    # Stopwords\n",
        "    stops = set(stopwords.words('english'))\n",
        "\n",
        "    # Load word2vec\n",
        "    print(\"Loading word2vec model(it may takes 2-3 mins) ...\")\n",
        "\n",
        "    if empty_w2v:\n",
        "        word2vec = EmptyWord2Vec\n",
        "    else:\n",
        "        word2vec = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "        #若有下載Google的word embeeding（GoogleNews-vectors-negative300.bin.gz）可執行此行\n",
        "        # word2vec = gensim.models.word2vec.Word2Vec.load(\"./data/Quora-Question-Pairs.w2v\").wv\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Print the number of embedded sentences.\n",
        "        if index != 0 and index % 1000 == 0:\n",
        "            print(\"{:,} sentences embedded.\".format(index), flush=True)\n",
        "\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for question in ['question1', 'question2']:\n",
        "\n",
        "            q2n = []  # q2n -> question numbers representation\n",
        "            for word in text_to_word_list(row[question]):\n",
        "                # Check for unwanted words\n",
        "                if word in stops:\n",
        "                    continue\n",
        "\n",
        "                # If a word is missing from word2vec model.\n",
        "                if word not in word2vec.vocab:\n",
        "                    if word not in vocabs_not_w2v:\n",
        "                        vocabs_not_w2v_cnt += 1\n",
        "                        vocabs_not_w2v[word] = 1\n",
        "\n",
        "                # If you have never seen a word, append it to vocab dictionary.\n",
        "                if word not in vocabs:\n",
        "                    vocabs_cnt += 1\n",
        "                    vocabs[word] = vocabs_cnt\n",
        "                    q2n.append(vocabs_cnt)\n",
        "                else:\n",
        "                    q2n.append(vocabs[word])\n",
        "\n",
        "            # Append question as number representation\n",
        "            df.at[index, question + '_n'] = q2n\n",
        "\n",
        "    embeddings = 1 * np.random.randn(len(vocabs) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "    embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "    # Build the embedding matrix\n",
        "    for word, index in vocabs.items():\n",
        "        if word in word2vec.vocab:\n",
        "            embeddings[index] = word2vec.word_vec(word)\n",
        "    del word2vec\n",
        "\n",
        "    return df, embeddings\n",
        "\n",
        "\n",
        "def split_and_zero_padding(df, max_seq_length):\n",
        "    # Split to dicts\n",
        "    X = {'left': df['question1_n'], 'right': df['question2_n']}\n",
        "\n",
        "    # Zero padding\n",
        "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
        "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EmptyWord2Vec:\n",
        "    \"\"\"\n",
        "    Just for test use.\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "word_vec = {}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vLlvWoKZRuAJ",
        "colab_type": "code",
        "outputId": "650c2f0b-c928-420a-f253-e7046e7de4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6821
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "TRAIN_CSV = 'questions.csv'\n",
        "\n",
        "# Load training set\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "for q in ['question1', 'question2']:\n",
        "    train_df[q + '_n'] = train_df[q]\n",
        "\n",
        "# Make word2vec embeddings\n",
        "embedding_dim = 300\n",
        "max_seq_length = 20\n",
        "\n",
        "#不使用word2vec訓練好摸word embeedings, 使用隨機初始化的embeedings, 交由神經網路來train其權重\n",
        "use_w2v = False\n",
        "\n",
        "train_df, embeddings = make_w2v_embeddings(train_df, embedding_dim=embedding_dim, empty_w2v=not use_w2v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word2vec model(it may takes 2-3 mins) ...\n",
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n",
            "3,000 sentences embedded.\n",
            "4,000 sentences embedded.\n",
            "5,000 sentences embedded.\n",
            "6,000 sentences embedded.\n",
            "7,000 sentences embedded.\n",
            "8,000 sentences embedded.\n",
            "9,000 sentences embedded.\n",
            "10,000 sentences embedded.\n",
            "11,000 sentences embedded.\n",
            "12,000 sentences embedded.\n",
            "13,000 sentences embedded.\n",
            "14,000 sentences embedded.\n",
            "15,000 sentences embedded.\n",
            "16,000 sentences embedded.\n",
            "17,000 sentences embedded.\n",
            "18,000 sentences embedded.\n",
            "19,000 sentences embedded.\n",
            "20,000 sentences embedded.\n",
            "21,000 sentences embedded.\n",
            "22,000 sentences embedded.\n",
            "23,000 sentences embedded.\n",
            "24,000 sentences embedded.\n",
            "25,000 sentences embedded.\n",
            "26,000 sentences embedded.\n",
            "27,000 sentences embedded.\n",
            "28,000 sentences embedded.\n",
            "29,000 sentences embedded.\n",
            "30,000 sentences embedded.\n",
            "31,000 sentences embedded.\n",
            "32,000 sentences embedded.\n",
            "33,000 sentences embedded.\n",
            "34,000 sentences embedded.\n",
            "35,000 sentences embedded.\n",
            "36,000 sentences embedded.\n",
            "37,000 sentences embedded.\n",
            "38,000 sentences embedded.\n",
            "39,000 sentences embedded.\n",
            "40,000 sentences embedded.\n",
            "41,000 sentences embedded.\n",
            "42,000 sentences embedded.\n",
            "43,000 sentences embedded.\n",
            "44,000 sentences embedded.\n",
            "45,000 sentences embedded.\n",
            "46,000 sentences embedded.\n",
            "47,000 sentences embedded.\n",
            "48,000 sentences embedded.\n",
            "49,000 sentences embedded.\n",
            "50,000 sentences embedded.\n",
            "51,000 sentences embedded.\n",
            "52,000 sentences embedded.\n",
            "53,000 sentences embedded.\n",
            "54,000 sentences embedded.\n",
            "55,000 sentences embedded.\n",
            "56,000 sentences embedded.\n",
            "57,000 sentences embedded.\n",
            "58,000 sentences embedded.\n",
            "59,000 sentences embedded.\n",
            "60,000 sentences embedded.\n",
            "61,000 sentences embedded.\n",
            "62,000 sentences embedded.\n",
            "63,000 sentences embedded.\n",
            "64,000 sentences embedded.\n",
            "65,000 sentences embedded.\n",
            "66,000 sentences embedded.\n",
            "67,000 sentences embedded.\n",
            "68,000 sentences embedded.\n",
            "69,000 sentences embedded.\n",
            "70,000 sentences embedded.\n",
            "71,000 sentences embedded.\n",
            "72,000 sentences embedded.\n",
            "73,000 sentences embedded.\n",
            "74,000 sentences embedded.\n",
            "75,000 sentences embedded.\n",
            "76,000 sentences embedded.\n",
            "77,000 sentences embedded.\n",
            "78,000 sentences embedded.\n",
            "79,000 sentences embedded.\n",
            "80,000 sentences embedded.\n",
            "81,000 sentences embedded.\n",
            "82,000 sentences embedded.\n",
            "83,000 sentences embedded.\n",
            "84,000 sentences embedded.\n",
            "85,000 sentences embedded.\n",
            "86,000 sentences embedded.\n",
            "87,000 sentences embedded.\n",
            "88,000 sentences embedded.\n",
            "89,000 sentences embedded.\n",
            "90,000 sentences embedded.\n",
            "91,000 sentences embedded.\n",
            "92,000 sentences embedded.\n",
            "93,000 sentences embedded.\n",
            "94,000 sentences embedded.\n",
            "95,000 sentences embedded.\n",
            "96,000 sentences embedded.\n",
            "97,000 sentences embedded.\n",
            "98,000 sentences embedded.\n",
            "99,000 sentences embedded.\n",
            "100,000 sentences embedded.\n",
            "101,000 sentences embedded.\n",
            "102,000 sentences embedded.\n",
            "103,000 sentences embedded.\n",
            "104,000 sentences embedded.\n",
            "105,000 sentences embedded.\n",
            "106,000 sentences embedded.\n",
            "107,000 sentences embedded.\n",
            "108,000 sentences embedded.\n",
            "109,000 sentences embedded.\n",
            "110,000 sentences embedded.\n",
            "111,000 sentences embedded.\n",
            "112,000 sentences embedded.\n",
            "113,000 sentences embedded.\n",
            "114,000 sentences embedded.\n",
            "115,000 sentences embedded.\n",
            "116,000 sentences embedded.\n",
            "117,000 sentences embedded.\n",
            "118,000 sentences embedded.\n",
            "119,000 sentences embedded.\n",
            "120,000 sentences embedded.\n",
            "121,000 sentences embedded.\n",
            "122,000 sentences embedded.\n",
            "123,000 sentences embedded.\n",
            "124,000 sentences embedded.\n",
            "125,000 sentences embedded.\n",
            "126,000 sentences embedded.\n",
            "127,000 sentences embedded.\n",
            "128,000 sentences embedded.\n",
            "129,000 sentences embedded.\n",
            "130,000 sentences embedded.\n",
            "131,000 sentences embedded.\n",
            "132,000 sentences embedded.\n",
            "133,000 sentences embedded.\n",
            "134,000 sentences embedded.\n",
            "135,000 sentences embedded.\n",
            "136,000 sentences embedded.\n",
            "137,000 sentences embedded.\n",
            "138,000 sentences embedded.\n",
            "139,000 sentences embedded.\n",
            "140,000 sentences embedded.\n",
            "141,000 sentences embedded.\n",
            "142,000 sentences embedded.\n",
            "143,000 sentences embedded.\n",
            "144,000 sentences embedded.\n",
            "145,000 sentences embedded.\n",
            "146,000 sentences embedded.\n",
            "147,000 sentences embedded.\n",
            "148,000 sentences embedded.\n",
            "149,000 sentences embedded.\n",
            "150,000 sentences embedded.\n",
            "151,000 sentences embedded.\n",
            "152,000 sentences embedded.\n",
            "153,000 sentences embedded.\n",
            "154,000 sentences embedded.\n",
            "155,000 sentences embedded.\n",
            "156,000 sentences embedded.\n",
            "157,000 sentences embedded.\n",
            "158,000 sentences embedded.\n",
            "159,000 sentences embedded.\n",
            "160,000 sentences embedded.\n",
            "161,000 sentences embedded.\n",
            "162,000 sentences embedded.\n",
            "163,000 sentences embedded.\n",
            "164,000 sentences embedded.\n",
            "165,000 sentences embedded.\n",
            "166,000 sentences embedded.\n",
            "167,000 sentences embedded.\n",
            "168,000 sentences embedded.\n",
            "169,000 sentences embedded.\n",
            "170,000 sentences embedded.\n",
            "171,000 sentences embedded.\n",
            "172,000 sentences embedded.\n",
            "173,000 sentences embedded.\n",
            "174,000 sentences embedded.\n",
            "175,000 sentences embedded.\n",
            "176,000 sentences embedded.\n",
            "177,000 sentences embedded.\n",
            "178,000 sentences embedded.\n",
            "179,000 sentences embedded.\n",
            "180,000 sentences embedded.\n",
            "181,000 sentences embedded.\n",
            "182,000 sentences embedded.\n",
            "183,000 sentences embedded.\n",
            "184,000 sentences embedded.\n",
            "185,000 sentences embedded.\n",
            "186,000 sentences embedded.\n",
            "187,000 sentences embedded.\n",
            "188,000 sentences embedded.\n",
            "189,000 sentences embedded.\n",
            "190,000 sentences embedded.\n",
            "191,000 sentences embedded.\n",
            "192,000 sentences embedded.\n",
            "193,000 sentences embedded.\n",
            "194,000 sentences embedded.\n",
            "195,000 sentences embedded.\n",
            "196,000 sentences embedded.\n",
            "197,000 sentences embedded.\n",
            "198,000 sentences embedded.\n",
            "199,000 sentences embedded.\n",
            "200,000 sentences embedded.\n",
            "201,000 sentences embedded.\n",
            "202,000 sentences embedded.\n",
            "203,000 sentences embedded.\n",
            "204,000 sentences embedded.\n",
            "205,000 sentences embedded.\n",
            "206,000 sentences embedded.\n",
            "207,000 sentences embedded.\n",
            "208,000 sentences embedded.\n",
            "209,000 sentences embedded.\n",
            "210,000 sentences embedded.\n",
            "211,000 sentences embedded.\n",
            "212,000 sentences embedded.\n",
            "213,000 sentences embedded.\n",
            "214,000 sentences embedded.\n",
            "215,000 sentences embedded.\n",
            "216,000 sentences embedded.\n",
            "217,000 sentences embedded.\n",
            "218,000 sentences embedded.\n",
            "219,000 sentences embedded.\n",
            "220,000 sentences embedded.\n",
            "221,000 sentences embedded.\n",
            "222,000 sentences embedded.\n",
            "223,000 sentences embedded.\n",
            "224,000 sentences embedded.\n",
            "225,000 sentences embedded.\n",
            "226,000 sentences embedded.\n",
            "227,000 sentences embedded.\n",
            "228,000 sentences embedded.\n",
            "229,000 sentences embedded.\n",
            "230,000 sentences embedded.\n",
            "231,000 sentences embedded.\n",
            "232,000 sentences embedded.\n",
            "233,000 sentences embedded.\n",
            "234,000 sentences embedded.\n",
            "235,000 sentences embedded.\n",
            "236,000 sentences embedded.\n",
            "237,000 sentences embedded.\n",
            "238,000 sentences embedded.\n",
            "239,000 sentences embedded.\n",
            "240,000 sentences embedded.\n",
            "241,000 sentences embedded.\n",
            "242,000 sentences embedded.\n",
            "243,000 sentences embedded.\n",
            "244,000 sentences embedded.\n",
            "245,000 sentences embedded.\n",
            "246,000 sentences embedded.\n",
            "247,000 sentences embedded.\n",
            "248,000 sentences embedded.\n",
            "249,000 sentences embedded.\n",
            "250,000 sentences embedded.\n",
            "251,000 sentences embedded.\n",
            "252,000 sentences embedded.\n",
            "253,000 sentences embedded.\n",
            "254,000 sentences embedded.\n",
            "255,000 sentences embedded.\n",
            "256,000 sentences embedded.\n",
            "257,000 sentences embedded.\n",
            "258,000 sentences embedded.\n",
            "259,000 sentences embedded.\n",
            "260,000 sentences embedded.\n",
            "261,000 sentences embedded.\n",
            "262,000 sentences embedded.\n",
            "263,000 sentences embedded.\n",
            "264,000 sentences embedded.\n",
            "265,000 sentences embedded.\n",
            "266,000 sentences embedded.\n",
            "267,000 sentences embedded.\n",
            "268,000 sentences embedded.\n",
            "269,000 sentences embedded.\n",
            "270,000 sentences embedded.\n",
            "271,000 sentences embedded.\n",
            "272,000 sentences embedded.\n",
            "273,000 sentences embedded.\n",
            "274,000 sentences embedded.\n",
            "275,000 sentences embedded.\n",
            "276,000 sentences embedded.\n",
            "277,000 sentences embedded.\n",
            "278,000 sentences embedded.\n",
            "279,000 sentences embedded.\n",
            "280,000 sentences embedded.\n",
            "281,000 sentences embedded.\n",
            "282,000 sentences embedded.\n",
            "283,000 sentences embedded.\n",
            "284,000 sentences embedded.\n",
            "285,000 sentences embedded.\n",
            "286,000 sentences embedded.\n",
            "287,000 sentences embedded.\n",
            "288,000 sentences embedded.\n",
            "289,000 sentences embedded.\n",
            "290,000 sentences embedded.\n",
            "291,000 sentences embedded.\n",
            "292,000 sentences embedded.\n",
            "293,000 sentences embedded.\n",
            "294,000 sentences embedded.\n",
            "295,000 sentences embedded.\n",
            "296,000 sentences embedded.\n",
            "297,000 sentences embedded.\n",
            "298,000 sentences embedded.\n",
            "299,000 sentences embedded.\n",
            "300,000 sentences embedded.\n",
            "301,000 sentences embedded.\n",
            "302,000 sentences embedded.\n",
            "303,000 sentences embedded.\n",
            "304,000 sentences embedded.\n",
            "305,000 sentences embedded.\n",
            "306,000 sentences embedded.\n",
            "307,000 sentences embedded.\n",
            "308,000 sentences embedded.\n",
            "309,000 sentences embedded.\n",
            "310,000 sentences embedded.\n",
            "311,000 sentences embedded.\n",
            "312,000 sentences embedded.\n",
            "313,000 sentences embedded.\n",
            "314,000 sentences embedded.\n",
            "315,000 sentences embedded.\n",
            "316,000 sentences embedded.\n",
            "317,000 sentences embedded.\n",
            "318,000 sentences embedded.\n",
            "319,000 sentences embedded.\n",
            "320,000 sentences embedded.\n",
            "321,000 sentences embedded.\n",
            "322,000 sentences embedded.\n",
            "323,000 sentences embedded.\n",
            "324,000 sentences embedded.\n",
            "325,000 sentences embedded.\n",
            "326,000 sentences embedded.\n",
            "327,000 sentences embedded.\n",
            "328,000 sentences embedded.\n",
            "329,000 sentences embedded.\n",
            "330,000 sentences embedded.\n",
            "331,000 sentences embedded.\n",
            "332,000 sentences embedded.\n",
            "333,000 sentences embedded.\n",
            "334,000 sentences embedded.\n",
            "335,000 sentences embedded.\n",
            "336,000 sentences embedded.\n",
            "337,000 sentences embedded.\n",
            "338,000 sentences embedded.\n",
            "339,000 sentences embedded.\n",
            "340,000 sentences embedded.\n",
            "341,000 sentences embedded.\n",
            "342,000 sentences embedded.\n",
            "343,000 sentences embedded.\n",
            "344,000 sentences embedded.\n",
            "345,000 sentences embedded.\n",
            "346,000 sentences embedded.\n",
            "347,000 sentences embedded.\n",
            "348,000 sentences embedded.\n",
            "349,000 sentences embedded.\n",
            "350,000 sentences embedded.\n",
            "351,000 sentences embedded.\n",
            "352,000 sentences embedded.\n",
            "353,000 sentences embedded.\n",
            "354,000 sentences embedded.\n",
            "355,000 sentences embedded.\n",
            "356,000 sentences embedded.\n",
            "357,000 sentences embedded.\n",
            "358,000 sentences embedded.\n",
            "359,000 sentences embedded.\n",
            "360,000 sentences embedded.\n",
            "361,000 sentences embedded.\n",
            "362,000 sentences embedded.\n",
            "363,000 sentences embedded.\n",
            "364,000 sentences embedded.\n",
            "365,000 sentences embedded.\n",
            "366,000 sentences embedded.\n",
            "367,000 sentences embedded.\n",
            "368,000 sentences embedded.\n",
            "369,000 sentences embedded.\n",
            "370,000 sentences embedded.\n",
            "371,000 sentences embedded.\n",
            "372,000 sentences embedded.\n",
            "373,000 sentences embedded.\n",
            "374,000 sentences embedded.\n",
            "375,000 sentences embedded.\n",
            "376,000 sentences embedded.\n",
            "377,000 sentences embedded.\n",
            "378,000 sentences embedded.\n",
            "379,000 sentences embedded.\n",
            "380,000 sentences embedded.\n",
            "381,000 sentences embedded.\n",
            "382,000 sentences embedded.\n",
            "383,000 sentences embedded.\n",
            "384,000 sentences embedded.\n",
            "385,000 sentences embedded.\n",
            "386,000 sentences embedded.\n",
            "387,000 sentences embedded.\n",
            "388,000 sentences embedded.\n",
            "389,000 sentences embedded.\n",
            "390,000 sentences embedded.\n",
            "391,000 sentences embedded.\n",
            "392,000 sentences embedded.\n",
            "393,000 sentences embedded.\n",
            "394,000 sentences embedded.\n",
            "395,000 sentences embedded.\n",
            "396,000 sentences embedded.\n",
            "397,000 sentences embedded.\n",
            "398,000 sentences embedded.\n",
            "399,000 sentences embedded.\n",
            "400,000 sentences embedded.\n",
            "401,000 sentences embedded.\n",
            "402,000 sentences embedded.\n",
            "403,000 sentences embedded.\n",
            "404,000 sentences embedded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dQyXyWfKjbWm",
        "colab_type": "code",
        "outputId": "3d766260-1e28-4fa4-b9a5-bb70737749d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#embeedings的維度為300\n",
        "embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85875, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "9W_F67xnjg7I",
        "colab_type": "code",
        "outputId": "4399d53b-1ff2-4ed1-cf47-ee91b6d8a392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1025
        }
      },
      "cell_type": "code",
      "source": [
        "#觀查其中一個詞的embedding向量內容\n",
        "embeddings[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.38364957, -0.26879586, -0.06596126, -1.39757429,  0.76987036,\n",
              "       -1.02234309,  0.94062954, -0.64016138, -1.82078856, -1.00352242,\n",
              "       -0.26517278,  0.70722258,  0.26891933, -0.61799643, -1.27027618,\n",
              "       -0.81611625, -1.15383747, -0.47841508, -1.04315984,  1.96259416,\n",
              "       -0.47600498, -0.30744685,  1.27818641,  0.6605044 , -0.41666049,\n",
              "        1.01230792,  0.52803812,  0.1990174 , -0.41910872, -1.33454405,\n",
              "        0.96383357,  0.28256065, -0.27146935,  1.63116663, -0.93793926,\n",
              "       -1.34437249, -0.68198521,  0.34336885, -1.11959809, -0.81809045,\n",
              "        0.26940654, -0.5268423 , -0.85947327,  0.67620704, -1.96643059,\n",
              "        1.15625116,  0.78262689,  1.26832895, -0.72577582, -0.52806436,\n",
              "       -0.27662911,  0.20934806, -0.18836113, -1.51751348,  0.62678425,\n",
              "        1.14168914,  0.43046918, -1.00209276,  0.78647026, -0.18222903,\n",
              "        0.19076548,  1.56551737, -1.23003002, -1.93593086,  0.27761621,\n",
              "       -0.19357746,  0.49919449,  0.01041363,  0.1477327 ,  0.80024119,\n",
              "       -0.14855582, -0.69293203, -0.13389674, -1.40678903, -0.18644331,\n",
              "       -0.27179153, -0.25452032,  0.24646248, -0.87219356, -0.86777681,\n",
              "       -0.37544562,  0.68601288, -0.75107745,  0.13514107, -0.32789078,\n",
              "        0.24630145,  0.4717079 , -0.03834549, -0.78492045,  0.2886409 ,\n",
              "       -1.55994306,  1.26745345,  1.42104419, -0.01891604, -0.93138956,\n",
              "        0.4992123 ,  0.65150651,  1.26456715,  0.0501327 , -1.46452731,\n",
              "        0.70943515,  1.43456062,  0.82830875, -0.5738368 ,  0.46615064,\n",
              "       -0.335301  , -0.30194814,  0.13731558, -0.77303823, -1.17083098,\n",
              "        0.41676387, -1.1675969 ,  1.77020518, -2.15518796, -0.50623065,\n",
              "       -1.02281428, -0.12850099, -0.70332337, -0.21905062,  0.05235   ,\n",
              "        1.0648541 , -1.14515225, -0.03165414, -0.37785447,  1.63611374,\n",
              "       -0.52896121,  0.95418122, -1.04338533, -1.34487859, -1.08803294,\n",
              "       -0.26217754, -1.35944879, -1.02439021, -0.9939938 , -0.51321312,\n",
              "        0.68622045, -2.09994347, -1.802156  ,  0.93309169, -0.68335624,\n",
              "       -0.07972068, -0.16872152,  1.28285022, -1.79328792,  0.05605324,\n",
              "        1.15593132,  0.917637  ,  0.39932587, -0.37600421, -2.80368574,\n",
              "       -0.97064389, -0.07849343, -0.64008617, -0.4571833 ,  0.6162836 ,\n",
              "       -0.59510603,  1.86441971,  0.63243093,  0.60454764, -0.48083943,\n",
              "        0.51783783,  1.17746437,  0.8064767 , -0.35664402,  0.91215352,\n",
              "       -0.19316094,  0.78275121, -2.18263931,  0.68393001,  0.39395341,\n",
              "        0.12529744, -0.88950538, -0.23822104,  0.23557295, -0.71563141,\n",
              "       -1.58365869, -0.23543819,  1.51720636, -0.48084071,  0.49408817,\n",
              "       -0.41306746,  0.85545139, -0.94970123,  0.78434026,  0.93210262,\n",
              "       -0.40126348,  1.63355455,  1.83070222,  0.84700768,  0.08588319,\n",
              "       -0.17541519,  0.49261122,  1.32566474,  1.00879553,  0.35063779,\n",
              "       -1.1995514 , -0.75896867,  0.62402848, -1.38460162,  0.14276113,\n",
              "       -0.40498692, -0.50110617, -0.67884733, -0.10752473,  2.47448962,\n",
              "       -0.39632695, -0.46675741,  0.00848674,  0.20060689, -1.38466548,\n",
              "        0.23084956,  1.14740696, -0.14912632,  1.08519648, -0.0588106 ,\n",
              "       -1.05921857, -0.09502027,  0.35176625, -1.07312017,  1.48407937,\n",
              "       -0.77879058, -0.44417062, -0.93570129, -0.66242449, -1.25282845,\n",
              "       -2.25171586,  0.85752526, -0.49687969,  0.69183321, -0.3089423 ,\n",
              "       -0.82019013, -0.81259979,  1.98742732, -1.1931137 ,  0.89565195,\n",
              "        0.39972123, -0.39942337,  1.09596312, -0.26275171, -1.15283706,\n",
              "        0.38161656,  0.45878829,  0.44984333,  1.61846182,  1.23062413,\n",
              "        0.68466569, -2.54199713,  0.05166435,  0.83091673, -0.41540914,\n",
              "        1.75624072, -0.12878745,  1.33585177, -1.42490763,  0.10092061,\n",
              "        1.17219427, -0.7855709 , -0.21695802, -1.34505084, -0.99133197,\n",
              "        0.17923009, -3.20828133,  0.2782283 , -0.75245943,  0.45251129,\n",
              "       -1.30940694, -0.43487232,  0.35182794, -0.26418175, -0.49434699,\n",
              "       -0.64241155, -0.16930032,  0.04230733,  0.30835857, -1.14860071,\n",
              "        1.93273348,  0.8482403 , -0.76825438, -0.4385675 ,  0.08281999,\n",
              "        0.5314479 , -1.05466079, -0.9733742 , -0.14545164,  0.010342  ,\n",
              "       -0.12708814, -1.02160103,  0.60021469,  0.6120531 ,  0.32048092,\n",
              "       -0.28627652,  1.94761891,  0.23395374, -0.8055362 , -1.48127528,\n",
              "       -0.53080923, -0.14342351, -0.24092919, -1.35810992,  0.0276056 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "dTBHlrmKXOJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split to train validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "validation_size = int(len(train_df) * 0.1)\n",
        "training_size = len(train_df) - validation_size\n",
        "\n",
        "X = train_df[['question1_n', 'question2_n']]\n",
        "Y = train_df['is_duplicate']\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
        "\n",
        "X_train = split_and_zero_padding(X_train, max_seq_length)\n",
        "X_validation = split_and_zero_padding(X_validation, max_seq_length)\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEhC1YtzZ03B",
        "colab_type": "code",
        "outputId": "989f0ec4-bc64-4c81-face-808947f0ec6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2705
        }
      },
      "cell_type": "code",
      "source": [
        "#觀察一下，經前處理的training資料，詞都已轉成整數數字\n",
        "train_df.head(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>question1_n</th>\n",
              "      <th>question2_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 1, 2, 3, 4, 5, 6]</td>\n",
              "      <td>[1, 1, 2, 3, 4, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>[7, 8, 9, 10, 10, 11, 12]</td>\n",
              "      <td>[13, 14, 15, 16, 17, 8, 9, 10, 10, 11, 12, 18]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>[19, 20, 21, 22, 23, 24]</td>\n",
              "      <td>[21, 20, 25, 26, 27]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>[28, 29, 30]</td>\n",
              "      <td>[31, 32, 33, 34, 35, 36, 33, 37, 36, 34]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>[38, 39, 40, 41, 42, 43, 44, 45, 46, 47]</td>\n",
              "      <td>[48, 13, 49, 43, 40]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "      <td>[50, 51, 52, 53, 54, 55, 54, 56, 57]</td>\n",
              "      <td>[58, 52, 53, 55, 59, 52, 57]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[60, 61]</td>\n",
              "      <td>[62, 63, 64, 65, 66, 67, 68]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "      <td>[69, 70]</td>\n",
              "      <td>[71, 70]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "      <td>[72, 73]</td>\n",
              "      <td>[72, 73]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "      <td>[74, 75, 51, 76, 77, 78, 79]</td>\n",
              "      <td>[76, 74, 79, 80, 21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>Method to find separation of slits using fresn...</td>\n",
              "      <td>What are some of the things technicians can te...</td>\n",
              "      <td>0</td>\n",
              "      <td>[81, 31, 82, 83, 23, 84, 85]</td>\n",
              "      <td>[86, 87, 88, 89, 90, 91, 92]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "      <td>[93, 31, 94, 95]</td>\n",
              "      <td>[96, 94, 95]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "      <td>[97, 98, 99, 100]</td>\n",
              "      <td>[97, 98, 99, 100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "      <td>[101, 102, 103, 104]</td>\n",
              "      <td>[101, 102, 103]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>0</td>\n",
              "      <td>[105, 106, 107, 108, 109, 110, 111, 112, 113, ...</td>\n",
              "      <td>[105, 106, 107, 108, 109, 110, 111, 112, 113, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>What would a Trump presidency mean for current...</td>\n",
              "      <td>How will a Trump presidency affect the student...</td>\n",
              "      <td>1</td>\n",
              "      <td>[13, 117, 118, 119, 120, 121, 122, 123, 124, 109]</td>\n",
              "      <td>[117, 118, 125, 123, 126, 112, 127, 128, 112]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>What does manipulation mean?</td>\n",
              "      <td>What does manipulation means?</td>\n",
              "      <td>1</td>\n",
              "      <td>[129, 119]</td>\n",
              "      <td>[129, 130]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>Why do girls want to be friends with the guy t...</td>\n",
              "      <td>How do guys feel after rejecting a girl?</td>\n",
              "      <td>0</td>\n",
              "      <td>[131, 132, 133, 134, 135]</td>\n",
              "      <td>[136, 137, 138, 139]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>Why are so many Quora users posting questions ...</td>\n",
              "      <td>Why do people ask Quora questions which can be...</td>\n",
              "      <td>1</td>\n",
              "      <td>[140, 141, 142, 143, 144, 145, 146, 147]</td>\n",
              "      <td>[148, 149, 141, 144, 146, 150, 147]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>Which is the best digital marketing institutio...</td>\n",
              "      <td>Which is the best digital marketing institute ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[151, 152, 153, 154, 155]</td>\n",
              "      <td>[151, 152, 153, 156, 157]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>Why do rockets look white?</td>\n",
              "      <td>Why are rockets and boosters painted white?</td>\n",
              "      <td>1</td>\n",
              "      <td>[158, 159, 160]</td>\n",
              "      <td>[158, 161, 162, 160]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>What's causing someone to be jealous?</td>\n",
              "      <td>What can I do to avoid being jealous of someone?</td>\n",
              "      <td>0</td>\n",
              "      <td>[163, 164, 165]</td>\n",
              "      <td>[166, 165, 164]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>What are the questions should not ask on Quora?</td>\n",
              "      <td>Which question should I ask on Quora?</td>\n",
              "      <td>0</td>\n",
              "      <td>[144, 149, 141]</td>\n",
              "      <td>[167, 149, 141]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>How much is 30 kV in HP?</td>\n",
              "      <td>Where can I find a conversion chart for CC to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[168, 169, 170, 171]</td>\n",
              "      <td>[31, 172, 173, 174, 175]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>What does it mean that every time I look at th...</td>\n",
              "      <td>How many times a day do a clock’s hands overlap?</td>\n",
              "      <td>0</td>\n",
              "      <td>[119, 176, 177, 159, 178, 179]</td>\n",
              "      <td>[140, 180, 181, 178, 182, 183]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>What are some tips on making it through the jo...</td>\n",
              "      <td>What are some tips on making it through the jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>[184, 185, 186, 187, 188, 189]</td>\n",
              "      <td>[184, 185, 186, 187, 188, 190, 191]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>What is web application?</td>\n",
              "      <td>What is the web application framework?</td>\n",
              "      <td>0</td>\n",
              "      <td>[192, 193]</td>\n",
              "      <td>[192, 193, 194]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>Does society place too much importance on sports?</td>\n",
              "      <td>How do sports contribute to the society?</td>\n",
              "      <td>0</td>\n",
              "      <td>[195, 196, 168, 197, 198]</td>\n",
              "      <td>[198, 199, 195]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>57</td>\n",
              "      <td>58</td>\n",
              "      <td>What is best way to make money online?</td>\n",
              "      <td>What is best way to ask for money online?</td>\n",
              "      <td>0</td>\n",
              "      <td>[151, 200, 97, 201, 202]</td>\n",
              "      <td>[151, 200, 149, 201, 202]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>How should I prepare for CA final law?</td>\n",
              "      <td>How one should know that he/she completely pre...</td>\n",
              "      <td>1</td>\n",
              "      <td>[203, 204, 205, 206]</td>\n",
              "      <td>[38, 207, 208, 203, 204, 205, 209]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>70</td>\n",
              "      <td>141</td>\n",
              "      <td>142</td>\n",
              "      <td>What are the types of immunity?</td>\n",
              "      <td>What are the different types of immunity in ou...</td>\n",
              "      <td>0</td>\n",
              "      <td>[469, 470]</td>\n",
              "      <td>[471, 469, 470, 472]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>71</td>\n",
              "      <td>143</td>\n",
              "      <td>144</td>\n",
              "      <td>What is a narcissistic personality disorder?</td>\n",
              "      <td>What is narcissistic personality disorder?</td>\n",
              "      <td>1</td>\n",
              "      <td>[473, 474, 475]</td>\n",
              "      <td>[473, 474, 475]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>72</td>\n",
              "      <td>145</td>\n",
              "      <td>146</td>\n",
              "      <td>How I can speak English fluently?</td>\n",
              "      <td>How can I learn to speak English fluently?</td>\n",
              "      <td>1</td>\n",
              "      <td>[476, 477, 478]</td>\n",
              "      <td>[100, 476, 477, 478]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>73</td>\n",
              "      <td>147</td>\n",
              "      <td>148</td>\n",
              "      <td>How helpful is QuickBooks' auto data recovery ...</td>\n",
              "      <td>What is the quickbooks customer support phone ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[479, 480, 481, 482, 406, 483, 66, 327, 410, 4...</td>\n",
              "      <td>[480, 486, 483, 66, 327, 487]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>74</td>\n",
              "      <td>149</td>\n",
              "      <td>150</td>\n",
              "      <td>Who is the richest gambler of all time and how...</td>\n",
              "      <td>Who is the richest gambler of all time and how...</td>\n",
              "      <td>1</td>\n",
              "      <td>[488, 489, 177, 490, 491]</td>\n",
              "      <td>[488, 489, 177, 490, 491, 489]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>151</td>\n",
              "      <td>152</td>\n",
              "      <td>If I fire a bullet backward from an aircraft g...</td>\n",
              "      <td>Do bullets travel faster than the speed of sou...</td>\n",
              "      <td>0</td>\n",
              "      <td>[492, 493, 494, 292, 495, 496, 497, 493, 495, ...</td>\n",
              "      <td>[499, 241, 496, 20, 500, 501, 250, 454, 250, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>76</td>\n",
              "      <td>153</td>\n",
              "      <td>154</td>\n",
              "      <td>How do I prevent breast cancer?</td>\n",
              "      <td>Is breast cancer preventable?</td>\n",
              "      <td>0</td>\n",
              "      <td>[504, 505, 506]</td>\n",
              "      <td>[505, 506, 507]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>77</td>\n",
              "      <td>155</td>\n",
              "      <td>156</td>\n",
              "      <td>How do I log out of my Gmail account on my fri...</td>\n",
              "      <td>How can I know who logged in to my Gmail accou...</td>\n",
              "      <td>0</td>\n",
              "      <td>[508, 402, 509, 392, 66]</td>\n",
              "      <td>[207, 401, 402, 509, 510, 511, 512, 513, 514]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>78</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>How can I make money through the Internet?</td>\n",
              "      <td>What are some different ways to make money onl...</td>\n",
              "      <td>0</td>\n",
              "      <td>[97, 201, 21]</td>\n",
              "      <td>[471, 411, 97, 201, 202, 515, 516, 86]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>79</td>\n",
              "      <td>159</td>\n",
              "      <td>160</td>\n",
              "      <td>What is purpose of life?</td>\n",
              "      <td>What's the purpose of life? What is life actua...</td>\n",
              "      <td>1</td>\n",
              "      <td>[517, 518]</td>\n",
              "      <td>[517, 518, 518, 519]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>80</td>\n",
              "      <td>161</td>\n",
              "      <td>162</td>\n",
              "      <td>When will the BJP government strip all the Mus...</td>\n",
              "      <td>Why India does not apply the \"Burma-Rohingya m...</td>\n",
              "      <td>0</td>\n",
              "      <td>[520, 16, 521, 522, 523, 15, 524, 525, 526, 10...</td>\n",
              "      <td>[6, 388, 528, 10, 527, 529, 530, 531, 532]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>What is the right etiquette for wishing a Jeho...</td>\n",
              "      <td>How important is it to be the first person to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[533, 534, 535, 536, 537, 538, 539]</td>\n",
              "      <td>[449, 101, 540, 541, 164, 538, 539]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>82</td>\n",
              "      <td>165</td>\n",
              "      <td>166</td>\n",
              "      <td>If someone wants to open a commercial FM radio...</td>\n",
              "      <td>I want to make a travel commercial/clip video ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[164, 279, 542, 543, 544, 545, 546, 547, 6, 16...</td>\n",
              "      <td>[132, 97, 241, 543, 549, 67, 550, 6, 318, 551,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>83</td>\n",
              "      <td>167</td>\n",
              "      <td>168</td>\n",
              "      <td>Why do Swiss despise Asians?</td>\n",
              "      <td>Why do technical employees despise sales peopl...</td>\n",
              "      <td>0</td>\n",
              "      <td>[552, 553, 554]</td>\n",
              "      <td>[555, 556, 553, 557, 148, 168]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>84</td>\n",
              "      <td>169</td>\n",
              "      <td>170</td>\n",
              "      <td>What are some of the high salary income jobs i...</td>\n",
              "      <td>What are some high paying jobs for a fresher w...</td>\n",
              "      <td>1</td>\n",
              "      <td>[558, 559, 560, 561, 562, 563]</td>\n",
              "      <td>[558, 564, 561, 565, 566, 563]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>85</td>\n",
              "      <td>171</td>\n",
              "      <td>172</td>\n",
              "      <td>How can I increase my height after 21 also?</td>\n",
              "      <td>Can height increase after 25?</td>\n",
              "      <td>1</td>\n",
              "      <td>[19, 567, 568, 569]</td>\n",
              "      <td>[567, 19, 570]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>86</td>\n",
              "      <td>173</td>\n",
              "      <td>174</td>\n",
              "      <td>What were the major effects of the cambodia ea...</td>\n",
              "      <td>What were the major effects of the cambodia ea...</td>\n",
              "      <td>1</td>\n",
              "      <td>[571, 572, 573, 574, 572, 113, 575, 576, 577]</td>\n",
              "      <td>[571, 572, 573, 574, 572, 113, 578, 574, 579]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>87</td>\n",
              "      <td>175</td>\n",
              "      <td>176</td>\n",
              "      <td>What is the difference between sincerity and f...</td>\n",
              "      <td>What's the difference between honest and sincere?</td>\n",
              "      <td>0</td>\n",
              "      <td>[580, 581, 582]</td>\n",
              "      <td>[580, 583, 584]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>88</td>\n",
              "      <td>177</td>\n",
              "      <td>178</td>\n",
              "      <td>Which is the best gaming laptop under 60k INR?</td>\n",
              "      <td>Which is the best gaming laptop under Rs 60000?</td>\n",
              "      <td>1</td>\n",
              "      <td>[151, 585, 586, 587, 588]</td>\n",
              "      <td>[151, 585, 586, 589, 587]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>89</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>What is your review of The Next Warrior: Provi...</td>\n",
              "      <td>What is your review of The Next Warrior: Provi...</td>\n",
              "      <td>0</td>\n",
              "      <td>[455, 261, 590, 51, 591, 592, 10, 593, 594]</td>\n",
              "      <td>[455, 261, 590, 51, 591, 592, 10, 593, 595]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>181</td>\n",
              "      <td>182</td>\n",
              "      <td>What is the best reference book for physics cl...</td>\n",
              "      <td>Which book should I choose for reference for p...</td>\n",
              "      <td>0</td>\n",
              "      <td>[151, 596, 432, 98, 597, 598]</td>\n",
              "      <td>[432, 268, 596, 98, 599, 597, 600, 601, 602]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>183</td>\n",
              "      <td>184</td>\n",
              "      <td>National Institute of Technology, Kurukshetra:...</td>\n",
              "      <td>National Institute of Technology Karnataka (NI...</td>\n",
              "      <td>0</td>\n",
              "      <td>[603, 156, 604, 605, 51, 606, 518, 607, 608]</td>\n",
              "      <td>[603, 156, 604, 609, 607, 608, 51, 610, 611, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>What are some of the best romantic movies in E...</td>\n",
              "      <td>What is the best romantic movie you have ever ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[151, 615, 616, 477]</td>\n",
              "      <td>[151, 615, 617, 375, 618]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>What causes a nightmare?</td>\n",
              "      <td>What causes nightmares that seem real?</td>\n",
              "      <td>1</td>\n",
              "      <td>[428, 619]</td>\n",
              "      <td>[428, 620, 621, 622]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>What is abstract expressionism in painting?</td>\n",
              "      <td>What are some of the major influences of abstr...</td>\n",
              "      <td>0</td>\n",
              "      <td>[623, 624, 625]</td>\n",
              "      <td>[571, 626, 623, 624]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>191</td>\n",
              "      <td>192</td>\n",
              "      <td>How does 3D printing work?</td>\n",
              "      <td>How do 3D printing work?</td>\n",
              "      <td>1</td>\n",
              "      <td>[627, 628, 629]</td>\n",
              "      <td>[627, 628, 629]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>193</td>\n",
              "      <td>194</td>\n",
              "      <td>What was it like to attend Caltech with Jeremy...</td>\n",
              "      <td>Who are some notable folks who attended Caltech?</td>\n",
              "      <td>0</td>\n",
              "      <td>[104, 630, 631, 632, 633]</td>\n",
              "      <td>[634, 635, 636, 631]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>195</td>\n",
              "      <td>196</td>\n",
              "      <td>Why did harry become a horcrux?</td>\n",
              "      <td>What is a Horcrux?</td>\n",
              "      <td>0</td>\n",
              "      <td>[430, 259, 637]</td>\n",
              "      <td>[637]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>197</td>\n",
              "      <td>198</td>\n",
              "      <td>What are the best associate product manager (A...</td>\n",
              "      <td>What are the general requirement to become a P...</td>\n",
              "      <td>0</td>\n",
              "      <td>[151, 638, 639, 640, 641, 389, 164, 642, 643, ...</td>\n",
              "      <td>[647, 648, 259, 639, 640, 361, 640, 639, 649, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>199</td>\n",
              "      <td>200</td>\n",
              "      <td>Why is the number for Skype at 1-855-425-3768 ...</td>\n",
              "      <td>How could I get Skype to work on an android 4....</td>\n",
              "      <td>0</td>\n",
              "      <td>[327, 651, 652, 10, 653, 10, 654, 10, 655, 369...</td>\n",
              "      <td>[657, 280, 651, 629, 658, 659, 652, 652, 66]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  qid1  qid2                                          question1  \\\n",
              "0    0     1     2  What is the step by step guide to invest in sh...   \n",
              "1    1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2    2     5     6  How can I increase the speed of my internet co...   \n",
              "3    3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4    4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "5    5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "6    6    13    14                                Should I buy tiago?   \n",
              "7    7    15    16                     How can I be a good geologist?   \n",
              "8    8    17    18                    When do you use シ instead of し?   \n",
              "9    9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
              "10  10    21    22  Method to find separation of slits using fresn...   \n",
              "11  11    23    24        How do I read and find my YouTube comments?   \n",
              "12  12    25    26               What can make Physics easy to learn?   \n",
              "13  13    27    28        What was your first sexual experience like?   \n",
              "14  14    29    30  What are the laws to change your status from a...   \n",
              "15  15    31    32  What would a Trump presidency mean for current...   \n",
              "16  16    33    34                       What does manipulation mean?   \n",
              "17  17    35    36  Why do girls want to be friends with the guy t...   \n",
              "18  18    37    38  Why are so many Quora users posting questions ...   \n",
              "19  19    39    40  Which is the best digital marketing institutio...   \n",
              "20  20    41    42                         Why do rockets look white?   \n",
              "21  21    43    44              What's causing someone to be jealous?   \n",
              "22  22    45    46    What are the questions should not ask on Quora?   \n",
              "23  23    47    48                           How much is 30 kV in HP?   \n",
              "24  24    49    50  What does it mean that every time I look at th...   \n",
              "25  25    51    52  What are some tips on making it through the jo...   \n",
              "26  26    53    54                           What is web application?   \n",
              "27  27    55    56  Does society place too much importance on sports?   \n",
              "28  28    57    58             What is best way to make money online?   \n",
              "29  29    59    60             How should I prepare for CA final law?   \n",
              "..  ..   ...   ...                                                ...   \n",
              "70  70   141   142                    What are the types of immunity?   \n",
              "71  71   143   144       What is a narcissistic personality disorder?   \n",
              "72  72   145   146                  How I can speak English fluently?   \n",
              "73  73   147   148  How helpful is QuickBooks' auto data recovery ...   \n",
              "74  74   149   150  Who is the richest gambler of all time and how...   \n",
              "75  75   151   152  If I fire a bullet backward from an aircraft g...   \n",
              "76  76   153   154                    How do I prevent breast cancer?   \n",
              "77  77   155   156  How do I log out of my Gmail account on my fri...   \n",
              "78  78   157   158         How can I make money through the Internet?   \n",
              "79  79   159   160                           What is purpose of life?   \n",
              "80  80   161   162  When will the BJP government strip all the Mus...   \n",
              "81  81   163   164  What is the right etiquette for wishing a Jeho...   \n",
              "82  82   165   166  If someone wants to open a commercial FM radio...   \n",
              "83  83   167   168                       Why do Swiss despise Asians?   \n",
              "84  84   169   170  What are some of the high salary income jobs i...   \n",
              "85  85   171   172        How can I increase my height after 21 also?   \n",
              "86  86   173   174  What were the major effects of the cambodia ea...   \n",
              "87  87   175   176  What is the difference between sincerity and f...   \n",
              "88  88   177   178     Which is the best gaming laptop under 60k INR?   \n",
              "89  89   179   180  What is your review of The Next Warrior: Provi...   \n",
              "90  90   181   182  What is the best reference book for physics cl...   \n",
              "91  91   183   184  National Institute of Technology, Kurukshetra:...   \n",
              "92  92   185   186  What are some of the best romantic movies in E...   \n",
              "93  93   187   188                           What causes a nightmare?   \n",
              "94  94   189   190        What is abstract expressionism in painting?   \n",
              "95  95   191   192                         How does 3D printing work?   \n",
              "96  96   193   194  What was it like to attend Caltech with Jeremy...   \n",
              "97  97   195   196                    Why did harry become a horcrux?   \n",
              "98  98   197   198  What are the best associate product manager (A...   \n",
              "99  99   199   200  Why is the number for Skype at 1-855-425-3768 ...   \n",
              "\n",
              "                                            question2  is_duplicate  \\\n",
              "0   What is the step by step guide to invest in sh...             0   \n",
              "1   What would happen if the Indian government sto...             0   \n",
              "2   How can Internet speed be increased by hacking...             0   \n",
              "3   Find the remainder when [math]23^{24}[/math] i...             0   \n",
              "4             Which fish would survive in salt water?             0   \n",
              "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1   \n",
              "6   What keeps childern active and far from phone ...             0   \n",
              "7           What should I do to be a great geologist?             1   \n",
              "8               When do you use \"&\" instead of \"and\"?             0   \n",
              "9   How do I hack Motorola DCX3400 for free internet?             0   \n",
              "10  What are some of the things technicians can te...             0   \n",
              "11             How can I see all my Youtube comments?             1   \n",
              "12            How can you make physics easy to learn?             1   \n",
              "13             What was your first sexual experience?             1   \n",
              "14  What are the laws to change your status from a...             0   \n",
              "15  How will a Trump presidency affect the student...             1   \n",
              "16                      What does manipulation means?             1   \n",
              "17           How do guys feel after rejecting a girl?             0   \n",
              "18  Why do people ask Quora questions which can be...             1   \n",
              "19  Which is the best digital marketing institute ...             0   \n",
              "20        Why are rockets and boosters painted white?             1   \n",
              "21   What can I do to avoid being jealous of someone?             0   \n",
              "22              Which question should I ask on Quora?             0   \n",
              "23  Where can I find a conversion chart for CC to ...             0   \n",
              "24   How many times a day do a clock’s hands overlap?             0   \n",
              "25  What are some tips on making it through the jo...             0   \n",
              "26             What is the web application framework?             0   \n",
              "27           How do sports contribute to the society?             0   \n",
              "28          What is best way to ask for money online?             0   \n",
              "29  How one should know that he/she completely pre...             1   \n",
              "..                                                ...           ...   \n",
              "70  What are the different types of immunity in ou...             0   \n",
              "71         What is narcissistic personality disorder?             1   \n",
              "72         How can I learn to speak English fluently?             1   \n",
              "73  What is the quickbooks customer support phone ...             1   \n",
              "74  Who is the richest gambler of all time and how...             1   \n",
              "75  Do bullets travel faster than the speed of sou...             0   \n",
              "76                      Is breast cancer preventable?             0   \n",
              "77  How can I know who logged in to my Gmail accou...             0   \n",
              "78  What are some different ways to make money onl...             0   \n",
              "79  What's the purpose of life? What is life actua...             1   \n",
              "80  Why India does not apply the \"Burma-Rohingya m...             0   \n",
              "81  How important is it to be the first person to ...             0   \n",
              "82  I want to make a travel commercial/clip video ...             0   \n",
              "83  Why do technical employees despise sales peopl...             0   \n",
              "84  What are some high paying jobs for a fresher w...             1   \n",
              "85                      Can height increase after 25?             1   \n",
              "86  What were the major effects of the cambodia ea...             1   \n",
              "87  What's the difference between honest and sincere?             0   \n",
              "88    Which is the best gaming laptop under Rs 60000?             1   \n",
              "89  What is your review of The Next Warrior: Provi...             0   \n",
              "90  Which book should I choose for reference for p...             0   \n",
              "91  National Institute of Technology Karnataka (NI...             0   \n",
              "92  What is the best romantic movie you have ever ...             1   \n",
              "93             What causes nightmares that seem real?             1   \n",
              "94  What are some of the major influences of abstr...             0   \n",
              "95                           How do 3D printing work?             1   \n",
              "96   Who are some notable folks who attended Caltech?             0   \n",
              "97                                 What is a Horcrux?             0   \n",
              "98  What are the general requirement to become a P...             0   \n",
              "99  How could I get Skype to work on an android 4....             0   \n",
              "\n",
              "                                          question1_n  \\\n",
              "0                               [1, 1, 2, 3, 4, 5, 6]   \n",
              "1                           [7, 8, 9, 10, 10, 11, 12]   \n",
              "2                            [19, 20, 21, 22, 23, 24]   \n",
              "3                                        [28, 29, 30]   \n",
              "4            [38, 39, 40, 41, 42, 43, 44, 45, 46, 47]   \n",
              "5                [50, 51, 52, 53, 54, 55, 54, 56, 57]   \n",
              "6                                            [60, 61]   \n",
              "7                                            [69, 70]   \n",
              "8                                            [72, 73]   \n",
              "9                        [74, 75, 51, 76, 77, 78, 79]   \n",
              "10                       [81, 31, 82, 83, 23, 84, 85]   \n",
              "11                                   [93, 31, 94, 95]   \n",
              "12                                  [97, 98, 99, 100]   \n",
              "13                               [101, 102, 103, 104]   \n",
              "14  [105, 106, 107, 108, 109, 110, 111, 112, 113, ...   \n",
              "15  [13, 117, 118, 119, 120, 121, 122, 123, 124, 109]   \n",
              "16                                         [129, 119]   \n",
              "17                          [131, 132, 133, 134, 135]   \n",
              "18           [140, 141, 142, 143, 144, 145, 146, 147]   \n",
              "19                          [151, 152, 153, 154, 155]   \n",
              "20                                    [158, 159, 160]   \n",
              "21                                    [163, 164, 165]   \n",
              "22                                    [144, 149, 141]   \n",
              "23                               [168, 169, 170, 171]   \n",
              "24                     [119, 176, 177, 159, 178, 179]   \n",
              "25                     [184, 185, 186, 187, 188, 189]   \n",
              "26                                         [192, 193]   \n",
              "27                          [195, 196, 168, 197, 198]   \n",
              "28                           [151, 200, 97, 201, 202]   \n",
              "29                               [203, 204, 205, 206]   \n",
              "..                                                ...   \n",
              "70                                         [469, 470]   \n",
              "71                                    [473, 474, 475]   \n",
              "72                                    [476, 477, 478]   \n",
              "73  [479, 480, 481, 482, 406, 483, 66, 327, 410, 4...   \n",
              "74                          [488, 489, 177, 490, 491]   \n",
              "75  [492, 493, 494, 292, 495, 496, 497, 493, 495, ...   \n",
              "76                                    [504, 505, 506]   \n",
              "77                           [508, 402, 509, 392, 66]   \n",
              "78                                      [97, 201, 21]   \n",
              "79                                         [517, 518]   \n",
              "80  [520, 16, 521, 522, 523, 15, 524, 525, 526, 10...   \n",
              "81                [533, 534, 535, 536, 537, 538, 539]   \n",
              "82  [164, 279, 542, 543, 544, 545, 546, 547, 6, 16...   \n",
              "83                                    [552, 553, 554]   \n",
              "84                     [558, 559, 560, 561, 562, 563]   \n",
              "85                                [19, 567, 568, 569]   \n",
              "86      [571, 572, 573, 574, 572, 113, 575, 576, 577]   \n",
              "87                                    [580, 581, 582]   \n",
              "88                          [151, 585, 586, 587, 588]   \n",
              "89        [455, 261, 590, 51, 591, 592, 10, 593, 594]   \n",
              "90                      [151, 596, 432, 98, 597, 598]   \n",
              "91       [603, 156, 604, 605, 51, 606, 518, 607, 608]   \n",
              "92                               [151, 615, 616, 477]   \n",
              "93                                         [428, 619]   \n",
              "94                                    [623, 624, 625]   \n",
              "95                                    [627, 628, 629]   \n",
              "96                          [104, 630, 631, 632, 633]   \n",
              "97                                    [430, 259, 637]   \n",
              "98  [151, 638, 639, 640, 641, 389, 164, 642, 643, ...   \n",
              "99  [327, 651, 652, 10, 653, 10, 654, 10, 655, 369...   \n",
              "\n",
              "                                          question2_n  \n",
              "0                                  [1, 1, 2, 3, 4, 5]  \n",
              "1      [13, 14, 15, 16, 17, 8, 9, 10, 10, 11, 12, 18]  \n",
              "2                                [21, 20, 25, 26, 27]  \n",
              "3            [31, 32, 33, 34, 35, 36, 33, 37, 36, 34]  \n",
              "4                                [48, 13, 49, 43, 40]  \n",
              "5                        [58, 52, 53, 55, 59, 52, 57]  \n",
              "6                        [62, 63, 64, 65, 66, 67, 68]  \n",
              "7                                            [71, 70]  \n",
              "8                                            [72, 73]  \n",
              "9                                [76, 74, 79, 80, 21]  \n",
              "10                       [86, 87, 88, 89, 90, 91, 92]  \n",
              "11                                       [96, 94, 95]  \n",
              "12                                  [97, 98, 99, 100]  \n",
              "13                                    [101, 102, 103]  \n",
              "14  [105, 106, 107, 108, 109, 110, 111, 112, 113, ...  \n",
              "15      [117, 118, 125, 123, 126, 112, 127, 128, 112]  \n",
              "16                                         [129, 130]  \n",
              "17                               [136, 137, 138, 139]  \n",
              "18                [148, 149, 141, 144, 146, 150, 147]  \n",
              "19                          [151, 152, 153, 156, 157]  \n",
              "20                               [158, 161, 162, 160]  \n",
              "21                                    [166, 165, 164]  \n",
              "22                                    [167, 149, 141]  \n",
              "23                           [31, 172, 173, 174, 175]  \n",
              "24                     [140, 180, 181, 178, 182, 183]  \n",
              "25                [184, 185, 186, 187, 188, 190, 191]  \n",
              "26                                    [192, 193, 194]  \n",
              "27                                    [198, 199, 195]  \n",
              "28                          [151, 200, 149, 201, 202]  \n",
              "29                 [38, 207, 208, 203, 204, 205, 209]  \n",
              "..                                                ...  \n",
              "70                               [471, 469, 470, 472]  \n",
              "71                                    [473, 474, 475]  \n",
              "72                               [100, 476, 477, 478]  \n",
              "73                      [480, 486, 483, 66, 327, 487]  \n",
              "74                     [488, 489, 177, 490, 491, 489]  \n",
              "75  [499, 241, 496, 20, 500, 501, 250, 454, 250, 1...  \n",
              "76                                    [505, 506, 507]  \n",
              "77      [207, 401, 402, 509, 510, 511, 512, 513, 514]  \n",
              "78             [471, 411, 97, 201, 202, 515, 516, 86]  \n",
              "79                               [517, 518, 518, 519]  \n",
              "80         [6, 388, 528, 10, 527, 529, 530, 531, 532]  \n",
              "81                [449, 101, 540, 541, 164, 538, 539]  \n",
              "82  [132, 97, 241, 543, 549, 67, 550, 6, 318, 551,...  \n",
              "83                     [555, 556, 553, 557, 148, 168]  \n",
              "84                     [558, 564, 561, 565, 566, 563]  \n",
              "85                                     [567, 19, 570]  \n",
              "86      [571, 572, 573, 574, 572, 113, 578, 574, 579]  \n",
              "87                                    [580, 583, 584]  \n",
              "88                          [151, 585, 586, 589, 587]  \n",
              "89        [455, 261, 590, 51, 591, 592, 10, 593, 595]  \n",
              "90       [432, 268, 596, 98, 599, 597, 600, 601, 602]  \n",
              "91  [603, 156, 604, 609, 607, 608, 51, 610, 611, 5...  \n",
              "92                          [151, 615, 617, 375, 618]  \n",
              "93                               [428, 620, 621, 622]  \n",
              "94                               [571, 626, 623, 624]  \n",
              "95                                    [627, 628, 629]  \n",
              "96                               [634, 635, 636, 631]  \n",
              "97                                              [637]  \n",
              "98  [647, 648, 259, 639, 640, 361, 640, 639, 649, ...  \n",
              "99       [657, 280, 651, 629, 658, 659, 652, 652, 66]  \n",
              "\n",
              "[100 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "KDM0EC0fgjKQ",
        "colab_type": "code",
        "outputId": "e79d325d-bbe3-465b-ffb2-7dae9e4d937d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.iloc[0]['question1']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the step by step guide to invest in share market in india?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "sb_p53E2gvsf",
        "colab_type": "code",
        "outputId": "beb31b8a-1e30-40c6-8654-ff4303d21e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.iloc[0]['question2']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the step by step guide to invest in share market?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "pYO-IqO4XgLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOtG9AU4iyOc",
        "colab_type": "code",
        "outputId": "5952b186-aa01-4637-9e9f-2fb0802dc0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "X_train['left'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,  140, 5061,  259, 1072, 4614], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "21MgqbQ7i6I1",
        "colab_type": "code",
        "outputId": "6a297f88-f69f-43cf-c0dd-a2e2efcca079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "X_train['right'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,  5832,\n",
              "        2005, 15007], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "-e-o85fn-2lW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding\n",
        "# Instantiates a single LSTM layer, once\n",
        "lstm = layers.LSTM(32)\n",
        "\n",
        "#使用上面處理建好的embeedings來建立embeeding layer\n",
        "\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=True)\n",
        "\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "# Building the left branch of the model: \n",
        "# Embedded version of the inputs\n",
        "\n",
        "encoded_left = embedding_layer(left_input)\n",
        "left_output = lstm(encoded_left)\n",
        "\n",
        "\n",
        "\n",
        "# Building the right branch of the model:\n",
        "# when you call an existing layer instance, you reuse its weights.\n",
        "# Embedded version of the inputs\n",
        "\n",
        "encoded_right = embedding_layer(right_input)\n",
        "right_output = lstm(encoded_right)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Builds the classifier on top\n",
        "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "# Instantiating the model\n",
        "model = Model([left_input, right_input], predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o6temtgKXxQM",
        "colab_type": "code",
        "outputId": "a7061dbe-6435-40ea-c801-cd423c6f0697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "gpus = 1\n",
        "batch_size = 1024 * gpus\n",
        "n_epoch = 20\n",
        "n_hidden = 50\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "\n",
        "from time import time\n",
        "training_start_time = time()\n",
        "\"\"\"\n",
        "malstm_trained = model.fit([X_train['left'].reshape(X_train['left'].shape[0],1,max_seq_length), X_train['right'].reshape(X_train['right'].shape[0],1,max_seq_length)], Y_train,\n",
        "                           batch_size=batch_size, epochs=n_epoch,\n",
        "                           validation_data=([X_validation['left'].reshape(X_validation['left'].shape[0],1,max_seq_length), X_validation['right'].reshape(X_validation['right'].shape[0],1,max_seq_length)], Y_validation))\n",
        "\"\"\"\n",
        "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\n",
        "                           batch_size=batch_size, epochs=n_epoch,\n",
        "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "\n",
        "training_end_time = time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 363916 samples, validate on 40435 samples\n",
            "Epoch 1/20\n",
            "363916/363916 [==============================] - 60s 165us/step - loss: 0.5485 - acc: 0.7235 - val_loss: 0.5210 - val_acc: 0.7402\n",
            "Epoch 2/20\n",
            "363916/363916 [==============================] - 57s 157us/step - loss: 0.4862 - acc: 0.7672 - val_loss: 0.4970 - val_acc: 0.7621\n",
            "Epoch 3/20\n",
            "363916/363916 [==============================] - 56s 154us/step - loss: 0.4556 - acc: 0.7862 - val_loss: 0.4924 - val_acc: 0.7654\n",
            "Epoch 4/20\n",
            "363916/363916 [==============================] - 55s 152us/step - loss: 0.4306 - acc: 0.8013 - val_loss: 0.4914 - val_acc: 0.7661\n",
            "Epoch 5/20\n",
            "363916/363916 [==============================] - 55s 151us/step - loss: 0.4082 - acc: 0.8138 - val_loss: 0.4911 - val_acc: 0.7692\n",
            "Epoch 6/20\n",
            "363916/363916 [==============================] - 55s 151us/step - loss: 0.3878 - acc: 0.8252 - val_loss: 0.4936 - val_acc: 0.7746\n",
            "Epoch 7/20\n",
            "363916/363916 [==============================] - 56s 153us/step - loss: 0.3684 - acc: 0.8356 - val_loss: 0.5001 - val_acc: 0.7711\n",
            "Epoch 8/20\n",
            "363916/363916 [==============================] - 57s 156us/step - loss: 0.3503 - acc: 0.8453 - val_loss: 0.5073 - val_acc: 0.7704\n",
            "Epoch 9/20\n",
            "363916/363916 [==============================] - 56s 154us/step - loss: 0.3329 - acc: 0.8542 - val_loss: 0.5138 - val_acc: 0.7732\n",
            "Epoch 10/20\n",
            "363916/363916 [==============================] - 55s 152us/step - loss: 0.3161 - acc: 0.8629 - val_loss: 0.5247 - val_acc: 0.7731\n",
            "Epoch 11/20\n",
            "363916/363916 [==============================] - 56s 155us/step - loss: 0.3004 - acc: 0.8704 - val_loss: 0.5355 - val_acc: 0.7713\n",
            "Epoch 12/20\n",
            "363916/363916 [==============================] - 57s 155us/step - loss: 0.2849 - acc: 0.8782 - val_loss: 0.5497 - val_acc: 0.7692\n",
            "Epoch 13/20\n",
            "363916/363916 [==============================] - 57s 157us/step - loss: 0.2701 - acc: 0.8854 - val_loss: 0.5622 - val_acc: 0.7704\n",
            "Epoch 14/20\n",
            "363916/363916 [==============================] - 56s 153us/step - loss: 0.2563 - acc: 0.8923 - val_loss: 0.5776 - val_acc: 0.7681\n",
            "Epoch 15/20\n",
            "363916/363916 [==============================] - 56s 154us/step - loss: 0.2427 - acc: 0.8987 - val_loss: 0.5963 - val_acc: 0.7638\n",
            "Epoch 16/20\n",
            "363916/363916 [==============================] - 57s 156us/step - loss: 0.2297 - acc: 0.9050 - val_loss: 0.6086 - val_acc: 0.7687\n",
            "Epoch 17/20\n",
            "363916/363916 [==============================] - 56s 154us/step - loss: 0.2176 - acc: 0.9107 - val_loss: 0.6278 - val_acc: 0.7628\n",
            "Epoch 18/20\n",
            "363916/363916 [==============================] - 56s 153us/step - loss: 0.2059 - acc: 0.9164 - val_loss: 0.6449 - val_acc: 0.7630\n",
            "Epoch 19/20\n",
            "363916/363916 [==============================] - 55s 152us/step - loss: 0.1947 - acc: 0.9212 - val_loss: 0.6630 - val_acc: 0.7653\n",
            "Epoch 20/20\n",
            "363916/363916 [==============================] - 55s 152us/step - loss: 0.1842 - acc: 0.9260 - val_loss: 0.6788 - val_acc: 0.7655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mJdMiK6OdVja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"Siamese_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q1I9b0-Jf8re",
        "colab_type": "code",
        "outputId": "99542d33-1d31-4970-ecb0-e7df6b765fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"Siamese_model.h5\")\n",
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 300)      25762500    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
            "                                                                 embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            65          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 25,805,189\n",
            "Trainable params: 25,805,189\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"387pt\" viewBox=\"0.00 0.00 568.00 387.00\" width=\"568pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 564,-383 564,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139806200486488 -->\n<g class=\"node\" id=\"node1\">\n<title>139806200486488</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 271,-378.5 271,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-351.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-332.5 133,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-355.5 191,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-332.5 191,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-363.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"191,-355.5 271,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-340.3\">(None, 20)</text>\n</g>\n<!-- 139806200486768 -->\n<g class=\"node\" id=\"node3\">\n<title>139806200486768</title>\n<polygon fill=\"none\" points=\"110,-249.5 110,-295.5 449,-295.5 449,-249.5 110,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-268.8\">embedding_1: Embedding</text>\n<polyline fill=\"none\" points=\"281,-249.5 281,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"281,-272.5 339,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"339,-249.5 339,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"394\" y=\"-280.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"339,-272.5 449,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"394\" y=\"-257.3\">(None, 20, 300)</text>\n</g>\n<!-- 139806200486488&#45;&gt;139806200486768 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139806200486488-&gt;139806200486768</title>\n<path d=\"M175.612,-332.3799C192.5492,-322.6175 212.4366,-311.1546 230.2524,-300.8857\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"232.4375,-303.6661 239.3536,-295.6399 228.9419,-297.6014 232.4375,-303.6661\" stroke=\"#000000\"/>\n</g>\n<!-- 139806200486600 -->\n<g class=\"node\" id=\"node2\">\n<title>139806200486600</title>\n<polygon fill=\"none\" points=\"289,-332.5 289,-378.5 560,-378.5 560,-332.5 289,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-351.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"422,-332.5 422,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"422,-355.5 480,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"480,-332.5 480,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520\" y=\"-363.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"480,-355.5 560,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520\" y=\"-340.3\">(None, 20)</text>\n</g>\n<!-- 139806200486600&#45;&gt;139806200486768 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139806200486600-&gt;139806200486768</title>\n<path d=\"M384.1094,-332.3799C367.0547,-322.6175 347.0292,-311.1546 329.0896,-300.8857\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"330.3427,-297.5703 319.9252,-295.6399 326.8652,-303.6454 330.3427,-297.5703\" stroke=\"#000000\"/>\n</g>\n<!-- 139806200486880 -->\n<g class=\"node\" id=\"node4\">\n<title>139806200486880</title>\n<polygon fill=\"none\" points=\"144.5,-166.5 144.5,-212.5 414.5,-212.5 414.5,-166.5 144.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-185.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"246.5,-166.5 246.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"246.5,-189.5 304.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"304.5,-166.5 304.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.5\" y=\"-197.3\">(None, 20, 300)</text>\n<polyline fill=\"none\" points=\"304.5,-189.5 414.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 139806200486768&#45;&gt;139806200486880 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139806200486768-&gt;139806200486880</title>\n<path d=\"M279.5,-249.3799C279.5,-241.1745 279.5,-231.7679 279.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"283.0001,-222.784 279.5,-212.784 276.0001,-222.784 283.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139806200486936 -->\n<g class=\"node\" id=\"node5\">\n<title>139806200486936</title>\n<polygon fill=\"none\" points=\"83.5,-83.5 83.5,-129.5 475.5,-129.5 475.5,-83.5 83.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"171\" y=\"-102.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"258.5,-83.5 258.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"258.5,-106.5 316.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"316.5,-83.5 316.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-114.3\">[(None, 32), (None, 32)]</text>\n<polyline fill=\"none\" points=\"316.5,-106.5 475.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-91.3\">(None, 64)</text>\n</g>\n<!-- 139806200486880&#45;&gt;139806200486936 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139806200486880-&gt;139806200486936</title>\n<path d=\"M279.5,-166.3799C279.5,-158.1745 279.5,-148.7679 279.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"283.0001,-139.784 279.5,-129.784 276.0001,-139.784 283.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139806200487608 -->\n<g class=\"node\" id=\"node6\">\n<title>139806200487608</title>\n<polygon fill=\"none\" points=\"157,-.5 157,-46.5 402,-46.5 402,-.5 157,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"264,-.5 264,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"264,-23.5 322,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"322,-.5 322,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-31.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"322,-23.5 402,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139806200486936&#45;&gt;139806200487608 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139806200486936-&gt;139806200487608</title>\n<path d=\"M279.5,-83.3799C279.5,-75.1745 279.5,-65.7679 279.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"283.0001,-56.784 279.5,-46.784 276.0001,-56.784 283.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "OIpQPLvYePq-",
        "colab_type": "code",
        "outputId": "dc7cacf0-a86b-4f7a-fad8-527485591705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print (training_start_time, training_end_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1541327867.2606907 1541328993.6600316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aKTcFfssSips",
        "colab_type": "code",
        "outputId": "f1c807ac-dd1f-4998-aa9d-9cb77dc2e752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = malstm_trained.history['acc']\n",
        "val_acc = malstm_trained.history['val_acc']\n",
        "loss = malstm_trained.history['loss']\n",
        "val_loss = malstm_trained.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2734eea668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRER8RCEsIiLiI/8feifPNIazScIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2734e852e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ds61zJRJ7yQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 使用word2vec"
      ]
    },
    {
      "metadata": {
        "id": "-hyX7nGGeCLA",
        "colab_type": "code",
        "outputId": "e2cbc84e-e855-421e-e9ba-0dd5fbabbfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6821
        }
      },
      "cell_type": "code",
      "source": [
        "# train一版: embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
        "\n",
        "use_w2v = True\n",
        "\n",
        "train_df, embeddings = make_w2v_embeddings(train_df, embedding_dim=embedding_dim, empty_w2v=not use_w2v)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding\n",
        "# Instantiates a single LSTM layer, once\n",
        "lstm = layers.LSTM(32)\n",
        "\n",
        "#使用上面處理建好的embeedings來建立embeeding layer\n",
        "#trainable設為False\n",
        "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
        "# Building the left branch of the model: \n",
        "# inputs are variable-length sequences of vectors of size 128.\n",
        "#left_input = Input(shape=(None, max_seq_length))\n",
        "\n",
        "# The visible layer\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "\n",
        "# Embedded version of the inputs\n",
        "encoded_left = embedding_layer(left_input)\n",
        "\n",
        "\n",
        "left_output = lstm(encoded_left)\n",
        "\n",
        "\n",
        "\n",
        "# Building the right branch of the model:\n",
        "# when you call an existing layer instance, you reuse its weights.\n",
        "#right_input = Input(shape=(None, max_seq_length))\n",
        "\n",
        "# Embedded version of the inputs\n",
        "encoded_right = embedding_layer(right_input)\n",
        "\n",
        "right_output = lstm(encoded_right)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Builds the classifier on top\n",
        "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "# Instantiating the model\n",
        "model = Model([left_input, right_input], predictions)\n",
        "\n",
        "gpus = 1\n",
        "batch_size = 1024 * gpus\n",
        "n_epoch = 20\n",
        "n_hidden = 50\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word2vec model(it may takes 2-3 mins) ...\n",
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n",
            "3,000 sentences embedded.\n",
            "4,000 sentences embedded.\n",
            "5,000 sentences embedded.\n",
            "6,000 sentences embedded.\n",
            "7,000 sentences embedded.\n",
            "8,000 sentences embedded.\n",
            "9,000 sentences embedded.\n",
            "10,000 sentences embedded.\n",
            "11,000 sentences embedded.\n",
            "12,000 sentences embedded.\n",
            "13,000 sentences embedded.\n",
            "14,000 sentences embedded.\n",
            "15,000 sentences embedded.\n",
            "16,000 sentences embedded.\n",
            "17,000 sentences embedded.\n",
            "18,000 sentences embedded.\n",
            "19,000 sentences embedded.\n",
            "20,000 sentences embedded.\n",
            "21,000 sentences embedded.\n",
            "22,000 sentences embedded.\n",
            "23,000 sentences embedded.\n",
            "24,000 sentences embedded.\n",
            "25,000 sentences embedded.\n",
            "26,000 sentences embedded.\n",
            "27,000 sentences embedded.\n",
            "28,000 sentences embedded.\n",
            "29,000 sentences embedded.\n",
            "30,000 sentences embedded.\n",
            "31,000 sentences embedded.\n",
            "32,000 sentences embedded.\n",
            "33,000 sentences embedded.\n",
            "34,000 sentences embedded.\n",
            "35,000 sentences embedded.\n",
            "36,000 sentences embedded.\n",
            "37,000 sentences embedded.\n",
            "38,000 sentences embedded.\n",
            "39,000 sentences embedded.\n",
            "40,000 sentences embedded.\n",
            "41,000 sentences embedded.\n",
            "42,000 sentences embedded.\n",
            "43,000 sentences embedded.\n",
            "44,000 sentences embedded.\n",
            "45,000 sentences embedded.\n",
            "46,000 sentences embedded.\n",
            "47,000 sentences embedded.\n",
            "48,000 sentences embedded.\n",
            "49,000 sentences embedded.\n",
            "50,000 sentences embedded.\n",
            "51,000 sentences embedded.\n",
            "52,000 sentences embedded.\n",
            "53,000 sentences embedded.\n",
            "54,000 sentences embedded.\n",
            "55,000 sentences embedded.\n",
            "56,000 sentences embedded.\n",
            "57,000 sentences embedded.\n",
            "58,000 sentences embedded.\n",
            "59,000 sentences embedded.\n",
            "60,000 sentences embedded.\n",
            "61,000 sentences embedded.\n",
            "62,000 sentences embedded.\n",
            "63,000 sentences embedded.\n",
            "64,000 sentences embedded.\n",
            "65,000 sentences embedded.\n",
            "66,000 sentences embedded.\n",
            "67,000 sentences embedded.\n",
            "68,000 sentences embedded.\n",
            "69,000 sentences embedded.\n",
            "70,000 sentences embedded.\n",
            "71,000 sentences embedded.\n",
            "72,000 sentences embedded.\n",
            "73,000 sentences embedded.\n",
            "74,000 sentences embedded.\n",
            "75,000 sentences embedded.\n",
            "76,000 sentences embedded.\n",
            "77,000 sentences embedded.\n",
            "78,000 sentences embedded.\n",
            "79,000 sentences embedded.\n",
            "80,000 sentences embedded.\n",
            "81,000 sentences embedded.\n",
            "82,000 sentences embedded.\n",
            "83,000 sentences embedded.\n",
            "84,000 sentences embedded.\n",
            "85,000 sentences embedded.\n",
            "86,000 sentences embedded.\n",
            "87,000 sentences embedded.\n",
            "88,000 sentences embedded.\n",
            "89,000 sentences embedded.\n",
            "90,000 sentences embedded.\n",
            "91,000 sentences embedded.\n",
            "92,000 sentences embedded.\n",
            "93,000 sentences embedded.\n",
            "94,000 sentences embedded.\n",
            "95,000 sentences embedded.\n",
            "96,000 sentences embedded.\n",
            "97,000 sentences embedded.\n",
            "98,000 sentences embedded.\n",
            "99,000 sentences embedded.\n",
            "100,000 sentences embedded.\n",
            "101,000 sentences embedded.\n",
            "102,000 sentences embedded.\n",
            "103,000 sentences embedded.\n",
            "104,000 sentences embedded.\n",
            "105,000 sentences embedded.\n",
            "106,000 sentences embedded.\n",
            "107,000 sentences embedded.\n",
            "108,000 sentences embedded.\n",
            "109,000 sentences embedded.\n",
            "110,000 sentences embedded.\n",
            "111,000 sentences embedded.\n",
            "112,000 sentences embedded.\n",
            "113,000 sentences embedded.\n",
            "114,000 sentences embedded.\n",
            "115,000 sentences embedded.\n",
            "116,000 sentences embedded.\n",
            "117,000 sentences embedded.\n",
            "118,000 sentences embedded.\n",
            "119,000 sentences embedded.\n",
            "120,000 sentences embedded.\n",
            "121,000 sentences embedded.\n",
            "122,000 sentences embedded.\n",
            "123,000 sentences embedded.\n",
            "124,000 sentences embedded.\n",
            "125,000 sentences embedded.\n",
            "126,000 sentences embedded.\n",
            "127,000 sentences embedded.\n",
            "128,000 sentences embedded.\n",
            "129,000 sentences embedded.\n",
            "130,000 sentences embedded.\n",
            "131,000 sentences embedded.\n",
            "132,000 sentences embedded.\n",
            "133,000 sentences embedded.\n",
            "134,000 sentences embedded.\n",
            "135,000 sentences embedded.\n",
            "136,000 sentences embedded.\n",
            "137,000 sentences embedded.\n",
            "138,000 sentences embedded.\n",
            "139,000 sentences embedded.\n",
            "140,000 sentences embedded.\n",
            "141,000 sentences embedded.\n",
            "142,000 sentences embedded.\n",
            "143,000 sentences embedded.\n",
            "144,000 sentences embedded.\n",
            "145,000 sentences embedded.\n",
            "146,000 sentences embedded.\n",
            "147,000 sentences embedded.\n",
            "148,000 sentences embedded.\n",
            "149,000 sentences embedded.\n",
            "150,000 sentences embedded.\n",
            "151,000 sentences embedded.\n",
            "152,000 sentences embedded.\n",
            "153,000 sentences embedded.\n",
            "154,000 sentences embedded.\n",
            "155,000 sentences embedded.\n",
            "156,000 sentences embedded.\n",
            "157,000 sentences embedded.\n",
            "158,000 sentences embedded.\n",
            "159,000 sentences embedded.\n",
            "160,000 sentences embedded.\n",
            "161,000 sentences embedded.\n",
            "162,000 sentences embedded.\n",
            "163,000 sentences embedded.\n",
            "164,000 sentences embedded.\n",
            "165,000 sentences embedded.\n",
            "166,000 sentences embedded.\n",
            "167,000 sentences embedded.\n",
            "168,000 sentences embedded.\n",
            "169,000 sentences embedded.\n",
            "170,000 sentences embedded.\n",
            "171,000 sentences embedded.\n",
            "172,000 sentences embedded.\n",
            "173,000 sentences embedded.\n",
            "174,000 sentences embedded.\n",
            "175,000 sentences embedded.\n",
            "176,000 sentences embedded.\n",
            "177,000 sentences embedded.\n",
            "178,000 sentences embedded.\n",
            "179,000 sentences embedded.\n",
            "180,000 sentences embedded.\n",
            "181,000 sentences embedded.\n",
            "182,000 sentences embedded.\n",
            "183,000 sentences embedded.\n",
            "184,000 sentences embedded.\n",
            "185,000 sentences embedded.\n",
            "186,000 sentences embedded.\n",
            "187,000 sentences embedded.\n",
            "188,000 sentences embedded.\n",
            "189,000 sentences embedded.\n",
            "190,000 sentences embedded.\n",
            "191,000 sentences embedded.\n",
            "192,000 sentences embedded.\n",
            "193,000 sentences embedded.\n",
            "194,000 sentences embedded.\n",
            "195,000 sentences embedded.\n",
            "196,000 sentences embedded.\n",
            "197,000 sentences embedded.\n",
            "198,000 sentences embedded.\n",
            "199,000 sentences embedded.\n",
            "200,000 sentences embedded.\n",
            "201,000 sentences embedded.\n",
            "202,000 sentences embedded.\n",
            "203,000 sentences embedded.\n",
            "204,000 sentences embedded.\n",
            "205,000 sentences embedded.\n",
            "206,000 sentences embedded.\n",
            "207,000 sentences embedded.\n",
            "208,000 sentences embedded.\n",
            "209,000 sentences embedded.\n",
            "210,000 sentences embedded.\n",
            "211,000 sentences embedded.\n",
            "212,000 sentences embedded.\n",
            "213,000 sentences embedded.\n",
            "214,000 sentences embedded.\n",
            "215,000 sentences embedded.\n",
            "216,000 sentences embedded.\n",
            "217,000 sentences embedded.\n",
            "218,000 sentences embedded.\n",
            "219,000 sentences embedded.\n",
            "220,000 sentences embedded.\n",
            "221,000 sentences embedded.\n",
            "222,000 sentences embedded.\n",
            "223,000 sentences embedded.\n",
            "224,000 sentences embedded.\n",
            "225,000 sentences embedded.\n",
            "226,000 sentences embedded.\n",
            "227,000 sentences embedded.\n",
            "228,000 sentences embedded.\n",
            "229,000 sentences embedded.\n",
            "230,000 sentences embedded.\n",
            "231,000 sentences embedded.\n",
            "232,000 sentences embedded.\n",
            "233,000 sentences embedded.\n",
            "234,000 sentences embedded.\n",
            "235,000 sentences embedded.\n",
            "236,000 sentences embedded.\n",
            "237,000 sentences embedded.\n",
            "238,000 sentences embedded.\n",
            "239,000 sentences embedded.\n",
            "240,000 sentences embedded.\n",
            "241,000 sentences embedded.\n",
            "242,000 sentences embedded.\n",
            "243,000 sentences embedded.\n",
            "244,000 sentences embedded.\n",
            "245,000 sentences embedded.\n",
            "246,000 sentences embedded.\n",
            "247,000 sentences embedded.\n",
            "248,000 sentences embedded.\n",
            "249,000 sentences embedded.\n",
            "250,000 sentences embedded.\n",
            "251,000 sentences embedded.\n",
            "252,000 sentences embedded.\n",
            "253,000 sentences embedded.\n",
            "254,000 sentences embedded.\n",
            "255,000 sentences embedded.\n",
            "256,000 sentences embedded.\n",
            "257,000 sentences embedded.\n",
            "258,000 sentences embedded.\n",
            "259,000 sentences embedded.\n",
            "260,000 sentences embedded.\n",
            "261,000 sentences embedded.\n",
            "262,000 sentences embedded.\n",
            "263,000 sentences embedded.\n",
            "264,000 sentences embedded.\n",
            "265,000 sentences embedded.\n",
            "266,000 sentences embedded.\n",
            "267,000 sentences embedded.\n",
            "268,000 sentences embedded.\n",
            "269,000 sentences embedded.\n",
            "270,000 sentences embedded.\n",
            "271,000 sentences embedded.\n",
            "272,000 sentences embedded.\n",
            "273,000 sentences embedded.\n",
            "274,000 sentences embedded.\n",
            "275,000 sentences embedded.\n",
            "276,000 sentences embedded.\n",
            "277,000 sentences embedded.\n",
            "278,000 sentences embedded.\n",
            "279,000 sentences embedded.\n",
            "280,000 sentences embedded.\n",
            "281,000 sentences embedded.\n",
            "282,000 sentences embedded.\n",
            "283,000 sentences embedded.\n",
            "284,000 sentences embedded.\n",
            "285,000 sentences embedded.\n",
            "286,000 sentences embedded.\n",
            "287,000 sentences embedded.\n",
            "288,000 sentences embedded.\n",
            "289,000 sentences embedded.\n",
            "290,000 sentences embedded.\n",
            "291,000 sentences embedded.\n",
            "292,000 sentences embedded.\n",
            "293,000 sentences embedded.\n",
            "294,000 sentences embedded.\n",
            "295,000 sentences embedded.\n",
            "296,000 sentences embedded.\n",
            "297,000 sentences embedded.\n",
            "298,000 sentences embedded.\n",
            "299,000 sentences embedded.\n",
            "300,000 sentences embedded.\n",
            "301,000 sentences embedded.\n",
            "302,000 sentences embedded.\n",
            "303,000 sentences embedded.\n",
            "304,000 sentences embedded.\n",
            "305,000 sentences embedded.\n",
            "306,000 sentences embedded.\n",
            "307,000 sentences embedded.\n",
            "308,000 sentences embedded.\n",
            "309,000 sentences embedded.\n",
            "310,000 sentences embedded.\n",
            "311,000 sentences embedded.\n",
            "312,000 sentences embedded.\n",
            "313,000 sentences embedded.\n",
            "314,000 sentences embedded.\n",
            "315,000 sentences embedded.\n",
            "316,000 sentences embedded.\n",
            "317,000 sentences embedded.\n",
            "318,000 sentences embedded.\n",
            "319,000 sentences embedded.\n",
            "320,000 sentences embedded.\n",
            "321,000 sentences embedded.\n",
            "322,000 sentences embedded.\n",
            "323,000 sentences embedded.\n",
            "324,000 sentences embedded.\n",
            "325,000 sentences embedded.\n",
            "326,000 sentences embedded.\n",
            "327,000 sentences embedded.\n",
            "328,000 sentences embedded.\n",
            "329,000 sentences embedded.\n",
            "330,000 sentences embedded.\n",
            "331,000 sentences embedded.\n",
            "332,000 sentences embedded.\n",
            "333,000 sentences embedded.\n",
            "334,000 sentences embedded.\n",
            "335,000 sentences embedded.\n",
            "336,000 sentences embedded.\n",
            "337,000 sentences embedded.\n",
            "338,000 sentences embedded.\n",
            "339,000 sentences embedded.\n",
            "340,000 sentences embedded.\n",
            "341,000 sentences embedded.\n",
            "342,000 sentences embedded.\n",
            "343,000 sentences embedded.\n",
            "344,000 sentences embedded.\n",
            "345,000 sentences embedded.\n",
            "346,000 sentences embedded.\n",
            "347,000 sentences embedded.\n",
            "348,000 sentences embedded.\n",
            "349,000 sentences embedded.\n",
            "350,000 sentences embedded.\n",
            "351,000 sentences embedded.\n",
            "352,000 sentences embedded.\n",
            "353,000 sentences embedded.\n",
            "354,000 sentences embedded.\n",
            "355,000 sentences embedded.\n",
            "356,000 sentences embedded.\n",
            "357,000 sentences embedded.\n",
            "358,000 sentences embedded.\n",
            "359,000 sentences embedded.\n",
            "360,000 sentences embedded.\n",
            "361,000 sentences embedded.\n",
            "362,000 sentences embedded.\n",
            "363,000 sentences embedded.\n",
            "364,000 sentences embedded.\n",
            "365,000 sentences embedded.\n",
            "366,000 sentences embedded.\n",
            "367,000 sentences embedded.\n",
            "368,000 sentences embedded.\n",
            "369,000 sentences embedded.\n",
            "370,000 sentences embedded.\n",
            "371,000 sentences embedded.\n",
            "372,000 sentences embedded.\n",
            "373,000 sentences embedded.\n",
            "374,000 sentences embedded.\n",
            "375,000 sentences embedded.\n",
            "376,000 sentences embedded.\n",
            "377,000 sentences embedded.\n",
            "378,000 sentences embedded.\n",
            "379,000 sentences embedded.\n",
            "380,000 sentences embedded.\n",
            "381,000 sentences embedded.\n",
            "382,000 sentences embedded.\n",
            "383,000 sentences embedded.\n",
            "384,000 sentences embedded.\n",
            "385,000 sentences embedded.\n",
            "386,000 sentences embedded.\n",
            "387,000 sentences embedded.\n",
            "388,000 sentences embedded.\n",
            "389,000 sentences embedded.\n",
            "390,000 sentences embedded.\n",
            "391,000 sentences embedded.\n",
            "392,000 sentences embedded.\n",
            "393,000 sentences embedded.\n",
            "394,000 sentences embedded.\n",
            "395,000 sentences embedded.\n",
            "396,000 sentences embedded.\n",
            "397,000 sentences embedded.\n",
            "398,000 sentences embedded.\n",
            "399,000 sentences embedded.\n",
            "400,000 sentences embedded.\n",
            "401,000 sentences embedded.\n",
            "402,000 sentences embedded.\n",
            "403,000 sentences embedded.\n",
            "404,000 sentences embedded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JjaJeiiBTw9w",
        "colab_type": "code",
        "outputId": "8f64ab4f-abf7-4bb2-8aa2-9b3bcc45f630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 20, 300)      25762500    input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 32)           42624       embedding_2[0][0]                \n",
            "                                                                 embedding_2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64)           0           lstm_2[0][0]                     \n",
            "                                                                 lstm_2[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            65          concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 25,805,189\n",
            "Trainable params: 42,689\n",
            "Non-trainable params: 25,762,500\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"387pt\" viewBox=\"0.00 0.00 568.00 387.00\" width=\"568pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 564,-383 564,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139805257037584 -->\n<g class=\"node\" id=\"node1\">\n<title>139805257037584</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 271,-378.5 271,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-351.8\">input_3: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-332.5 133,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-355.5 191,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-332.5 191,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-363.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"191,-355.5 271,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-340.3\">(None, 20)</text>\n</g>\n<!-- 139808604345456 -->\n<g class=\"node\" id=\"node3\">\n<title>139808604345456</title>\n<polygon fill=\"none\" points=\"110,-249.5 110,-295.5 449,-295.5 449,-249.5 110,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-268.8\">embedding_2: Embedding</text>\n<polyline fill=\"none\" points=\"281,-249.5 281,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"281,-272.5 339,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"339,-249.5 339,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"394\" y=\"-280.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"339,-272.5 449,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"394\" y=\"-257.3\">(None, 20, 300)</text>\n</g>\n<!-- 139805257037584&#45;&gt;139808604345456 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139805257037584-&gt;139808604345456</title>\n<path d=\"M175.612,-332.3799C192.5492,-322.6175 212.4366,-311.1546 230.2524,-300.8857\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"232.4375,-303.6661 239.3536,-295.6399 228.9419,-297.6014 232.4375,-303.6661\" stroke=\"#000000\"/>\n</g>\n<!-- 139805257037640 -->\n<g class=\"node\" id=\"node2\">\n<title>139805257037640</title>\n<polygon fill=\"none\" points=\"289,-332.5 289,-378.5 560,-378.5 560,-332.5 289,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355.5\" y=\"-351.8\">input_4: InputLayer</text>\n<polyline fill=\"none\" points=\"422,-332.5 422,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"422,-355.5 480,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"480,-332.5 480,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520\" y=\"-363.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"480,-355.5 560,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520\" y=\"-340.3\">(None, 20)</text>\n</g>\n<!-- 139805257037640&#45;&gt;139808604345456 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139805257037640-&gt;139808604345456</title>\n<path d=\"M384.1094,-332.3799C367.0547,-322.6175 347.0292,-311.1546 329.0896,-300.8857\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"330.3427,-297.5703 319.9252,-295.6399 326.8652,-303.6454 330.3427,-297.5703\" stroke=\"#000000\"/>\n</g>\n<!-- 139805257039208 -->\n<g class=\"node\" id=\"node4\">\n<title>139805257039208</title>\n<polygon fill=\"none\" points=\"144.5,-166.5 144.5,-212.5 414.5,-212.5 414.5,-166.5 144.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-185.8\">lstm_2: LSTM</text>\n<polyline fill=\"none\" points=\"246.5,-166.5 246.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"246.5,-189.5 304.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"304.5,-166.5 304.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.5\" y=\"-197.3\">(None, 20, 300)</text>\n<polyline fill=\"none\" points=\"304.5,-189.5 414.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 139808604345456&#45;&gt;139805257039208 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139808604345456-&gt;139805257039208</title>\n<path d=\"M279.5,-249.3799C279.5,-241.1745 279.5,-231.7679 279.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"283.0001,-222.784 279.5,-212.784 276.0001,-222.784 283.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139805257039488 -->\n<g class=\"node\" id=\"node5\">\n<title>139805257039488</title>\n<polygon fill=\"none\" points=\"83.5,-83.5 83.5,-129.5 475.5,-129.5 475.5,-83.5 83.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"171\" y=\"-102.8\">concatenate_2: Concatenate</text>\n<polyline fill=\"none\" points=\"258.5,-83.5 258.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"258.5,-106.5 316.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"316.5,-83.5 316.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-114.3\">[(None, 32), (None, 32)]</text>\n<polyline fill=\"none\" points=\"316.5,-106.5 475.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-91.3\">(None, 64)</text>\n</g>\n<!-- 139805257039208&#45;&gt;139805257039488 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139805257039208-&gt;139805257039488</title>\n<path d=\"M279.5,-166.3799C279.5,-158.1745 279.5,-148.7679 279.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"283.0001,-139.784 279.5,-129.784 276.0001,-139.784 283.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139805257038928 -->\n<g class=\"node\" id=\"node6\">\n<title>139805257038928</title>\n<polygon fill=\"none\" points=\"157,-.5 157,-46.5 402,-46.5 402,-.5 157,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"264,-.5 264,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"264,-23.5 322,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"322,-.5 322,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-31.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"322,-23.5 402,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139805257039488&#45;&gt;139805257038928 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139805257039488-&gt;139805257038928</title>\n<path d=\"M279.5,-83.3799C279.5,-75.1745 279.5,-65.7679 279.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"283.0001,-56.784 279.5,-46.784 276.0001,-56.784 283.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "StC6KwjOT6F4",
        "colab_type": "code",
        "outputId": "836ff966-34d2-4721-b0cc-d429b52ea520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "training_start_time = time()\n",
        "\n",
        "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\n",
        "                           batch_size=batch_size, epochs=n_epoch,\n",
        "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "\n",
        "training_end_time = time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 363916 samples, validate on 40435 samples\n",
            "Epoch 1/20\n",
            "363916/363916 [==============================] - 47s 128us/step - loss: 0.5727 - acc: 0.7008 - val_loss: 0.5532 - val_acc: 0.7178\n",
            "Epoch 2/20\n",
            "363916/363916 [==============================] - 44s 121us/step - loss: 0.5417 - acc: 0.7281 - val_loss: 0.5439 - val_acc: 0.7221\n",
            "Epoch 3/20\n",
            "363916/363916 [==============================] - 44s 120us/step - loss: 0.5272 - acc: 0.7371 - val_loss: 0.5335 - val_acc: 0.7317\n",
            "Epoch 4/20\n",
            "363916/363916 [==============================] - 44s 120us/step - loss: 0.5164 - acc: 0.7447 - val_loss: 0.5249 - val_acc: 0.7389\n",
            "Epoch 5/20\n",
            "363916/363916 [==============================] - 45s 124us/step - loss: 0.5082 - acc: 0.7495 - val_loss: 0.5135 - val_acc: 0.7484\n",
            "Epoch 6/20\n",
            "363916/363916 [==============================] - 44s 122us/step - loss: 0.5006 - acc: 0.7541 - val_loss: 0.5083 - val_acc: 0.7521\n",
            "Epoch 7/20\n",
            "363916/363916 [==============================] - 44s 122us/step - loss: 0.4944 - acc: 0.7580 - val_loss: 0.5064 - val_acc: 0.7551\n",
            "Epoch 8/20\n",
            "363916/363916 [==============================] - 44s 120us/step - loss: 0.4893 - acc: 0.7610 - val_loss: 0.5168 - val_acc: 0.7450\n",
            "Epoch 9/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4843 - acc: 0.7642 - val_loss: 0.5062 - val_acc: 0.7540\n",
            "Epoch 10/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4799 - acc: 0.7666 - val_loss: 0.5006 - val_acc: 0.7590\n",
            "Epoch 11/20\n",
            "363916/363916 [==============================] - 43s 118us/step - loss: 0.4755 - acc: 0.7694 - val_loss: 0.5021 - val_acc: 0.7593\n",
            "Epoch 12/20\n",
            "363916/363916 [==============================] - 43s 118us/step - loss: 0.4710 - acc: 0.7717 - val_loss: 0.4985 - val_acc: 0.7604\n",
            "Epoch 13/20\n",
            "363916/363916 [==============================] - 43s 118us/step - loss: 0.4678 - acc: 0.7737 - val_loss: 0.4994 - val_acc: 0.7604\n",
            "Epoch 14/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4648 - acc: 0.7753 - val_loss: 0.4983 - val_acc: 0.7623\n",
            "Epoch 15/20\n",
            "363916/363916 [==============================] - 43s 118us/step - loss: 0.4609 - acc: 0.7780 - val_loss: 0.4976 - val_acc: 0.7628\n",
            "Epoch 16/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4578 - acc: 0.7792 - val_loss: 0.5016 - val_acc: 0.7639\n",
            "Epoch 17/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4554 - acc: 0.7805 - val_loss: 0.5056 - val_acc: 0.7622\n",
            "Epoch 18/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4523 - acc: 0.7822 - val_loss: 0.4962 - val_acc: 0.7629\n",
            "Epoch 19/20\n",
            "363916/363916 [==============================] - 43s 119us/step - loss: 0.4499 - acc: 0.7833 - val_loss: 0.5033 - val_acc: 0.7644\n",
            "Epoch 20/20\n",
            "363916/363916 [==============================] - 44s 120us/step - loss: 0.4469 - acc: 0.7859 - val_loss: 0.5022 - val_acc: 0.7587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7kxIJ1ESeve3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"Siamese_emb_not_trainable_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L3rKsJPk9Luo",
        "colab_type": "code",
        "outputId": "14933a32-50fd-47ee-ce6c-a1de1b26e5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = malstm_trained.history['acc']\n",
        "val_acc = malstm_trained.history['val_acc']\n",
        "loss = malstm_trained.history['loss']\n",
        "val_loss = malstm_trained.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f272808ac88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYRQGCnOQgghhMJIcRZCCCEU5i963fxjQ38RDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f27280854e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ft61ohe3hnYx",
        "colab_type": "code",
        "outputId": "5309896e-7f80-48ef-ec57-035bd448b1f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "! ls -al '/content/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x 4 root root 4096 Nov  1 16:42 .\n",
            "drwxr-xr-x 1 root root 4096 Nov  5 13:25 ..\n",
            "drwxr-xr-x 4 root root 4096 Nov  1 16:29 .config\n",
            "drwxr-xr-x 2 root root 4096 Nov  1 16:42 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9KjjxpcGgfqw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"Siamese_emb_not_trainable_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTv1FpZlgbHX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_results = model.predict([X_validation['left'][0:20],X_validation['right'][0:20]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y86Y9OOoGIDe",
        "colab_type": "code",
        "outputId": "cdec8ef6-e548-44d1-dc8d-4056e42b3de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.round(predict_results,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22],\n",
              "       [0.57],\n",
              "       [0.66],\n",
              "       [0.06],\n",
              "       [0.11],\n",
              "       [0.51],\n",
              "       [0.61],\n",
              "       [0.19],\n",
              "       [0.  ],\n",
              "       [0.94],\n",
              "       [0.1 ],\n",
              "       [0.21],\n",
              "       [0.62],\n",
              "       [0.15],\n",
              "       [0.31],\n",
              "       [0.68],\n",
              "       [0.45],\n",
              "       [0.99],\n",
              "       [0.11],\n",
              "       [0.55]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "ZBcNAhfnGiKA",
        "colab_type": "code",
        "outputId": "0a6f7f60-8637-45b7-9be5-ec64e2b8aaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#觀察測試集中相似度高的 question pair-> 第9筆,相似度為0.94\n",
        "X_validation['left'][9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,  151,  200,  166, 8054], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "-KpAp5NzHjoF",
        "colab_type": "code",
        "outputId": "0d713b3a-f24c-46b6-8c7f-66ea6b6f9db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "X_validation['right'][9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,   657,\n",
              "         166, 14025], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "P1-m7qc4J0WE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inv_vocabs = {}\n",
        "for key in vocabs:\n",
        "  inv_vocabs[vocabs[key]] = key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6qUkuwzKEHA",
        "colab_type": "code",
        "outputId": "c898d81b-122b-4878-e4fa-506b1ba2c16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "#印出question的文字(pair的左邊)\n",
        "for x in X_validation['left'][9]:\n",
        "  if x != 0:\n",
        "    print (inv_vocabs[x])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best\n",
            "way\n",
            "avoid\n",
            "procrastination\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O2hLe9R2Kot8",
        "colab_type": "code",
        "outputId": "8c88606a-bb5b-4a6f-b5d3-9f8d87028968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#印出question的文字(pair的右邊)\n",
        "for x in X_validation['right'][9]:\n",
        "  if x != 0:\n",
        "    print (inv_vocabs[x])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "could\n",
            "avoid\n",
            "laziness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-CsvP4HyJyTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnbPnupJeMD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CX8OrIf-2lb",
        "colab_type": "code",
        "outputId": "92f88bf1-9f5d-429d-8760-c87a6219e600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "cell_type": "code",
      "source": [
        "#使用亂數模擬資料\n",
        "import numpy as np\n",
        "\n",
        "num_samples = 100\n",
        "num_symbols = 10\n",
        "\n",
        "TRACE = True\n",
        "\n",
        "left_data = np.random.randint(0,num_symbols, size=(num_samples,1,128))\n",
        "if TRACE:\n",
        "    print(type(left_data))\n",
        "    print(left_data.shape)\n",
        "    print(left_data)\n",
        "    print('-'*50)\n",
        "\n",
        "right_data = np.random.randint(0,num_symbols, size=(num_samples,1,128))\n",
        "if TRACE:\n",
        "    print(type(right_data))\n",
        "    print(right_data.shape)\n",
        "    print(right_data)\n",
        "    print('-'*50)\n",
        "\n",
        "matching_list = [np.random.randint(0,num_symbols) for _ in range(num_samples)]\n",
        "targets = np.array(matching_list)\n",
        "if TRACE:\n",
        "    print(type(targets))\n",
        "    print(targets.shape)\n",
        "    print(targets)\n",
        "    print('-'*50)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(100, 1, 128)\n",
            "[[[4 1 1 ... 4 4 7]]\n",
            "\n",
            " [[8 7 6 ... 9 8 7]]\n",
            "\n",
            " [[6 6 3 ... 7 4 2]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[7 7 5 ... 8 0 6]]\n",
            "\n",
            " [[7 9 7 ... 0 9 5]]\n",
            "\n",
            " [[6 7 1 ... 2 6 7]]]\n",
            "--------------------------------------------------\n",
            "<class 'numpy.ndarray'>\n",
            "(100, 1, 128)\n",
            "[[[2 3 3 ... 5 3 0]]\n",
            "\n",
            " [[2 1 6 ... 0 7 8]]\n",
            "\n",
            " [[8 9 3 ... 6 0 4]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[4 9 7 ... 7 9 5]]\n",
            "\n",
            " [[7 3 0 ... 7 8 3]]\n",
            "\n",
            " [[9 4 8 ... 4 3 4]]]\n",
            "--------------------------------------------------\n",
            "<class 'numpy.ndarray'>\n",
            "(100,)\n",
            "[0 8 3 4 5 0 1 0 3 1 1 4 7 4 6 7 4 0 8 0 2 6 5 3 2 3 5 7 5 7 7 4 1 1 0 8 1\n",
            " 9 5 2 8 9 1 5 3 0 0 7 9 4 2 5 4 3 6 0 4 0 0 9 4 8 7 7 6 8 5 2 5 0 5 8 0 6\n",
            " 3 1 7 9 8 4 0 9 5 3 9 2 4 4 5 2 0 0 4 6 2 3 5 9 7 7]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HBuMbQNjdW-9",
        "colab_type": "code",
        "outputId": "88925619-2564-45df-9851-f83a0a84f526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#書上的範例程式, 並未使用Embedding layer\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "\n",
        "# Instantiates a single LSTM layer, once\n",
        "lstm = layers.LSTM(32)\n",
        "\n",
        "# Building the left branch of the model: \n",
        "# inputs are variable-length sequences of vectors of size 128.\n",
        "left_input = Input(shape=(None, 128))\n",
        "left_output = lstm(left_input)\n",
        "\n",
        "# Building the right branch of the model:\n",
        "# when you call an existing layer instance, you reuse its weights.\n",
        "right_input = Input(shape=(None, 128))\n",
        "right_output = lstm(right_input)\n",
        "\n",
        "# Builds the classifier on top\n",
        "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "# Instantiating the model\n",
        "model = Model([left_input, right_input], predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ImWzdhm1Grff",
        "colab_type": "code",
        "outputId": "b05150bb-dc28-4bbc-9e2d-1de82f5a94ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, 128)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 128)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           20608       input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            65          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 20,673\n",
            "Trainable params: 20,673\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"304pt\" viewBox=\"0.00 0.00 660.00 304.00\" width=\"660pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 656,-300 656,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140658436107456 -->\n<g class=\"node\" id=\"node1\">\n<title>140658436107456</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 317,-295.5 317,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-268.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-249.5 133,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-272.5 191,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-249.5 191,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-280.3\">(None, None, 128)</text>\n<polyline fill=\"none\" points=\"191,-272.5 317,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-257.3\">(None, None, 128)</text>\n</g>\n<!-- 140658436107344 -->\n<g class=\"node\" id=\"node3\">\n<title>140658436107344</title>\n<polygon fill=\"none\" points=\"182.5,-166.5 182.5,-212.5 468.5,-212.5 468.5,-166.5 182.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-185.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"284.5,-166.5 284.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"284.5,-189.5 342.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"342.5,-166.5 342.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-197.3\">(None, None, 128)</text>\n<polyline fill=\"none\" points=\"342.5,-189.5 468.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 140658436107456&#45;&gt;140658436107344 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140658436107456-&gt;140658436107344</title>\n<path d=\"M205.0188,-249.3799C225.1117,-239.3936 248.7848,-227.6279 269.8043,-217.1811\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.5441,-220.2249 278.9413,-212.6399 268.4286,-213.9564 271.5441,-220.2249\" stroke=\"#000000\"/>\n</g>\n<!-- 140657393087768 -->\n<g class=\"node\" id=\"node2\">\n<title>140657393087768</title>\n<polygon fill=\"none\" points=\"335,-249.5 335,-295.5 652,-295.5 652,-249.5 335,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-268.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"468,-249.5 468,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"468,-272.5 526,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"526,-249.5 526,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589\" y=\"-280.3\">(None, None, 128)</text>\n<polyline fill=\"none\" points=\"526,-272.5 652,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589\" y=\"-257.3\">(None, None, 128)</text>\n</g>\n<!-- 140657393087768&#45;&gt;140658436107344 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140657393087768-&gt;140658436107344</title>\n<path d=\"M446.7026,-249.3799C426.4894,-239.3936 402.6746,-227.6279 381.5292,-217.1811\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"382.8533,-213.9315 372.3375,-212.6399 379.7527,-220.2073 382.8533,-213.9315\" stroke=\"#000000\"/>\n</g>\n<!-- 140657393087208 -->\n<g class=\"node\" id=\"node4\">\n<title>140657393087208</title>\n<polygon fill=\"none\" points=\"129.5,-83.5 129.5,-129.5 521.5,-129.5 521.5,-83.5 129.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-102.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"304.5,-83.5 304.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"304.5,-106.5 362.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"362.5,-83.5 362.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442\" y=\"-114.3\">[(None, 32), (None, 32)]</text>\n<polyline fill=\"none\" points=\"362.5,-106.5 521.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442\" y=\"-91.3\">(None, 64)</text>\n</g>\n<!-- 140658436107344&#45;&gt;140657393087208 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140658436107344-&gt;140657393087208</title>\n<path d=\"M325.5,-166.3799C325.5,-158.1745 325.5,-148.7679 325.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"329.0001,-139.784 325.5,-129.784 322.0001,-139.784 329.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140657393087040 -->\n<g class=\"node\" id=\"node5\">\n<title>140657393087040</title>\n<polygon fill=\"none\" points=\"203,-.5 203,-46.5 448,-46.5 448,-.5 203,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"310,-.5 310,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"310,-23.5 368,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"368,-.5 368,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-31.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"368,-23.5 448,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140657393087208&#45;&gt;140657393087040 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140657393087208-&gt;140657393087040</title>\n<path d=\"M325.5,-83.3799C325.5,-75.1745 325.5,-65.7679 325.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"329.0001,-56.784 325.5,-46.784 322.0001,-56.784 329.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "rEGypXHxG9fa",
        "colab_type": "code",
        "outputId": "31221ec2-fb2d-4d0f-d227-28511d89fc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "# 使用模擬資料進行training\n",
        "# We must compile a model before training/testing.\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "\n",
        "# Training the model: when you train such a model,\n",
        "# the weights of the LSTM layer are updated based on both inputs.\n",
        "model.fit([left_data, right_data],targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "100/100 [==============================] - 3s 31ms/step - loss: -3.0247 - acc: 0.0900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed59353f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "KGJ0nkWX-2lh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1.6. Models as layers\n",
        "\n",
        "Importantly, in the functional API, models can be used as you’d use layers—effectively, you can think of a model as a “bigger layer.” This is true of both the Sequential and Model classes. This means you can call a model on an input tensor and retrieve an output tensor: \n",
        "\n",
        "    y = model(x)\n",
        "\n",
        "If the model has multiple input tensors and multiple output tensors, it should be called with a list of tensors: \n",
        "\n",
        "    y1, y2 = model([x1, x2])\n",
        "\n",
        "When you call a model instance, you’re reusing the weights of the model—exactly like what happens when you call a layer instance. Calling an instance, whether it’s a layer instance or a model instance, will always reuse the existing learned representations of the instance—which is intuitive."
      ]
    },
    {
      "metadata": {
        "id": "ojA1GoJb-2lh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import applications \n",
        "from keras import Input\n",
        "\n",
        "nbr_classes = 10\n",
        "\n",
        "# The base image-processing model is the Xception network (convolutional base only).\n",
        "xception_base = applications.Xception(weights=None,include_top=False)\n",
        "\n",
        "# The inputs are 250 × 250 RGB images.\n",
        "left_input = Input(shape=(250, 250, 3))\n",
        "right_input = Input(shape=(250, 250, 3))\n",
        "\n",
        "left_features = xception_base(left_input)\n",
        "# right_input = xception_base(right_input)\n",
        "right_features = xception_base(right_input)\n",
        "\n",
        "merged_features = layers.concatenate([left_features, right_features], axis=-1)\n",
        "\n",
        "predictions = layers.Dense(nbr_classes, activation='softmax')(merged_features)\n",
        "\n",
        "# Instantiating the model\n",
        "model = Model([left_input, right_input], predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RiTOYosP-2lj",
        "colab_type": "code",
        "outputId": "afbd7590-0616-43a1-c1e0-e4a0d34f2c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 250, 250, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 250, 250, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "xception (Model)                multiple             20861480    input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 4096)   0           xception[1][0]                   \n",
            "                                                                 xception[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 8, 8, 10)     40970       concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 20,902,450\n",
            "Trainable params: 20,847,922\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"304pt\" viewBox=\"0.00 0.00 672.00 304.00\" width=\"672pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 668,-300 668,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140657273414712 -->\n<g class=\"node\" id=\"node1\">\n<title>140657273414712</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 323,-295.5 323,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-268.8\">input_4: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-249.5 133,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-272.5 191,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-249.5 191,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-280.3\">(None, 250, 250, 3)</text>\n<polyline fill=\"none\" points=\"191,-272.5 323,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-257.3\">(None, 250, 250, 3)</text>\n</g>\n<!-- 140656954947512 -->\n<g class=\"node\" id=\"node3\">\n<title>140656954947512</title>\n<polygon fill=\"none\" points=\"215,-166.5 215,-212.5 448,-212.5 448,-166.5 215,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-185.8\">xception: Model</text>\n<polyline fill=\"none\" points=\"326,-166.5 326,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"326,-189.5 384,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"384,-166.5 384,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416\" y=\"-197.3\">multiple</text>\n<polyline fill=\"none\" points=\"384,-189.5 448,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416\" y=\"-174.3\">multiple</text>\n</g>\n<!-- 140657273414712&#45;&gt;140656954947512 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140657273414712-&gt;140656954947512</title>\n<path d=\"M208.8545,-249.3799C229.4,-239.3488 253.6229,-227.5224 275.0915,-217.0406\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"276.6544,-220.1725 284.1049,-212.6399 273.5832,-213.8822 276.6544,-220.1725\" stroke=\"#000000\"/>\n</g>\n<!-- 140657232134664 -->\n<g class=\"node\" id=\"node2\">\n<title>140657232134664</title>\n<polygon fill=\"none\" points=\"341,-249.5 341,-295.5 664,-295.5 664,-249.5 341,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"407.5\" y=\"-268.8\">input_5: InputLayer</text>\n<polyline fill=\"none\" points=\"474,-249.5 474,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"474,-272.5 532,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"532,-249.5 532,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598\" y=\"-280.3\">(None, 250, 250, 3)</text>\n<polyline fill=\"none\" points=\"532,-272.5 664,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598\" y=\"-257.3\">(None, 250, 250, 3)</text>\n</g>\n<!-- 140657232134664&#45;&gt;140656954947512 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140657232134664-&gt;140656954947512</title>\n<path d=\"M454.867,-249.3799C434.2006,-239.3488 409.8352,-227.5224 388.2403,-217.0406\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"389.6985,-213.8579 379.1739,-212.6399 386.6418,-220.1553 389.6985,-213.8579\" stroke=\"#000000\"/>\n</g>\n<!-- 140656955306448 -->\n<g class=\"node\" id=\"node4\">\n<title>140656955306448</title>\n<polygon fill=\"none\" points=\"90.5,-83.5 90.5,-129.5 572.5,-129.5 572.5,-83.5 90.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178\" y=\"-102.8\">concatenate_2: Concatenate</text>\n<polyline fill=\"none\" points=\"265.5,-83.5 265.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"265.5,-106.5 323.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"323.5,-83.5 323.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448\" y=\"-114.3\">[(None, 8, 8, 2048), (None, 8, 8, 2048)]</text>\n<polyline fill=\"none\" points=\"323.5,-106.5 572.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448\" y=\"-91.3\">(None, 8, 8, 4096)</text>\n</g>\n<!-- 140656954947512&#45;&gt;140656955306448 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140656954947512-&gt;140656955306448</title>\n<path d=\"M331.5,-166.3799C331.5,-158.1745 331.5,-148.7679 331.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"335.0001,-139.784 331.5,-129.784 328.0001,-139.784 335.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140656955083520 -->\n<g class=\"node\" id=\"node5\">\n<title>140656955083520</title>\n<polygon fill=\"none\" points=\"186.5,-.5 186.5,-46.5 476.5,-46.5 476.5,-.5 186.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"293.5,-.5 293.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"293.5,-23.5 351.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"351.5,-.5 351.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-31.3\">(None, 8, 8, 4096)</text>\n<polyline fill=\"none\" points=\"351.5,-23.5 476.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-8.3\">(None, 8, 8, 10)</text>\n</g>\n<!-- 140656955306448&#45;&gt;140656955083520 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140656955306448-&gt;140656955083520</title>\n<path d=\"M331.5,-83.3799C331.5,-75.1745 331.5,-65.7679 331.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"335.0001,-56.784 331.5,-46.784 328.0001,-56.784 335.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "q28xgEGt-2lm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}